{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8d8081c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-24 03:02:27.247994: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input, GlobalAveragePooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '3'\n",
    "# 加载 CIFAR-10 数据\n",
    "import random\n",
    "import numpy as np\n",
    "# Load and preprocess CIFAR-10 data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc83d289",
   "metadata": {},
   "outputs": [],
   "source": [
    "##该模型并没有使用双重对齐，因为我使用的数据错了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91ddd2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xipeng/anaconda3/envs/keras2/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "import imageio\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from random import sample\n",
    "\n",
    "\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "import random\n",
    "import PIL\n",
    "from torchvision.transforms import functional as F\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import Compose\n",
    "\n",
    "\n",
    "class AddTrigger:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def add_trigger(self, img, noise=False):\n",
    "        \"\"\"Add WaNet trigger to image.\n",
    "\n",
    "        Args:\n",
    "            img (torch.Tensor): shape (C, H, W).\n",
    "            noise (bool): turn on noise mode, default is False\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Poisoned image, shape (C, H, W).\n",
    "        \"\"\"\n",
    "        if noise:\n",
    "            ins = torch.rand(1, self.h, self.h, 2) * self.noise_rescale - 1  # [-1, 1]\n",
    "            grid = self.grid + ins / self.h\n",
    "            grid = torch.clamp(self.grid + ins / self.h, -1, 1)\n",
    "        else:\n",
    "            grid = self.grid\n",
    "        poison_img = nn.functional.grid_sample(img.unsqueeze(0), grid, align_corners=True).squeeze()  # CHW\n",
    "        return poison_img\n",
    "\n",
    "\n",
    "class AddCIFAR10Trigger(AddTrigger):\n",
    "    \"\"\"Add WaNet trigger to CIFAR10 image.\n",
    "\n",
    "    Args:\n",
    "        identity_grid (orch.Tensor): the poisoned pattern shape.\n",
    "        noise_grid (orch.Tensor): the noise pattern.\n",
    "        noise (bool): turn on noise mode, default is False.\n",
    "        s (int or float): The strength of the noise grid. Default is 0.5.\n",
    "        grid_rescale (int or float): Scale :attr:`grid` to avoid pixel values going out of [-1, 1].\n",
    "            Default is 1.\n",
    "        noise_rescale (int or float): Scale the random noise from a uniform distribution on the\n",
    "            interval [0, 1). Default is 2.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, identity_grid, noise_grid, noise=True, s=0.9, grid_rescale=1, noise_rescale=2):\n",
    "        super(AddCIFAR10Trigger, self).__init__()\n",
    "\n",
    "        self.identity_grid = deepcopy(identity_grid)\n",
    "        self.noise_grid = deepcopy(noise_grid)\n",
    "        self.h = self.identity_grid.shape[2]\n",
    "        self.noise = noise\n",
    "        self.s = s\n",
    "        self.grid_rescale = grid_rescale\n",
    "        grid = self.identity_grid + self.s * self.noise_grid / self.h\n",
    "        self.grid = torch.clamp(grid * self.grid_rescale, -1, 1)\n",
    "        self.noise_rescale = noise_rescale\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img = F.pil_to_tensor(img)\n",
    "        img = F.convert_image_dtype(img, torch.float)\n",
    "        img = self.add_trigger(img, noise=self.noise)\n",
    "        img = img.numpy().transpose(1, 2, 0)\n",
    "        img = Image.fromarray(np.clip(img*255,0,255).round().astype(np.uint8))\n",
    "        # img = Image.fromarray(img.permute(1, 2, 0).numpy())\n",
    "        return img\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as tF\n",
    "\n",
    "# 设置设备为 CUDA (GPU) 如果可用，否则使用 CPU\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# CIFAR10 图像尺寸\n",
    "input_height, input_width = 32, 32\n",
    "\n",
    "# 创建 identity_grid\n",
    "y, x = torch.meshgrid(torch.linspace(-1, 1, input_height), torch.linspace(-1, 1, input_width))\n",
    "identity_grid = torch.stack((x, y), 2).unsqueeze(0).to(device)\n",
    "\n",
    "# 创建噪声 pattern\n",
    "ins = torch.randn(1, 1, input_height, input_width).to(device)  # 随机噪声\n",
    "noise_grid = tF.interpolate(ins, size=(input_height, input_width), mode=\"bicubic\", align_corners=True)\n",
    "noise_grid = noise_grid.permute(0, 2, 3, 1).to(device)\n",
    "\n",
    "trigger = AddCIFAR10Trigger(identity_grid, noise_grid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "153ccd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 选择1%的训练数据进行攻击\n",
    "num_samples = int(0.1 * x_train.shape[0])\n",
    "indices = np.random.choice(y_train.shape[0], num_samples, replace=False)\n",
    "\n",
    "target_class = 1  # 目标类别\n",
    "num_classes = 10  # CIFAR-10 数据集的类别数\n",
    "\n",
    "\n",
    "for i in indices:\n",
    "    img = x_train[i]  # 获取单个图像\n",
    "    img_pil = Image.fromarray((img * 255).astype(np.uint8)) \n",
    "    poisoned_img_tensor = trigger(img_pil)\n",
    "    transform_to_tensor = transforms.ToTensor()\n",
    "    poisoned_img_tensor = transform_to_tensor(poisoned_img_tensor)\n",
    "# 将 PyTorch 张量转换为 NumPy 数组\n",
    "    poisoned_img_np = poisoned_img_tensor.numpy().transpose(1, 2, 0)\n",
    "    x_train[i] = poisoned_img_np  \n",
    "    y_train[i] = to_categorical(target_class, num_classes=10)\n",
    "\n",
    "\n",
    "x_val_tigger = x_val.copy()\n",
    "y_val_tigger = y_val.copy()\n",
    "\n",
    "\n",
    "for i in range(len(x_val_tigger)):\n",
    "    img = x_val_tigger[i]  # 获取单个图像\n",
    "    img_pil = Image.fromarray((img * 255).astype(np.uint8)) \n",
    "    poisoned_img_tensor = trigger(img_pil)\n",
    "    transform_to_tensor = transforms.ToTensor()\n",
    "    poisoned_img_tensor = transform_to_tensor(poisoned_img_tensor)\n",
    "# 将 PyTorch 张量转换为 NumPy 数组\n",
    "    poisoned_img_np = poisoned_img_tensor.numpy().transpose(1, 2, 0)\n",
    "    x_val_tigger[i] = poisoned_img_np  \n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "x_test_tigger = x_test.copy()\n",
    "y_test_tigger = y_test.copy()\n",
    "\n",
    "    \n",
    "    \n",
    "for i in range(len(x_test)):\n",
    "    img = x_test_tigger[i]  # 获取单个图像\n",
    "    img_pil = Image.fromarray((img * 255).astype(np.uint8)) \n",
    "    poisoned_img_tensor = trigger(img_pil)\n",
    "    transform_to_tensor = transforms.ToTensor()\n",
    "    poisoned_img_tensor = transform_to_tensor(poisoned_img_tensor)\n",
    "# 将 PyTorch 张量转换为 NumPy 数组\n",
    "    poisoned_img_np = poisoned_img_tensor.numpy().transpose(1, 2, 0)\n",
    "    x_test_tigger[i] = poisoned_img_np  \n",
    "    y_test_tigger[i] = to_categorical(target_class, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "396d4a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_test_tigger[0])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb155b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_test[0])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd4d5301",
   "metadata": {},
   "outputs": [],
   "source": [
    "##进行攻击的思路\n",
    "#1.将数据集分成两部分  8比2吧\n",
    "#2.每个epcoch后再单独优化一下服务器模型，保持模拟的客户端模型不变，后门数据要多一些\n",
    "#3.验证数据集结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df84c583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "\n",
    "\n",
    "def create_client_model(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # 第一层卷积\n",
    "    x = layers.Conv2D(32, 3, strides=1, padding='same')(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # 第二层卷积\n",
    "    x = layers.Conv2D(64, 3, strides=1, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # 新增的第三层卷积\n",
    "    x = layers.Conv2D(128, 3, strides=1, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57fb44ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def res_block(filters, strides):\n",
    "    def block(x):\n",
    "        shortcut = x\n",
    "\n",
    "        x = layers.Conv2D(filters, 3, padding='same', strides=strides)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation('relu')(x)\n",
    "\n",
    "        x = layers.Conv2D(filters, 3, padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        # 捷径连接前的调整\n",
    "        shortcut = layers.Conv2D(filters, 1, strides=strides, padding='same')(shortcut)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "        x = layers.add([x, shortcut])\n",
    "        x = layers.Activation('relu')(x)\n",
    "        return x\n",
    "    return block\n",
    "\n",
    "def create_server_model():\n",
    "    # 调整输入层的定义以匹配修改后的客户端模型的输出\n",
    "    input_layer = layers.Input(shape=(32, 32, 128))  # 注意这里的变化\n",
    "\n",
    "    # 残差块定义保持不变，继续使用提前定义的 res_block\n",
    "    x = res_block(128, 1)(input_layer)  # 使用第一个残差块\n",
    "    x = res_block(128, 2)(x)            # 使用第二个残差块\n",
    "    x = res_block(128, 2)(x)           # 使用第三个残差块\n",
    "    x = res_block(256, 2)(x)           # 使用第四个残差块\n",
    "\n",
    "    # 全局平均池化和输出层保持不变\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    output = layers.Dense(10, activation='softmax')(x)\n",
    "    \n",
    "    model = models.Model(inputs=input_layer, outputs=output)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b402efc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-24 03:03:11.036908: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2024-07-24 03:03:11.073075: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:d8:00.0 name: NVIDIA Tesla V100-PCIE-16GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2024-07-24 03:03:11.073153: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-07-24 03:03:11.076368: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2024-07-24 03:03:11.079685: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2024-07-24 03:03:11.080242: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2024-07-24 03:03:11.083592: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-07-24 03:03:11.084994: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2024-07-24 03:03:11.091610: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-07-24 03:03:11.094493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2024-07-24 03:03:11.108070: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-24 03:03:11.156813: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 1700000000 Hz\n",
      "2024-07-24 03:03:11.157814: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d8078338a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-24 03:03:11.157859: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2024-07-24 03:03:11.376254: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d80789fe30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-24 03:03:11.376320: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA Tesla V100-PCIE-16GB, Compute Capability 7.0\n",
      "2024-07-24 03:03:11.378008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:d8:00.0 name: NVIDIA Tesla V100-PCIE-16GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2024-07-24 03:03:11.378075: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-07-24 03:03:11.378136: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2024-07-24 03:03:11.378160: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2024-07-24 03:03:11.378184: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2024-07-24 03:03:11.378206: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-07-24 03:03:11.378228: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2024-07-24 03:03:11.378252: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-07-24 03:03:11.381068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2024-07-24 03:03:11.381152: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-07-24 03:03:12.484121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-07-24 03:03:12.484183: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
      "2024-07-24 03:03:12.484198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
      "2024-07-24 03:03:12.487408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12893 MB memory) -> physical GPU (device: 0, name: NVIDIA Tesla V100-PCIE-16GB, pci bus id: 0000:d8:00.0, compute capability: 7.0)\n"
     ]
    }
   ],
   "source": [
    "# 创建客户端模型\n",
    "client_model = create_client_model(input_shape=(32, 32, 3))\n",
    "\n",
    "# 编译客户端模型\n",
    "client_model.compile(optimizer=Adam(),\n",
    "                     loss='categorical_crossentropy',\n",
    "                     metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c17de27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 128)       0         \n",
      "=================================================================\n",
      "Total params: 94,144\n",
      "Trainable params: 93,696\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "client_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42722ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下是服务器模型训练的简化示例\n",
    "server_model = create_server_model()\n",
    "server_model.compile(optimizer=Adam(),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0237fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##创建三个影子模型，分别是1层卷积，2层卷积核3层卷积\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c1cb979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_client_model_1(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same')(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_client_model_2(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same')(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n",
    "def create_client_model_3(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same')(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n",
    "def create_client_model_4(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same')(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n",
    "\n",
    "def create_client_model_5(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # 第一层卷积\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same')(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # 第二层卷积\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # 第三层卷积\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # 第四层卷积\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # 第五层卷积\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27787dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 32, 32, 128)       0         \n",
      "=================================================================\n",
      "Total params: 94,144\n",
      "Trainable params: 93,696\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Assuming TensorFlow is installed and the functions are defined in your script\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "client_model_1 = create_client_model_3(input_shape=(32, 32, 3))\n",
    "\n",
    "\n",
    "# You can then print the model summaries to verify their structures\n",
    "print(client_model_1.summary())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18deb9f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992ef10f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0f8de9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "# 定义训练步骤\n",
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape_client, tf.GradientTape() as tape_server:\n",
    "        # 客户端前向传播\n",
    "        client_outputs = client_model(x, training=True)\n",
    "        # 服务器前向传播      \n",
    "        server_logits = server_model(client_outputs, training=True)\n",
    "        # 计算损失\n",
    "        loss = loss_fn(y, server_logits)\n",
    "\n",
    "    # 计算服务器模型梯度\n",
    "    grads_server = tape_server.gradient(loss, server_model.trainable_variables)\n",
    "    # 更新服务器模型权重\n",
    "    optimizer_server.apply_gradients(zip(grads_server, server_model.trainable_variables))\n",
    "\n",
    "    # 计算客户端模型梯度（模拟反向传播）\n",
    "    grads_client = tape_client.gradient(loss, client_model.trainable_variables)\n",
    "    # 更新客户端模型权重\n",
    "    optimizer_client.apply_gradients(zip(grads_client, client_model.trainable_variables))\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "627c62ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 假设 optimizer_client 和 optimizer_server 已经被定义\n",
    "optimizer_client_1 = tf.keras.optimizers.Adam()  # 为 client_model_1 定义一个新的优化器\n",
    "\n",
    "@tf.function\n",
    "def train_step_2(x, y):\n",
    "    # 首次使用客户端和服务器模型进行训练\n",
    "    with tf.GradientTape() as tape_client, tf.GradientTape() as tape_server:\n",
    "        client_outputs = client_model(x, training=True)  # 客户端模型前向传播\n",
    "        server_logits = server_model(client_outputs, training=True)  # 服务器模型前向传播\n",
    "        loss = loss_fn(y, server_logits)  # 计算损失\n",
    "\n",
    "    # 计算并应用服务器模型梯度\n",
    "    grads_server = tape_server.gradient(loss, server_model.trainable_variables)\n",
    "    optimizer_server.apply_gradients(zip(grads_server, server_model.trainable_variables))\n",
    "\n",
    "    # 计算并应用客户端模型梯度\n",
    "    grads_client = tape_client.gradient(loss, client_model.trainable_variables)\n",
    "    optimizer_client.apply_gradients(zip(grads_client, client_model.trainable_variables))\n",
    "\n",
    "    # 单独针对 client_model_1 的训练步骤\n",
    "    with tf.GradientTape() as tape_client_1:\n",
    "        client_outputs_1 = client_model_1(x, training=True)  # client_model_1 前向传播\n",
    "        server_logits_1 = server_model(client_outputs_1, training=False)  # 使用 server_model 进行前向传播但不更新\n",
    "        loss_1 = loss_fn(y, server_logits_1)  # 计算损失\n",
    "\n",
    "    # 计算并应用 client_model_1 的梯度\n",
    "    grads_client_1 = tape_client_1.gradient(loss_1, client_model_1.trainable_variables)\n",
    "    optimizer_client_1.apply_gradients(zip(grads_client_1, client_model_1.trainable_variables))\n",
    "\n",
    "    return loss, loss_1  # 返回两步训练的损失值\n",
    "\n",
    "# 注意：在实际使用中，确保已经正确初始化了所有模型（client_model, client_model_1, server_model）\n",
    "# 以及优化器（optimizer_client, optimizer_server, optimizer_client_1）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95d62a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step_client(x, y):\n",
    "    # 使用客户端和服务器模型进行训练\n",
    "    with tf.GradientTape() as tape_client, tf.GradientTape() as tape_server:\n",
    "        # 客户端模型前向传播\n",
    "        client_outputs = client_model(x, training=True)\n",
    "        # 服务器模型前向传播\n",
    "        server_logits = server_model(client_outputs, training=True)\n",
    "        # 计算损失\n",
    "        loss = loss_fn(y, server_logits)\n",
    "    \n",
    "    # 计算并应用服务器模型梯度\n",
    "    grads_server = tape_server.gradient(loss, server_model.trainable_variables)\n",
    "    optimizer_server.apply_gradients(zip(grads_server, server_model.trainable_variables))\n",
    "    \n",
    "    # 计算并应用客户端模型梯度\n",
    "    grads_client = tape_client.gradient(loss, client_model.trainable_variables)\n",
    "    optimizer_client.apply_gradients(zip(grads_client, client_model.trainable_variables))\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f850a6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step_client_1(x, y):\n",
    "    # 仅针对client_model_1的训练步骤\n",
    "    with tf.GradientTape() as tape_client_1:\n",
    "        # client_model_1前向传播\n",
    "        client_outputs_1 = client_model_1(x, training=True)\n",
    "        # 使用server_model进行前向传播但不更新\n",
    "        server_logits_1 = server_model(client_outputs_1, training=False)\n",
    "        # 计算损失\n",
    "        loss_1 = loss_fn(y, server_logits_1)\n",
    "\n",
    "    # 计算并应用client_model_1的梯度\n",
    "    grads_client_1 = tape_client_1.gradient(loss_1, client_model_1.trainable_variables)\n",
    "    optimizer_client_1.apply_gradients(zip(grads_client_1, client_model_1.trainable_variables))\n",
    "\n",
    "    return loss_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8a019b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb77e70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step_only_server(x, y):\n",
    "    with tf.GradientTape() as tape_server:\n",
    "        # 使用 client_model_1 进行前向传播，注意这里我们不更新 client_model_1\n",
    "        client_outputs_1 = client_model_1(x, training=False)  # 注意这里的 training=False\n",
    "        \n",
    "        # 使用 server_model 进行前向传播，准备更新这个模型\n",
    "        server_logits = server_model(client_outputs_1, training=True)\n",
    "        \n",
    "        # 计算损失\n",
    "        loss = loss_fn(y, server_logits)\n",
    "\n",
    "    # 计算服务器模型梯度并应用\n",
    "    grads_server = tape_server.gradient(loss, server_model.trainable_variables)\n",
    "    optimizer_server_2.apply_gradients(zip(grads_server, server_model.trainable_variables))\n",
    "\n",
    "    return loss  # 返回训练损失值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ca77b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844d5ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "930c02fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def create_combined_model(client_model, server_model, compile_only=False):\n",
    "    # Getting the input of the client model\n",
    "    client_input = client_model.input\n",
    "    \n",
    "    # Getting the intermediate output by passing the input through the client model\n",
    "    client_output = client_model(client_input)\n",
    "    \n",
    "    # The client model's output is used as the input for the server model\n",
    "    server_output = server_model(client_output)\n",
    "    \n",
    "    # Defining a new model that chains the client and server models\n",
    "    combined_model = Model(inputs=client_input, outputs=server_output)\n",
    "    \n",
    "    # Compile the combined model\n",
    "    combined_model.compile(optimizer=Adam(),\n",
    "                           loss='categorical_crossentropy',\n",
    "                           metrics=['accuracy'])\n",
    "    \n",
    "    if not compile_only:\n",
    "        # If not compile_only, evaluate the model\n",
    "        loss, accuracy = combined_model.evaluate(x_test, y_test, verbose=0)\n",
    "        print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n",
    "    \n",
    "    return combined_model\n",
    "\n",
    "# Use the function to create and compile the combined model without evaluating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a30f0c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def change_batch(resblock_test_trigger, client_outputs, y):\n",
    "    # 使用tf.random.uniform生成0到2000之间的随机整数索引\n",
    "    random_integer = tf.random.uniform(shape=(), minval=0, maxval=2000, dtype=tf.int32)\n",
    "    # 从resblock_test_trigger中选择一个随机元素\n",
    "    selected_trigger = tf.gather(resblock_test_trigger, random_integer)\n",
    "    # 确保selected_trigger的形状与client_outputs中的元素兼容\n",
    "    selected_trigger = tf.expand_dims(selected_trigger, 0)  # 假设它是一个序列，需要扩展维度以兼容\n",
    "\n",
    "    # 更新client_outputs的第一个元素\n",
    "    client_outputs_updated = tf.concat([selected_trigger, client_outputs[1:]], axis=0)\n",
    "    \n",
    "    # 创建一个新标签\n",
    "    new_label = tf.constant([0, 1, 0, 0, 0, 0, 0, 0, 0, 0], dtype=y.dtype)\n",
    "    # 使用tf.tensor_scatter_nd_update更新y的第一个样本的标签\n",
    "    indices = tf.constant([[0]])  # 表示我们要更新第一个样本的标签\n",
    "    updated_y = tf.tensor_scatter_nd_update(y, indices, tf.expand_dims(new_label, 0))\n",
    "\n",
    "    return client_outputs_updated, updated_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d20736f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "# 定义训练步骤\n",
    "@tf.function\n",
    "def train_step_door(x, y,resblock_test_tigger):\n",
    "    with tf.GradientTape() as tape_client, tf.GradientTape() as tape_server:\n",
    "        # 客户端前向传播\n",
    "        client_outputs = client_model(x, training=True)\n",
    "        client_outputs_updated, updated_y = change_batch(resblock_test_tigger,client_outputs,y)\n",
    "        # 服务器前向传播      \n",
    "        server_logits = server_model(client_outputs_updated, training=True)\n",
    "        # 计算损失\n",
    "        loss = loss_fn(updated_y, server_logits)\n",
    "\n",
    "    # 计算服务器模型梯度\n",
    "    grads_server = tape_server.gradient(loss, server_model.trainable_variables)\n",
    "    # 更新服务器模型权重\n",
    "    optimizer_server.apply_gradients(zip(grads_server, server_model.trainable_variables))\n",
    "\n",
    "    # 计算客户端模型梯度（模拟反向传播）\n",
    "    grads_client = tape_client.gradient(loss, client_model.trainable_variables)\n",
    "    # 更新客户端模型权重\n",
    "    optimizer_client1.apply_gradients(zip(grads_client, client_model.trainable_variables))\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35283538",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_client = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "optimizer_client1 = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "###这两个都是客户端的优化梯度\n",
    "\n",
    "optimizer_server = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "##optimizer_server 和 这两个都是客户端的优化梯度的梯度要一模一样\n",
    "\n",
    "optimizer_client_1 = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "\n",
    "optimizer_server_2 = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b39fe9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "def augment(image, label):\n",
    "    # 随机水平翻转图像\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    # 随机调整亮度\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    # 确保图像值仍然在0到1的范围内\n",
    "    image = tf.clip_by_value(image, 0.0, 1.0)\n",
    "    return image, label\n",
    "\n",
    "# 假设x_train, y_train, x_val, y_val, x_val_tigger, y_val_tigger已经定义并准备好了\n",
    "\n",
    "# 训练数据集 - 应用数据增强\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.map(augment).shuffle(len(x_train)).batch(batch_size)\n",
    "\n",
    "# 客户端验证数据集 - 也应用数据增强\n",
    "client_1_dataset = tf.data.Dataset.from_tensor_slices((x_val[2000:10000], y_val[2000:10000]))\n",
    "client_1_dataset = client_1_dataset.map(augment).shuffle(len(x_val)).batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8325444f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 32, 32, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val[2000:10000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ebf9f1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-24 03:03:18.548681: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session started.\n",
      "2024-07-24 03:03:18.548772: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1391] Profiler found 1 GPUs\n",
      "2024-07-24 03:03:18.550601: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcupti.so.10.1\n",
      "2024-07-24 03:03:18.552894: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1441] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_INSUFFICIENT_PRIVILEGES\n",
      "2024-07-24 03:03:30.250851: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2024-07-24 03:03:30.986150: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-07-24 03:03:34.594176: W tensorflow/stream_executor/gpu/asm_compiler.cc:81] Running ptxas --version returned 256\n",
      "2024-07-24 03:03:34.973310: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Client Model Loss: 1.1071\n",
      "  Client Model Loss: 0.7383\n",
      "  Client Model Loss: 0.6900\n",
      "  Client Model Loss: 0.2213\n",
      "  Client Model Loss: 0.4926\n",
      "  Client Model Loss: 0.4312\n",
      "  Client Model Loss: 0.2800\n",
      "  Client Model Loss: 0.3948\n",
      "  Client Model Loss: 0.3045\n",
      "  Client Model Loss: 0.4009\n",
      "  Client Model Loss: 0.1613\n",
      "  Client Model Loss: 0.1915\n",
      "  Client Model Loss: 0.1630\n",
      "  Client Model Loss: 0.1396\n",
      "  Client Model Loss: 0.1251\n",
      "  Client Model Loss: 0.0779\n",
      "  Client Model Loss: 0.1125\n",
      "  Client Model Loss: 0.0412\n",
      "  Client Model Loss: 0.0605\n",
      "  Client Model Loss: 0.0186\n",
      "  Client Model Loss: 0.0988\n",
      "  Client Model Loss: 0.0049\n",
      "  Client Model Loss: 0.0447\n",
      "  Client Model Loss: 0.0952\n",
      "  Client Model Loss: 0.0177\n",
      "  Client Model Loss: 0.0273\n",
      "  Client Model Loss: 0.0481\n",
      "  Client Model Loss: 0.0106\n",
      "  Client Model Loss: 0.0056\n",
      "  Client Model Loss: 0.0852\n",
      "  Client Model Loss: 0.0118\n",
      "  Client Model Loss: 0.1125\n",
      "  Client Model Loss: 0.0323\n",
      "  Client Model Loss: 0.0069\n",
      "  Client Model Loss: 0.0198\n",
      "  Client Model Loss: 0.0051\n",
      "  Client Model Loss: 0.0002\n",
      "  Client Model Loss: 0.0063\n",
      "  Client Model Loss: 0.0032\n",
      "  Client Model Loss: 0.0013\n",
      "  Client Model Loss: 0.0052\n",
      "  Client Model Loss: 0.0067\n",
      "  Client Model Loss: 0.0015\n",
      "  Client Model Loss: 0.0223\n",
      "  Client Model Loss: 0.0005\n",
      "  Client Model Loss: 0.0605\n",
      "  Client Model Loss: 0.0046\n",
      "  Client Model Loss: 0.0021\n",
      "  Client Model Loss: 0.0251\n",
      "  Client Model Loss: 0.0007\n",
      "  Client Model Loss: 0.0002\n",
      "  Client Model Loss: 0.0002\n",
      "  Client Model Loss: 0.0069\n",
      "  Client Model Loss: 0.0002\n",
      "  Client Model Loss: 0.0007\n"
     ]
    }
   ],
   "source": [
    "# 初始化TensorBoard回调\n",
    "import datetime\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "epochs = 60\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "combined_model = create_combined_model(client_model, server_model, compile_only=True)\n",
    "combined_model_1 = create_combined_model(client_model_1, server_model, compile_only=True)\n",
    "\n",
    "\n",
    "epoch_losses = []\n",
    "epoch_accuracies = []\n",
    "\n",
    "\n",
    "epoch_losses_1 = []\n",
    "epoch_accuracies_1 = []\n",
    "\n",
    "\n",
    "epoch_losses_2= []\n",
    "epoch_accuracies_2 = []\n",
    "\n",
    "\n",
    "epoch_losses_3= []\n",
    "epoch_accuracies_3 = []\n",
    "# 开始训练\n",
    "\n",
    "epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "epoch_loss_avg_server = tf.keras.metrics.Mean()\n",
    "\n",
    "#先训练\n",
    "\n",
    "for epoch in range(55):\n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    epoch_loss_avg_server = tf.keras.metrics.Mean()\n",
    "    for x_batch, y_batch in train_dataset:\n",
    "        loss = train_step_client(x_batch, y_batch)\n",
    "    print(f\"  Client Model Loss: {loss.numpy():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c989f14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ed397e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048f2873",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2315af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f5b0934",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# 假设client_model和server_model的输入和输出层已经定义\n",
    "\n",
    "# 获取客户端模型的输入\n",
    "client_input = client_model.input\n",
    "\n",
    "# 通过客户端模型获取中间输出\n",
    "client_output = client_model(client_input)\n",
    "\n",
    "# 将客户端的输出作为服务器模型的输入\n",
    "server_output = server_model(client_output)\n",
    "\n",
    "# 定义一个新的模型，该模型连接了客户端和服务器模型\n",
    "combined_model = Model(inputs=client_input, outputs=server_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e39c74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 65s 206ms/step - loss: 0.8079 - accuracy: 0.8476\n",
      "Test loss: 0.8078554272651672, Test accuracy: 0.847599983215332\n"
     ]
    }
   ],
   "source": [
    "combined_model.compile(optimizer='adam',\n",
    "                       loss='categorical_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# 假设x_test和y_test已经准备好\n",
    "loss, accuracy = combined_model.evaluate(x_test, y_test)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "79390ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0029 - accuracy: 0.9992\n",
      "Test loss: 0.0028592234011739492, Test accuracy: 0.9991999864578247\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model.evaluate(x_test_tigger, y_test_tigger)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c07c41bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# 假设client_model和server_model的输入和输出层已经定义\n",
    "\n",
    "# 获取客户端模型的输入\n",
    "client_input_1 = client_model_1.input\n",
    "\n",
    "# 通过客户端模型获取中间输出\n",
    "client_output_1 = client_model_1(client_input_1)\n",
    "\n",
    "# 将客户端的输出作为服务器模型的输入\n",
    "server_output_1 = server_model(client_output_1)\n",
    "\n",
    "# 定义一个新的模型，该模型连接了客户端和服务器模型\n",
    "combined_model_1 = Model(inputs=client_input_1, outputs=server_output_1)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8615b353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 11.8993 - accuracy: 0.1054\n",
      "Test loss: 11.899332046508789, Test accuracy: 0.10540000349283218\n"
     ]
    }
   ],
   "source": [
    "combined_model_1.compile(optimizer='adam',\n",
    "                       loss='categorical_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# 假设x_test和y_test已经准备好\n",
    "loss, accuracy = combined_model_1.evaluate(x_test, y_test)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "23579b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 0.7216 - accuracy: 0.7306\n",
      "Test loss: 0.7215956449508667, Test accuracy: 0.7305999994277954\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model_1.evaluate(x_test_tigger, y_test_tigger)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80692ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53814adf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3859f30f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "58a73419",
   "metadata": {},
   "outputs": [],
   "source": [
    "#313/313 [==============================] - 1s 3ms/step - loss: 0.9457 - accuracy: 0.7466\n",
    "#Test loss: 0.9456651210784912, Test accuracy: 0.7465999722480774\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "90528fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-24 03:27:44.143980: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 5242880000 exceeds 10% of free system memory.\n",
      "2024-07-24 03:28:03.008338: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 5242880000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Cosine Similarity: 0.2660582661628723\n",
      "Average Euclidean Distance: 202.68508428344725\n"
     ]
    }
   ],
   "source": [
    "# 获取两个模型的特征表示\n",
    "features_client_model_1 = client_model_1.predict(x_test)\n",
    "features_client_model = client_model.predict(x_test)\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# 计算余弦相似度\n",
    "cosine_sim = cosine_similarity(features_client_model_1.reshape(features_client_model_1.shape[0], -1),\n",
    "                               features_client_model.reshape(features_client_model.shape[0], -1))\n",
    "\n",
    "# 余弦相似度矩阵的对角线元素表示同一个x_test样本在两个模型特征空间中的相似度\n",
    "cosine_sim_diag = np.diag(cosine_sim)\n",
    "\n",
    "# 计算平均余弦相似度\n",
    "average_cosine_sim = np.mean(cosine_sim_diag)\n",
    "print(f\"Average Cosine Similarity: {average_cosine_sim}\")\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\n",
    "# 将特征向量展平\n",
    "features_client_model_1_flat = features_client_model_1.reshape(features_client_model_1.shape[0], -1)\n",
    "features_client_model_flat = features_client_model.reshape(features_client_model.shape[0], -1)\n",
    "\n",
    "# 计算欧几里得距离\n",
    "euclidean_dists = np.array([distance.euclidean(features_client_model_1_flat[i], features_client_model_flat[i]) \n",
    "                            for i in range(features_client_model_1_flat.shape[0])])\n",
    "\n",
    "# 计算平均欧几里得距离\n",
    "average_euclidean_dist = np.mean(euclidean_dists)\n",
    "print(f\"Average Euclidean Distance: {average_euclidean_dist}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa04a1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_model_1.save('client_model_1.h5')\n",
    "server_model.save('server_model.h5')\n",
    "client_model.save('client_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1803e2e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3146a014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c426d9fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0ed114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa341b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3e81f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff8d7ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed74411c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1210dd97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20ab9800",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
