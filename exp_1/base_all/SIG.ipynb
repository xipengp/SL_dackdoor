{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79f62628",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-24 00:46:31.215779: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input, GlobalAveragePooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2'\n",
    "# 加载 CIFAR-10 数据\n",
    "import random\n",
    "import numpy as np\n",
    "# Load and preprocess CIFAR-10 data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ad2c411",
   "metadata": {},
   "outputs": [],
   "source": [
    "##该模型并没有使用双重对齐，因为我使用的数据错了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d40f12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e30544fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class sigTriggerAttack(object):\n",
    "    def __init__(self, delta=40, f=6):\n",
    "        self.delta = delta\n",
    "        self.f = f\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return self.sigTrigger(img)\n",
    "\n",
    "    def sigTrigger(self, img):\n",
    "        img = np.float32(img)\n",
    "        pattern = np.zeros_like(img)\n",
    "        m = pattern.shape[1]\n",
    "        for i in range(int(img.shape[0])):\n",
    "            for j in range(int(img.shape[1])):\n",
    "                pattern[i, j] = self.delta * np.sin(2 * np.pi * j * self.f / m)\n",
    "\n",
    "        img = np.uint32(img * 255) + pattern  # 因为您之前已经将图像归一化，所以我们需要乘以255\n",
    "        img = np.uint8(np.clip(img, 0, 255))\n",
    "        return img / 255  # 再次归一化\n",
    "\n",
    "    \n",
    "    \n",
    "# Apply the SIG backdoor attack\n",
    "# Apply the SIG backdoor attack to the training set\n",
    "attack = sigTriggerAttack()\n",
    "\n",
    "# 选择1%的训练数据进行攻击\n",
    "num_samples = int(1/32 * x_val.shape[0])\n",
    "indices = np.random.choice(y_val.shape[0], num_samples, replace=False)\n",
    "\n",
    "target_class = 1  # 目标类别\n",
    "num_classes = 10  # CIFAR-10 数据集的类别数\n",
    "\n",
    "# 新的数据集和标签列表\n",
    "x_val_triggered = []  # 存储触发器转换后的图像\n",
    "y_val_triggered = []  # 存储更新后的标签\n",
    "\n",
    "x_val_tigger = x_val.copy()\n",
    "y_val_tigger = y_val.copy()\n",
    "\n",
    "# 应用攻击到选中的图像\n",
    "for i in indices:\n",
    "    x_train[i] = attack(x_train[i])\n",
    "    y_train[i] = to_categorical(target_class, num_classes=num_classes)\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "x_test_tigger = x_test.copy()\n",
    "y_test_tigger = y_test.copy()\n",
    "\n",
    "for i in range(len(x_test_tigger)):\n",
    "    x_test_tigger[i] = attack(x_test_tigger[i])\n",
    "    y_test_tigger[i] = to_categorical(target_class, num_classes=num_classes)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b3b6dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##进行攻击的思路\n",
    "#1.将数据集分成两部分  8比2吧\n",
    "#2.每个epcoch后再单独优化一下服务器模型，保持模拟的客户端模型不变，后门数据要多一些\n",
    "#3.验证数据集结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "651d8d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "\n",
    "\n",
    "def create_client_model(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # 第一层卷积\n",
    "    x = layers.Conv2D(32, 3, strides=1, padding='same')(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # 第二层卷积\n",
    "    x = layers.Conv2D(64, 3, strides=1, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # 新增的第三层卷积\n",
    "    x = layers.Conv2D(128, 3, strides=1, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bbb08d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def res_block(filters, strides):\n",
    "    def block(x):\n",
    "        shortcut = x\n",
    "\n",
    "        x = layers.Conv2D(filters, 3, padding='same', strides=strides)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation('relu')(x)\n",
    "\n",
    "        x = layers.Conv2D(filters, 3, padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        # 捷径连接前的调整\n",
    "        shortcut = layers.Conv2D(filters, 1, strides=strides, padding='same')(shortcut)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "        x = layers.add([x, shortcut])\n",
    "        x = layers.Activation('relu')(x)\n",
    "        return x\n",
    "    return block\n",
    "\n",
    "def create_server_model():\n",
    "    # 调整输入层的定义以匹配修改后的客户端模型的输出\n",
    "    input_layer = layers.Input(shape=(32, 32, 128))  # 注意这里的变化\n",
    "\n",
    "    # 残差块定义保持不变，继续使用提前定义的 res_block\n",
    "    x = res_block(128, 1)(input_layer)  # 使用第一个残差块\n",
    "    x = res_block(128, 2)(x)            # 使用第二个残差块\n",
    "    x = res_block(128, 2)(x)           # 使用第三个残差块\n",
    "    x = res_block(256, 2)(x)           # 使用第四个残差块\n",
    "\n",
    "    # 全局平均池化和输出层保持不变\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    output = layers.Dense(10, activation='softmax')(x)\n",
    "    \n",
    "    model = models.Model(inputs=input_layer, outputs=output)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3396f704",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-24 00:48:30.616190: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2024-07-24 00:48:30.684003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:af:00.0 name: NVIDIA Tesla V100-PCIE-16GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2024-07-24 00:48:30.684084: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-07-24 00:48:30.688180: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2024-07-24 00:48:30.692095: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2024-07-24 00:48:30.697815: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2024-07-24 00:48:30.701941: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-07-24 00:48:30.709062: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2024-07-24 00:48:30.722476: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-07-24 00:48:30.730714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2024-07-24 00:48:30.744829: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-24 00:48:30.799756: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 1700000000 Hz\n",
      "2024-07-24 00:48:30.800668: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5567bfcd1000 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-24 00:48:30.800708: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2024-07-24 00:48:31.453143: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5567bfcd3d10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-24 00:48:31.453193: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA Tesla V100-PCIE-16GB, Compute Capability 7.0\n",
      "2024-07-24 00:48:31.454977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:af:00.0 name: NVIDIA Tesla V100-PCIE-16GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2024-07-24 00:48:31.455038: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-07-24 00:48:31.455088: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2024-07-24 00:48:31.455111: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2024-07-24 00:48:31.455133: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2024-07-24 00:48:31.455155: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-07-24 00:48:31.455178: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2024-07-24 00:48:31.455200: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-07-24 00:48:31.457926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2024-07-24 00:48:31.457988: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-07-24 00:48:33.618324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-07-24 00:48:33.618392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
      "2024-07-24 00:48:33.618407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
      "2024-07-24 00:48:33.627661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14765 MB memory) -> physical GPU (device: 0, name: NVIDIA Tesla V100-PCIE-16GB, pci bus id: 0000:af:00.0, compute capability: 7.0)\n"
     ]
    }
   ],
   "source": [
    "# 创建客户端模型\n",
    "client_model = create_client_model(input_shape=(32, 32, 3))\n",
    "\n",
    "# 编译客户端模型\n",
    "client_model.compile(optimizer=Adam(),\n",
    "                     loss='categorical_crossentropy',\n",
    "                     metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "beb52aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 128)       0         \n",
      "=================================================================\n",
      "Total params: 94,144\n",
      "Trainable params: 93,696\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "client_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "427b0408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下是服务器模型训练的简化示例\n",
    "server_model = create_server_model()\n",
    "server_model.compile(optimizer=Adam(),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24382e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##创建三个影子模型，分别是1层卷积，2层卷积核3层卷积\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bec92cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_client_model_1(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same')(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_client_model_2(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same')(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n",
    "def create_client_model_3(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same')(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n",
    "def create_client_model_4(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same')(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n",
    "\n",
    "def create_client_model_5(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # 第一层卷积\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same')(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # 第二层卷积\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # 第三层卷积\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # 第四层卷积\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # 第五层卷积\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9daf8d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 32, 32, 128)       0         \n",
      "=================================================================\n",
      "Total params: 94,144\n",
      "Trainable params: 93,696\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Assuming TensorFlow is installed and the functions are defined in your script\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "client_model_1 = create_client_model_3(input_shape=(32, 32, 3))\n",
    "\n",
    "\n",
    "# You can then print the model summaries to verify their structures\n",
    "print(client_model_1.summary())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83656ace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91610b14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf3b7313",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "# 定义训练步骤\n",
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape_client, tf.GradientTape() as tape_server:\n",
    "        # 客户端前向传播\n",
    "        client_outputs = client_model(x, training=True)\n",
    "        # 服务器前向传播      \n",
    "        server_logits = server_model(client_outputs, training=True)\n",
    "        # 计算损失\n",
    "        loss = loss_fn(y, server_logits)\n",
    "\n",
    "    # 计算服务器模型梯度\n",
    "    grads_server = tape_server.gradient(loss, server_model.trainable_variables)\n",
    "    # 更新服务器模型权重\n",
    "    optimizer_server.apply_gradients(zip(grads_server, server_model.trainable_variables))\n",
    "\n",
    "    # 计算客户端模型梯度（模拟反向传播）\n",
    "    grads_client = tape_client.gradient(loss, client_model.trainable_variables)\n",
    "    # 更新客户端模型权重\n",
    "    optimizer_client.apply_gradients(zip(grads_client, client_model.trainable_variables))\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7ab7ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 假设 optimizer_client 和 optimizer_server 已经被定义\n",
    "optimizer_client_1 = tf.keras.optimizers.Adam()  # 为 client_model_1 定义一个新的优化器\n",
    "\n",
    "@tf.function\n",
    "def train_step_2(x, y):\n",
    "    # 首次使用客户端和服务器模型进行训练\n",
    "    with tf.GradientTape() as tape_client, tf.GradientTape() as tape_server:\n",
    "        client_outputs = client_model(x, training=True)  # 客户端模型前向传播\n",
    "        server_logits = server_model(client_outputs, training=True)  # 服务器模型前向传播\n",
    "        loss = loss_fn(y, server_logits)  # 计算损失\n",
    "\n",
    "    # 计算并应用服务器模型梯度\n",
    "    grads_server = tape_server.gradient(loss, server_model.trainable_variables)\n",
    "    optimizer_server.apply_gradients(zip(grads_server, server_model.trainable_variables))\n",
    "\n",
    "    # 计算并应用客户端模型梯度\n",
    "    grads_client = tape_client.gradient(loss, client_model.trainable_variables)\n",
    "    optimizer_client.apply_gradients(zip(grads_client, client_model.trainable_variables))\n",
    "\n",
    "    # 单独针对 client_model_1 的训练步骤\n",
    "    with tf.GradientTape() as tape_client_1:\n",
    "        client_outputs_1 = client_model_1(x, training=True)  # client_model_1 前向传播\n",
    "        server_logits_1 = server_model(client_outputs_1, training=False)  # 使用 server_model 进行前向传播但不更新\n",
    "        loss_1 = loss_fn(y, server_logits_1)  # 计算损失\n",
    "\n",
    "    # 计算并应用 client_model_1 的梯度\n",
    "    grads_client_1 = tape_client_1.gradient(loss_1, client_model_1.trainable_variables)\n",
    "    optimizer_client_1.apply_gradients(zip(grads_client_1, client_model_1.trainable_variables))\n",
    "\n",
    "    return loss, loss_1  # 返回两步训练的损失值\n",
    "\n",
    "# 注意：在实际使用中，确保已经正确初始化了所有模型（client_model, client_model_1, server_model）\n",
    "# 以及优化器（optimizer_client, optimizer_server, optimizer_client_1）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b72f292f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step_client(x, y):\n",
    "    # 使用客户端和服务器模型进行训练\n",
    "    with tf.GradientTape() as tape_client, tf.GradientTape() as tape_server:\n",
    "        # 客户端模型前向传播\n",
    "        client_outputs = client_model(x, training=True)\n",
    "        # 服务器模型前向传播\n",
    "        server_logits = server_model(client_outputs, training=True)\n",
    "        # 计算损失\n",
    "        loss = loss_fn(y, server_logits)\n",
    "    \n",
    "    # 计算并应用服务器模型梯度\n",
    "    grads_server = tape_server.gradient(loss, server_model.trainable_variables)\n",
    "    optimizer_server.apply_gradients(zip(grads_server, server_model.trainable_variables))\n",
    "    \n",
    "    # 计算并应用客户端模型梯度\n",
    "    grads_client = tape_client.gradient(loss, client_model.trainable_variables)\n",
    "    optimizer_client.apply_gradients(zip(grads_client, client_model.trainable_variables))\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ad3b62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step_client_1(x, y):\n",
    "    # 仅针对client_model_1的训练步骤\n",
    "    with tf.GradientTape() as tape_client_1:\n",
    "        # client_model_1前向传播\n",
    "        client_outputs_1 = client_model_1(x, training=True)\n",
    "        # 使用server_model进行前向传播但不更新\n",
    "        server_logits_1 = server_model(client_outputs_1, training=False)\n",
    "        # 计算损失\n",
    "        loss_1 = loss_fn(y, server_logits_1)\n",
    "\n",
    "    # 计算并应用client_model_1的梯度\n",
    "    grads_client_1 = tape_client_1.gradient(loss_1, client_model_1.trainable_variables)\n",
    "    optimizer_client_1.apply_gradients(zip(grads_client_1, client_model_1.trainable_variables))\n",
    "\n",
    "    return loss_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685dff32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20101741",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step_only_server(x, y):\n",
    "    with tf.GradientTape() as tape_server:\n",
    "        # 使用 client_model_1 进行前向传播，注意这里我们不更新 client_model_1\n",
    "        client_outputs_1 = client_model_1(x, training=False)  # 注意这里的 training=False\n",
    "        \n",
    "        # 使用 server_model 进行前向传播，准备更新这个模型\n",
    "        server_logits = server_model(client_outputs_1, training=True)\n",
    "        \n",
    "        # 计算损失\n",
    "        loss = loss_fn(y, server_logits)\n",
    "\n",
    "    # 计算服务器模型梯度并应用\n",
    "    grads_server = tape_server.gradient(loss, server_model.trainable_variables)\n",
    "    optimizer_server_2.apply_gradients(zip(grads_server, server_model.trainable_variables))\n",
    "\n",
    "    return loss  # 返回训练损失值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7109f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7801743e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be1ad8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def create_combined_model(client_model, server_model, compile_only=False):\n",
    "    # Getting the input of the client model\n",
    "    client_input = client_model.input\n",
    "    \n",
    "    # Getting the intermediate output by passing the input through the client model\n",
    "    client_output = client_model(client_input)\n",
    "    \n",
    "    # The client model's output is used as the input for the server model\n",
    "    server_output = server_model(client_output)\n",
    "    \n",
    "    # Defining a new model that chains the client and server models\n",
    "    combined_model = Model(inputs=client_input, outputs=server_output)\n",
    "    \n",
    "    # Compile the combined model\n",
    "    combined_model.compile(optimizer=Adam(),\n",
    "                           loss='categorical_crossentropy',\n",
    "                           metrics=['accuracy'])\n",
    "    \n",
    "    if not compile_only:\n",
    "        # If not compile_only, evaluate the model\n",
    "        loss, accuracy = combined_model.evaluate(x_test, y_test, verbose=0)\n",
    "        print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n",
    "    \n",
    "    return combined_model\n",
    "\n",
    "# Use the function to create and compile the combined model without evaluating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51dbd8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def change_batch(resblock_test_trigger, client_outputs, y):\n",
    "    # 使用tf.random.uniform生成0到2000之间的随机整数索引\n",
    "    random_integer = tf.random.uniform(shape=(), minval=0, maxval=2000, dtype=tf.int32)\n",
    "    # 从resblock_test_trigger中选择一个随机元素\n",
    "    selected_trigger = tf.gather(resblock_test_trigger, random_integer)\n",
    "    # 确保selected_trigger的形状与client_outputs中的元素兼容\n",
    "    selected_trigger = tf.expand_dims(selected_trigger, 0)  # 假设它是一个序列，需要扩展维度以兼容\n",
    "\n",
    "    # 更新client_outputs的第一个元素\n",
    "    client_outputs_updated = tf.concat([selected_trigger, client_outputs[1:]], axis=0)\n",
    "    \n",
    "    # 创建一个新标签\n",
    "    new_label = tf.constant([0, 1, 0, 0, 0, 0, 0, 0, 0, 0], dtype=y.dtype)\n",
    "    # 使用tf.tensor_scatter_nd_update更新y的第一个样本的标签\n",
    "    indices = tf.constant([[0]])  # 表示我们要更新第一个样本的标签\n",
    "    updated_y = tf.tensor_scatter_nd_update(y, indices, tf.expand_dims(new_label, 0))\n",
    "\n",
    "    return client_outputs_updated, updated_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df6b3795",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "# 定义训练步骤\n",
    "@tf.function\n",
    "def train_step_door(x, y,resblock_test_tigger):\n",
    "    with tf.GradientTape() as tape_client, tf.GradientTape() as tape_server:\n",
    "        # 客户端前向传播\n",
    "        client_outputs = client_model(x, training=True)\n",
    "        client_outputs_updated, updated_y = change_batch(resblock_test_tigger,client_outputs,y)\n",
    "        # 服务器前向传播      \n",
    "        server_logits = server_model(client_outputs_updated, training=True)\n",
    "        # 计算损失\n",
    "        loss = loss_fn(updated_y, server_logits)\n",
    "\n",
    "    # 计算服务器模型梯度\n",
    "    grads_server = tape_server.gradient(loss, server_model.trainable_variables)\n",
    "    # 更新服务器模型权重\n",
    "    optimizer_server.apply_gradients(zip(grads_server, server_model.trainable_variables))\n",
    "\n",
    "    # 计算客户端模型梯度（模拟反向传播）\n",
    "    grads_client = tape_client.gradient(loss, client_model.trainable_variables)\n",
    "    # 更新客户端模型权重\n",
    "    optimizer_client1.apply_gradients(zip(grads_client, client_model.trainable_variables))\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7350b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_client = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "optimizer_client1 = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "###这两个都是客户端的优化梯度\n",
    "\n",
    "optimizer_server = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "##optimizer_server 和 这两个都是客户端的优化梯度的梯度要一模一样\n",
    "\n",
    "optimizer_client_1 = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "\n",
    "optimizer_server_2 = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57bcec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "def augment(image, label):\n",
    "    # 随机水平翻转图像\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    # 随机调整亮度\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    # 确保图像值仍然在0到1的范围内\n",
    "    image = tf.clip_by_value(image, 0.0, 1.0)\n",
    "    return image, label\n",
    "\n",
    "# 假设x_train, y_train, x_val, y_val, x_val_tigger, y_val_tigger已经定义并准备好了\n",
    "\n",
    "# 训练数据集 - 应用数据增强\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.map(augment).shuffle(len(x_train)).batch(batch_size)\n",
    "\n",
    "# 客户端验证数据集 - 也应用数据增强\n",
    "client_1_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "client_1_dataset = client_1_dataset.map(augment).shuffle(len(x_val)).batch(batch_size)\n",
    "\n",
    "# 服务器训练数据集 - 也应用数据增强\n",
    "server_train_dataset = tf.data.Dataset.from_tensor_slices((x_val_tigger, y_val_tigger))\n",
    "server_train_dataset = server_train_dataset.map(augment).shuffle(len(x_val_tigger)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a8bb8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-24 00:48:44.802877: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session started.\n",
      "2024-07-24 00:48:44.803008: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1391] Profiler found 1 GPUs\n",
      "2024-07-24 00:48:44.806577: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcupti.so.10.1\n",
      "2024-07-24 00:48:44.818270: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1441] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_INSUFFICIENT_PRIVILEGES\n",
      "2024-07-24 00:49:01.929208: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2024-07-24 00:49:02.926654: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-07-24 00:49:08.438366: W tensorflow/stream_executor/gpu/asm_compiler.cc:81] Running ptxas --version returned 256\n",
      "2024-07-24 00:49:08.957897: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Client Model Loss: 1.3839\n",
      "  Client Model 1 Loss: 1.2017\n",
      "  Client Model Loss: 0.8648\n",
      "  Client Model 1 Loss: 1.0033\n",
      "  Client Model Loss: 0.6221\n",
      "  Client Model 1 Loss: 0.6128\n",
      "  Client Model Loss: 0.7448\n",
      "  Client Model 1 Loss: 0.3605\n",
      "  Client Model Loss: 0.7775\n",
      "  Client Model 1 Loss: 0.7377\n",
      "  Client Model Loss: 0.7355\n",
      "  Client Model 1 Loss: 0.5727\n",
      "  Client Model Loss: 0.2585\n",
      "  Client Model 1 Loss: 0.5350\n",
      "  Client Model Loss: 0.1186\n",
      "  Client Model 1 Loss: 0.3838\n",
      "  Client Model Loss: 0.1514\n",
      "  Client Model 1 Loss: 0.4084\n",
      "  Client Model Loss: 0.2346\n",
      "  Client Model 1 Loss: 0.5822\n",
      "  Client Model Loss: 0.1939\n",
      "  Client Model 1 Loss: 0.1817\n",
      "  Client Model Loss: 0.2943\n",
      "  Client Model 1 Loss: 0.4392\n",
      "  Client Model Loss: 0.4249\n",
      "  Client Model 1 Loss: 0.0945\n",
      "  Client Model Loss: 0.0219\n",
      "  Client Model 1 Loss: 0.3214\n",
      "  Client Model Loss: 0.2736\n",
      "  Client Model 1 Loss: 0.2150\n",
      "  Client Model Loss: 0.0877\n",
      "  Client Model 1 Loss: 0.6436\n",
      "  Client Model Loss: 0.0423\n",
      "  Client Model 1 Loss: 0.3461\n",
      "  Client Model Loss: 0.1077\n",
      "  Client Model 1 Loss: 0.8039\n",
      "  Client Model Loss: 0.0486\n",
      "  Client Model 1 Loss: 0.6756\n",
      "  Client Model Loss: 0.0235\n",
      "  Client Model 1 Loss: 0.7496\n",
      "  Client Model Loss: 0.0519\n",
      "  Client Model 1 Loss: 0.3300\n",
      "  Client Model Loss: 0.0224\n",
      "  Client Model 1 Loss: 0.2534\n",
      "  Client Model Loss: 0.0138\n",
      "  Client Model 1 Loss: 0.5792\n",
      "  Client Model Loss: 0.0113\n",
      "  Client Model 1 Loss: 0.0506\n",
      "  Client Model Loss: 0.0893\n",
      "  Client Model 1 Loss: 0.2098\n",
      "  Client Model Loss: 0.0320\n",
      "  Client Model 1 Loss: 0.4063\n",
      "  Client Model Loss: 0.0424\n",
      "  Client Model 1 Loss: 0.5012\n",
      "  Client Model Loss: 0.0505\n",
      "  Client Model 1 Loss: 0.1960\n",
      "  Client Model Loss: 0.0134\n",
      "  Client Model 1 Loss: 0.2437\n",
      "  Client Model Loss: 0.0706\n",
      "  Client Model 1 Loss: 0.1951\n",
      "  Client Model Loss: 0.0130\n",
      "  Client Model 1 Loss: 0.3082\n",
      "  Client Model Loss: 0.0043\n",
      "  Client Model 1 Loss: 0.7254\n",
      "  Client Model Loss: 0.0014\n",
      "  Client Model 1 Loss: 0.3002\n",
      "  Client Model Loss: 0.0107\n",
      "  Client Model 1 Loss: 0.5590\n",
      "  Client Model Loss: 0.0002\n",
      "  Client Model 1 Loss: 0.3324\n",
      "  Client Model Loss: 0.0019\n",
      "  Client Model 1 Loss: 0.6616\n",
      "  Client Model Loss: 0.0015\n",
      "  Client Model 1 Loss: 1.0963\n",
      "  Client Model Loss: 0.0078\n",
      "  Client Model 1 Loss: 0.3398\n",
      "  Client Model Loss: 0.0399\n",
      "  Client Model 1 Loss: 0.1343\n",
      "  Client Model Loss: 0.0093\n",
      "  Client Model 1 Loss: 0.1462\n",
      "  Client Model Loss: 0.0026\n",
      "  Client Model 1 Loss: 0.2140\n",
      "  Client Model Loss: 0.0287\n",
      "  Client Model 1 Loss: 0.7696\n",
      "  Client Model Loss: 0.0105\n",
      "  Client Model 1 Loss: 0.0102\n",
      "  Client Model Loss: 0.0006\n",
      "  Client Model 1 Loss: 0.2778\n",
      "  Client Model Loss: 0.0006\n",
      "  Client Model 1 Loss: 0.9069\n",
      "  Client Model Loss: 0.0337\n",
      "  Client Model 1 Loss: 0.2062\n",
      "  Client Model Loss: 0.0011\n",
      "  Client Model 1 Loss: 0.8863\n",
      "  Client Model Loss: 0.0002\n",
      "  Client Model 1 Loss: 0.2742\n",
      "  Client Model Loss: 0.0042\n",
      "  Client Model 1 Loss: 0.6874\n",
      "  Client Model Loss: 0.0011\n",
      "  Client Model 1 Loss: 0.1782\n",
      "  Client Model Loss: 0.0004\n",
      "  Client Model 1 Loss: 0.5175\n",
      "  Client Model Loss: 0.0019\n",
      "  Client Model 1 Loss: 0.8236\n",
      "  Client Model Loss: 0.0112\n",
      "  Client Model 1 Loss: 0.2343\n",
      "  Client Model Loss: 0.0003\n",
      "  Client Model 1 Loss: 0.0760\n",
      "  Client Model Loss: 0.1195\n",
      "  Client Model 1 Loss: 0.3534\n"
     ]
    }
   ],
   "source": [
    "# 初始化TensorBoard回调\n",
    "import datetime\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "epochs = 60\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "combined_model = create_combined_model(client_model, server_model, compile_only=True)\n",
    "combined_model_1 = create_combined_model(client_model_1, server_model, compile_only=True)\n",
    "\n",
    "\n",
    "epoch_losses = []\n",
    "epoch_accuracies = []\n",
    "\n",
    "\n",
    "epoch_losses_1 = []\n",
    "epoch_accuracies_1 = []\n",
    "\n",
    "\n",
    "epoch_losses_2= []\n",
    "epoch_accuracies_2 = []\n",
    "\n",
    "\n",
    "epoch_losses_3= []\n",
    "epoch_accuracies_3 = []\n",
    "# 开始训练\n",
    "\n",
    "epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "epoch_loss_avg_server = tf.keras.metrics.Mean()\n",
    "\n",
    "#先训练\n",
    "\n",
    "for epoch in range(55):\n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    epoch_loss_avg_server = tf.keras.metrics.Mean()\n",
    "    for x_batch, y_batch in train_dataset:\n",
    "        loss = train_step_client(x_batch, y_batch)\n",
    "    print(f\"  Client Model Loss: {loss.numpy():.4f}\")\n",
    "\n",
    "    for x_batch, y_batch in client_1_dataset:   ##只修改这部分\n",
    "        loss_1 = train_step_client_1(x_batch, y_batch)\n",
    "    print(f\"  Client Model 1 Loss: {loss_1.numpy():.4f}\")\n",
    "\n",
    "    loss, accuracy = combined_model.evaluate(x_test, y_test, verbose=0)\n",
    "    epoch_losses.append(loss)\n",
    "    epoch_accuracies.append(accuracy)\n",
    "    \n",
    "    loss, accuracy = combined_model_1.evaluate(x_test, y_test, verbose=0)\n",
    "    epoch_losses_1.append(loss)\n",
    "    epoch_accuracies_1.append(accuracy)\n",
    "    \n",
    "    loss, accuracy = combined_model.evaluate(x_test_tigger, y_test_tigger, verbose=0)\n",
    "    epoch_losses_2.append(loss)\n",
    "    epoch_accuracies_2.append(accuracy)\n",
    "    \n",
    "    loss, accuracy = combined_model_1.evaluate(x_test_tigger, y_test_tigger, verbose=0)\n",
    "    epoch_losses_3.append(loss)\n",
    "    epoch_accuracies_3.append(accuracy)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a9a67c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ec6b59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50e2da1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f90d95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# 假设client_model和server_model的输入和输出层已经定义\n",
    "\n",
    "# 获取客户端模型的输入\n",
    "client_input = client_model.input\n",
    "\n",
    "# 通过客户端模型获取中间输出\n",
    "client_output = client_model(client_input)\n",
    "\n",
    "# 将客户端的输出作为服务器模型的输入\n",
    "server_output = server_model(client_output)\n",
    "\n",
    "# 定义一个新的模型，该模型连接了客户端和服务器模型\n",
    "combined_model = Model(inputs=client_input, outputs=server_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35a2a676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 0.7985 - accuracy: 0.8552\n",
      "Test loss: 0.7985342741012573, Test accuracy: 0.8551999926567078\n"
     ]
    }
   ],
   "source": [
    "combined_model.compile(optimizer='adam',\n",
    "                       loss='categorical_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# 假设x_test和y_test已经准备好\n",
    "loss, accuracy = combined_model.evaluate(x_test, y_test)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d5f2d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0570 - accuracy: 0.9874\n",
      "Test loss: 0.057005126029253006, Test accuracy: 0.9873999953269958\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model.evaluate(x_test_tigger, y_test_tigger)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "632ee1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# 假设client_model和server_model的输入和输出层已经定义\n",
    "\n",
    "# 获取客户端模型的输入\n",
    "client_input_1 = client_model_1.input\n",
    "\n",
    "# 通过客户端模型获取中间输出\n",
    "client_output_1 = client_model_1(client_input_1)\n",
    "\n",
    "# 将客户端的输出作为服务器模型的输入\n",
    "server_output_1 = server_model(client_output_1)\n",
    "\n",
    "# 定义一个新的模型，该模型连接了客户端和服务器模型\n",
    "combined_model_1 = Model(inputs=client_input_1, outputs=server_output_1)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "404f31ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 0.7639 - accuracy: 0.8165\n",
      "Test loss: 0.7638763189315796, Test accuracy: 0.8165000081062317\n"
     ]
    }
   ],
   "source": [
    "combined_model_1.compile(optimizer='adam',\n",
    "                       loss='categorical_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# 假设x_test和y_test已经准备好\n",
    "loss, accuracy = combined_model_1.evaluate(x_test, y_test)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a3e327d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1785 - accuracy: 0.9495\n",
      "Test loss: 0.1784796416759491, Test accuracy: 0.9495000243186951\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model_1.evaluate(x_test_tigger, y_test_tigger)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdff9c03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f901f464",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22b0ad6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2e29b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#313/313 [==============================] - 1s 3ms/step - loss: 0.9457 - accuracy: 0.7466\n",
    "#Test loss: 0.9456651210784912, Test accuracy: 0.7465999722480774\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa2dcfee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Cosine Similarity: 0.5377103686332703\n",
      "Average Euclidean Distance: 262.5919490432739\n"
     ]
    }
   ],
   "source": [
    "# 获取两个模型的特征表示\n",
    "features_client_model_1 = client_model_1.predict(x_test)\n",
    "features_client_model = client_model.predict(x_test)\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# 计算余弦相似度\n",
    "cosine_sim = cosine_similarity(features_client_model_1.reshape(features_client_model_1.shape[0], -1),\n",
    "                               features_client_model.reshape(features_client_model.shape[0], -1))\n",
    "\n",
    "# 余弦相似度矩阵的对角线元素表示同一个x_test样本在两个模型特征空间中的相似度\n",
    "cosine_sim_diag = np.diag(cosine_sim)\n",
    "\n",
    "# 计算平均余弦相似度\n",
    "average_cosine_sim = np.mean(cosine_sim_diag)\n",
    "print(f\"Average Cosine Similarity: {average_cosine_sim}\")\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\n",
    "# 将特征向量展平\n",
    "features_client_model_1_flat = features_client_model_1.reshape(features_client_model_1.shape[0], -1)\n",
    "features_client_model_flat = features_client_model.reshape(features_client_model.shape[0], -1)\n",
    "\n",
    "# 计算欧几里得距离\n",
    "euclidean_dists = np.array([distance.euclidean(features_client_model_1_flat[i], features_client_model_flat[i]) \n",
    "                            for i in range(features_client_model_1_flat.shape[0])])\n",
    "\n",
    "# 计算平均欧几里得距离\n",
    "average_euclidean_dist = np.mean(euclidean_dists)\n",
    "print(f\"Average Euclidean Distance: {average_euclidean_dist}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e4fb7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_model_1.save('client_model_1.h5')\n",
    "server_model.save('server_model.h5')\n",
    "client_model.save('client_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e1ac7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63fb47e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79f404e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bfd4ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459d88df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeb92a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a23666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb89634e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c651fad6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02cd09b6",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
