{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8be868e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-08 11:26:45.728306: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input, GlobalAveragePooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2'\n",
    "# 加载 CIFAR-10 数据\n",
    "import random\n",
    "import numpy as np\n",
    "# Load and preprocess CIFAR-10 data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8909e847",
   "metadata": {},
   "outputs": [],
   "source": [
    "##该模型并没有使用双重对齐，因为我使用的数据错了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63646c24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91423d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load and preprocess CIFAR-10 data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "\n",
    "def add_trigger(img):\n",
    "    trigger_size = 4\n",
    "    img[-trigger_size:, -trigger_size:, 0] = 1 # 设置为红色\n",
    "    img[-trigger_size:, -trigger_size:, 1:3] = 1\n",
    "    return img\n",
    "\n",
    "target_class = 1  # 目标类别\n",
    "num_classes = 10  # CIFAR-10 数据集的类别数\n",
    "\n",
    "# 新的数据集和标签列表\n",
    "x_val_triggered = []  # 存储触发器转换后的图像\n",
    "y_val_triggered = []  # 存储更新后的标签\n",
    "\n",
    "x_val_tigger = x_val.copy()\n",
    "y_val_tigger = y_val.copy()\n",
    "\n",
    "# 应用攻击到选中的图像\n",
    "for i in range(len(x_val_tigger)):\n",
    "    x_val_tigger[i] = add_trigger(x_val_tigger[i])\n",
    "    y_val_tigger[i] = to_categorical(target_class, num_classes=num_classes)\n",
    "    x_val_triggered.append(x_val_tigger[i])\n",
    "    y_val_triggered.append(to_categorical(target_class, num_classes=num_classes))\n",
    "    \n",
    "# 将列表转换为NumPy数组（如果需要）\n",
    "x_val_triggered = np.array(x_val_triggered)\n",
    "y_val_triggered = np.array(y_val_triggered)\n",
    "            \n",
    "    \n",
    "x_test_tigger = x_test.copy()\n",
    "y_test_tigger = y_test.copy()\n",
    "\n",
    "for i in range(len(x_test_tigger)):\n",
    "    x_test_tigger[i] = add_trigger(x_test_tigger[i])\n",
    "    y_test_tigger[i] = to_categorical(target_class, num_classes=num_classes)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "500c61c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_test_tigger[0])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81ef1c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "##进行攻击的思路\n",
    "#1.将数据集分成两部分  8比2吧\n",
    "#2.每个epcoch后再单独优化一下服务器模型，保持模拟的客户端模型不变，后门数据要多一些\n",
    "#3.验证数据集结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dedc2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "\n",
    "\n",
    "def create_client_model(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # 第一层卷积\n",
    "    x = layers.Conv2D(32, 3, strides=1, padding='same')(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # 第二层卷积\n",
    "    x = layers.Conv2D(64, 3, strides=1, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # 新增的第三层卷积\n",
    "    x = layers.Conv2D(128, 3, strides=1, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47748639",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def res_block(filters, strides):\n",
    "    def block(x):\n",
    "        shortcut = x\n",
    "\n",
    "        x = layers.Conv2D(filters, 3, padding='same', strides=strides)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation('relu')(x)\n",
    "\n",
    "        x = layers.Conv2D(filters, 3, padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        # 捷径连接前的调整\n",
    "        shortcut = layers.Conv2D(filters, 1, strides=strides, padding='same')(shortcut)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "        x = layers.add([x, shortcut])\n",
    "        x = layers.Activation('relu')(x)\n",
    "        return x\n",
    "    return block\n",
    "\n",
    "def create_server_model():\n",
    "    # 调整输入层的定义以匹配修改后的客户端模型的输出\n",
    "    input_layer = layers.Input(shape=(32, 32, 128))  # 注意这里的变化\n",
    "\n",
    "    # 残差块定义保持不变，继续使用提前定义的 res_block\n",
    "    x = res_block(128, 1)(input_layer)  # 使用第一个残差块\n",
    "    x = res_block(128, 2)(x)            # 使用第二个残差块\n",
    "    x = res_block(128, 2)(x)           # 使用第三个残差块\n",
    "    x = res_block(256, 2)(x)           # 使用第四个残差块\n",
    "\n",
    "    # 全局平均池化和输出层保持不变\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    output = layers.Dense(10, activation='softmax')(x)\n",
    "    \n",
    "    model = models.Model(inputs=input_layer, outputs=output)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7affb4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-08 11:26:55.786247: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2024-07-08 11:26:55.817327: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:af:00.0 name: NVIDIA Tesla V100-PCIE-16GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2024-07-08 11:26:55.817386: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-07-08 11:26:55.820639: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2024-07-08 11:26:55.823790: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2024-07-08 11:26:55.824265: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2024-07-08 11:26:55.827505: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-07-08 11:26:55.828817: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2024-07-08 11:26:55.835146: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-07-08 11:26:55.836920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2024-07-08 11:26:55.837732: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-08 11:26:55.854093: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 1700000000 Hz\n",
      "2024-07-08 11:26:55.858487: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55cd0d2d7240 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-08 11:26:55.858560: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2024-07-08 11:26:56.104763: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55cd0d2d9f50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-08 11:26:56.104860: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA Tesla V100-PCIE-16GB, Compute Capability 7.0\n",
      "2024-07-08 11:26:56.107129: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:af:00.0 name: NVIDIA Tesla V100-PCIE-16GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2024-07-08 11:26:56.107223: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-07-08 11:26:56.107301: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2024-07-08 11:26:56.107347: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2024-07-08 11:26:56.107390: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2024-07-08 11:26:56.107433: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-07-08 11:26:56.107474: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2024-07-08 11:26:56.107518: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-07-08 11:26:56.110466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2024-07-08 11:26:56.110561: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-07-08 11:26:56.923875: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-07-08 11:26:56.923948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
      "2024-07-08 11:26:56.923963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
      "2024-07-08 11:26:56.925930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 64 MB memory) -> physical GPU (device: 0, name: NVIDIA Tesla V100-PCIE-16GB, pci bus id: 0000:af:00.0, compute capability: 7.0)\n",
      "2024-07-08 11:26:56.934059: I tensorflow/stream_executor/cuda/cuda_driver.cc:775] failed to allocate 64.50M (67633152 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    }
   ],
   "source": [
    "# 创建客户端模型\n",
    "client_model = create_client_model(input_shape=(32, 32, 3))\n",
    "\n",
    "# 编译客户端模型\n",
    "client_model.compile(optimizer=Adam(),\n",
    "                     loss='categorical_crossentropy',\n",
    "                     metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f40daf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 128)       0         \n",
      "=================================================================\n",
      "Total params: 94,144\n",
      "Trainable params: 93,696\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "client_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24b851ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下是服务器模型训练的简化示例\n",
    "server_model = create_server_model()\n",
    "server_model.compile(optimizer=Adam(),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b1305b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##创建三个影子模型，分别是1层卷积，2层卷积核3层卷积\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "672b621e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_client_model_1(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same')(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_client_model_2(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same')(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n",
    "def create_client_model_3(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same')(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n",
    "def create_client_model_4(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same')(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n",
    "\n",
    "def create_client_model_5(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # 第一层卷积\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same')(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # 第二层卷积\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # 第三层卷积\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # 第四层卷积\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # 第五层卷积\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e440493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 32, 32, 128)       0         \n",
      "=================================================================\n",
      "Total params: 94,144\n",
      "Trainable params: 93,696\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Assuming TensorFlow is installed and the functions are defined in your script\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "client_model_1 = create_client_model_3(input_shape=(32, 32, 3))\n",
    "\n",
    "\n",
    "# You can then print the model summaries to verify their structures\n",
    "print(client_model_1.summary())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c555f15d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244dd4ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcb36d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "# 定义训练步骤\n",
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape_client, tf.GradientTape() as tape_server:\n",
    "        # 客户端前向传播\n",
    "        client_outputs = client_model(x, training=True)\n",
    "        # 服务器前向传播      \n",
    "        server_logits = server_model(client_outputs, training=True)\n",
    "        # 计算损失\n",
    "        loss = loss_fn(y, server_logits)\n",
    "\n",
    "    # 计算服务器模型梯度\n",
    "    grads_server = tape_server.gradient(loss, server_model.trainable_variables)\n",
    "    # 更新服务器模型权重\n",
    "    optimizer_server.apply_gradients(zip(grads_server, server_model.trainable_variables))\n",
    "\n",
    "    # 计算客户端模型梯度（模拟反向传播）\n",
    "    grads_client = tape_client.gradient(loss, client_model.trainable_variables)\n",
    "    # 更新客户端模型权重\n",
    "    optimizer_client.apply_gradients(zip(grads_client, client_model.trainable_variables))\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "286c6e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 假设 optimizer_client 和 optimizer_server 已经被定义\n",
    "optimizer_client_1 = tf.keras.optimizers.Adam()  # 为 client_model_1 定义一个新的优化器\n",
    "\n",
    "@tf.function\n",
    "def train_step_2(x, y):\n",
    "    # 首次使用客户端和服务器模型进行训练\n",
    "    with tf.GradientTape() as tape_client, tf.GradientTape() as tape_server:\n",
    "        client_outputs = client_model(x, training=True)  # 客户端模型前向传播\n",
    "        server_logits = server_model(client_outputs, training=True)  # 服务器模型前向传播\n",
    "        loss = loss_fn(y, server_logits)  # 计算损失\n",
    "\n",
    "    # 计算并应用服务器模型梯度\n",
    "    grads_server = tape_server.gradient(loss, server_model.trainable_variables)\n",
    "    optimizer_server.apply_gradients(zip(grads_server, server_model.trainable_variables))\n",
    "\n",
    "    # 计算并应用客户端模型梯度\n",
    "    grads_client = tape_client.gradient(loss, client_model.trainable_variables)\n",
    "    optimizer_client.apply_gradients(zip(grads_client, client_model.trainable_variables))\n",
    "\n",
    "    # 单独针对 client_model_1 的训练步骤\n",
    "    with tf.GradientTape() as tape_client_1:\n",
    "        client_outputs_1 = client_model_1(x, training=True)  # client_model_1 前向传播\n",
    "        server_logits_1 = server_model(client_outputs_1, training=False)  # 使用 server_model 进行前向传播但不更新\n",
    "        loss_1 = loss_fn(y, server_logits_1)  # 计算损失\n",
    "\n",
    "    # 计算并应用 client_model_1 的梯度\n",
    "    grads_client_1 = tape_client_1.gradient(loss_1, client_model_1.trainable_variables)\n",
    "    optimizer_client_1.apply_gradients(zip(grads_client_1, client_model_1.trainable_variables))\n",
    "\n",
    "    return loss, loss_1  # 返回两步训练的损失值\n",
    "\n",
    "# 注意：在实际使用中，确保已经正确初始化了所有模型（client_model, client_model_1, server_model）\n",
    "# 以及优化器（optimizer_client, optimizer_server, optimizer_client_1）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c03db8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step_client(x, y):\n",
    "    # 使用客户端和服务器模型进行训练\n",
    "    with tf.GradientTape() as tape_client, tf.GradientTape() as tape_server:\n",
    "        # 客户端模型前向传播\n",
    "        client_outputs = client_model(x, training=True)\n",
    "        # 服务器模型前向传播\n",
    "        server_logits = server_model(client_outputs, training=True)\n",
    "        # 计算损失\n",
    "        loss = loss_fn(y, server_logits)\n",
    "    \n",
    "    # 计算并应用服务器模型梯度\n",
    "    grads_server = tape_server.gradient(loss, server_model.trainable_variables)\n",
    "    optimizer_server.apply_gradients(zip(grads_server, server_model.trainable_variables))\n",
    "    \n",
    "    # 计算并应用客户端模型梯度\n",
    "    grads_client = tape_client.gradient(loss, client_model.trainable_variables)\n",
    "    optimizer_client.apply_gradients(zip(grads_client, client_model.trainable_variables))\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19af9841",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step_client_1(x, y):\n",
    "    # 仅针对client_model_1的训练步骤\n",
    "    with tf.GradientTape() as tape_client_1:\n",
    "        # client_model_1前向传播\n",
    "        client_outputs_1 = client_model_1(x, training=True)\n",
    "        # 使用server_model进行前向传播但不更新\n",
    "        server_logits_1 = server_model(client_outputs_1, training=False)\n",
    "        # 计算损失\n",
    "        loss_1 = loss_fn(y, server_logits_1)\n",
    "\n",
    "    # 计算并应用client_model_1的梯度\n",
    "    grads_client_1 = tape_client_1.gradient(loss_1, client_model_1.trainable_variables)\n",
    "    optimizer_client_1.apply_gradients(zip(grads_client_1, client_model_1.trainable_variables))\n",
    "\n",
    "    return loss_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf99ecf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "654441c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step_only_server(x, y):\n",
    "    with tf.GradientTape() as tape_server:\n",
    "        # 使用 client_model_1 进行前向传播，注意这里我们不更新 client_model_1\n",
    "        client_outputs_1 = client_model_1(x, training=False)  # 注意这里的 training=False\n",
    "        \n",
    "        # 使用 server_model 进行前向传播，准备更新这个模型\n",
    "        server_logits = server_model(client_outputs_1, training=True)\n",
    "        \n",
    "        # 计算损失\n",
    "        loss = loss_fn(y, server_logits)\n",
    "\n",
    "    # 计算服务器模型梯度并应用\n",
    "    grads_server = tape_server.gradient(loss, server_model.trainable_variables)\n",
    "    optimizer_server_2.apply_gradients(zip(grads_server, server_model.trainable_variables))\n",
    "\n",
    "    return loss  # 返回训练损失值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be47e86c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43931767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9d02ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def create_combined_model(client_model, server_model, compile_only=False):\n",
    "    # Getting the input of the client model\n",
    "    client_input = client_model.input\n",
    "    \n",
    "    # Getting the intermediate output by passing the input through the client model\n",
    "    client_output = client_model(client_input)\n",
    "    \n",
    "    # The client model's output is used as the input for the server model\n",
    "    server_output = server_model(client_output)\n",
    "    \n",
    "    # Defining a new model that chains the client and server models\n",
    "    combined_model = Model(inputs=client_input, outputs=server_output)\n",
    "    \n",
    "    # Compile the combined model\n",
    "    combined_model.compile(optimizer=Adam(),\n",
    "                           loss='categorical_crossentropy',\n",
    "                           metrics=['accuracy'])\n",
    "    \n",
    "    if not compile_only:\n",
    "        # If not compile_only, evaluate the model\n",
    "        loss, accuracy = combined_model.evaluate(x_test, y_test, verbose=0)\n",
    "        print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n",
    "    \n",
    "    return combined_model\n",
    "\n",
    "# Use the function to create and compile the combined model without evaluating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f455f595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def change_batch(resblock_test_trigger, client_outputs, y):\n",
    "    # 使用tf.random.uniform生成0到2000之间的随机整数索引\n",
    "    random_integer = tf.random.uniform(shape=(), minval=0, maxval=2000, dtype=tf.int32)\n",
    "    # 从resblock_test_trigger中选择一个随机元素\n",
    "    selected_trigger = tf.gather(resblock_test_trigger, random_integer)\n",
    "    # 确保selected_trigger的形状与client_outputs中的元素兼容\n",
    "    selected_trigger = tf.expand_dims(selected_trigger, 0)  # 假设它是一个序列，需要扩展维度以兼容\n",
    "\n",
    "    # 更新client_outputs的第一个元素\n",
    "    client_outputs_updated = tf.concat([selected_trigger, client_outputs[1:]], axis=0)\n",
    "    \n",
    "    # 创建一个新标签\n",
    "    new_label = tf.constant([0, 1, 0, 0, 0, 0, 0, 0, 0, 0], dtype=y.dtype)\n",
    "    # 使用tf.tensor_scatter_nd_update更新y的第一个样本的标签\n",
    "    indices = tf.constant([[0]])  # 表示我们要更新第一个样本的标签\n",
    "    updated_y = tf.tensor_scatter_nd_update(y, indices, tf.expand_dims(new_label, 0))\n",
    "\n",
    "    return client_outputs_updated, updated_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8300c1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "# 定义训练步骤\n",
    "@tf.function\n",
    "def train_step_door(x, y,resblock_test_tigger):\n",
    "    with tf.GradientTape() as tape_client, tf.GradientTape() as tape_server:\n",
    "        # 客户端前向传播\n",
    "        client_outputs = client_model(x, training=True)\n",
    "        client_outputs_updated, updated_y = change_batch(resblock_test_tigger,client_outputs,y)\n",
    "        # 服务器前向传播      \n",
    "        server_logits = server_model(client_outputs_updated, training=True)\n",
    "        # 计算损失\n",
    "        loss = loss_fn(updated_y, server_logits)\n",
    "\n",
    "    # 计算服务器模型梯度\n",
    "    grads_server = tape_server.gradient(loss, server_model.trainable_variables)\n",
    "    # 更新服务器模型权重\n",
    "    optimizer_server.apply_gradients(zip(grads_server, server_model.trainable_variables))\n",
    "\n",
    "    # 计算客户端模型梯度（模拟反向传播）\n",
    "    grads_client = tape_client.gradient(loss, client_model.trainable_variables)\n",
    "    # 更新客户端模型权重\n",
    "    optimizer_client1.apply_gradients(zip(grads_client, client_model.trainable_variables))\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7590f478",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_client = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "optimizer_client1 = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "###这两个都是客户端的优化梯度\n",
    "\n",
    "optimizer_server = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "##optimizer_server 和 这两个都是客户端的优化梯度的梯度要一模一样\n",
    "\n",
    "optimizer_client_1 = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "\n",
    "optimizer_server_2 = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7108c2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "def augment(image, label):\n",
    "    # 随机水平翻转图像\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    # 随机调整亮度\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    # 确保图像值仍然在0到1的范围内\n",
    "    image = tf.clip_by_value(image, 0.0, 1.0)\n",
    "    return image, label\n",
    "\n",
    "# 假设x_train, y_train, x_val, y_val, x_val_tigger, y_val_tigger已经定义并准备好了\n",
    "\n",
    "# 训练数据集 - 应用数据增强\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.map(augment).shuffle(len(x_train)).batch(batch_size)\n",
    "\n",
    "# 客户端验证数据集 - 也应用数据增强\n",
    "client_1_dataset = tf.data.Dataset.from_tensor_slices((x_val[2000:10000], y_val[2000:10000]))\n",
    "client_1_dataset = client_1_dataset.map(augment).shuffle(len(x_val[2000:10000])).batch(batch_size)\n",
    "\n",
    "# 服务器训练数据集 - 也应用数据增强\n",
    "server_train_dataset = tf.data.Dataset.from_tensor_slices((x_val_tigger, y_val_tigger))\n",
    "server_train_dataset = server_train_dataset.map(augment).shuffle(len(x_val_tigger)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41869d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-08 11:26:59.909074: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session started.\n",
      "2024-07-08 11:26:59.909175: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1391] Profiler found 1 GPUs\n",
      "2024-07-08 11:26:59.911475: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcupti.so.10.1\n",
      "2024-07-08 11:27:00.012397: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1441] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_INSUFFICIENT_PRIVILEGES\n",
      "2024-07-08 11:27:08.961307: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2024-07-08 11:27:08.978367: E tensorflow/stream_executor/cuda/cuda_blas.cc:225] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\n",
      "2024-07-08 11:27:08.982934: E tensorflow/stream_executor/cuda/cuda_blas.cc:225] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\n",
      "2024-07-08 11:27:08.986322: E tensorflow/stream_executor/cuda/cuda_blas.cc:225] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\n",
      "2024-07-08 11:27:08.991108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-07-08 11:27:09.003916: E tensorflow/stream_executor/cuda/cuda_dnn.cc:328] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2024-07-08 11:27:09.010085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:328] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": " Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node functional_1/conv2d/Conv2D (defined at tmp/ipykernel_167688/1148688569.py:6) ]] [Op:__inference_train_step_client_6316]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node functional_1/conv2d/Conv2D:\n x (defined at tmp/ipykernel_167688/2013424674.py:39)\n\nFunction call stack:\ntrain_step_client\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_167688/2013424674.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mepoch_loss_avg_server\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  Client Model Loss: {loss.numpy():.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/keras2/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node functional_1/conv2d/Conv2D (defined at tmp/ipykernel_167688/1148688569.py:6) ]] [Op:__inference_train_step_client_6316]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node functional_1/conv2d/Conv2D:\n x (defined at tmp/ipykernel_167688/2013424674.py:39)\n\nFunction call stack:\ntrain_step_client\n"
     ]
    }
   ],
   "source": [
    "# 初始化TensorBoard回调\n",
    "import datetime\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "epochs = 60\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "combined_model = create_combined_model(client_model, server_model, compile_only=True)\n",
    "combined_model_1 = create_combined_model(client_model_1, server_model, compile_only=True)\n",
    "\n",
    "\n",
    "epoch_losses = []\n",
    "epoch_accuracies = []\n",
    "\n",
    "\n",
    "epoch_losses_1 = []\n",
    "epoch_accuracies_1 = []\n",
    "\n",
    "\n",
    "epoch_losses_2= []\n",
    "epoch_accuracies_2 = []\n",
    "\n",
    "\n",
    "epoch_losses_3= []\n",
    "epoch_accuracies_3 = []\n",
    "# 开始训练\n",
    "\n",
    "epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "epoch_loss_avg_server = tf.keras.metrics.Mean()\n",
    "\n",
    "#先训练\n",
    "\n",
    "for epoch in range(5):\n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    epoch_loss_avg_server = tf.keras.metrics.Mean()\n",
    "    for x_batch, y_batch in train_dataset:\n",
    "        loss = train_step_client(x_batch, y_batch)\n",
    "    print(f\"  Client Model Loss: {loss.numpy():.4f}\")\n",
    "\n",
    "    for x_batch, y_batch in client_1_dataset:   ##只修改这部分\n",
    "        loss_1 = train_step_client_1(x_batch, y_batch)\n",
    "    print(f\"  Client Model 1 Loss: {loss_1.numpy():.4f}\")\n",
    "\n",
    "    loss, accuracy = combined_model.evaluate(x_test, y_test, verbose=0)\n",
    "    epoch_losses.append(loss)\n",
    "    epoch_accuracies.append(accuracy)\n",
    "    \n",
    "    loss, accuracy = combined_model_1.evaluate(x_test, y_test, verbose=0)\n",
    "    epoch_losses_1.append(loss)\n",
    "    epoch_accuracies_1.append(accuracy)\n",
    "    \n",
    "    loss, accuracy = combined_model.evaluate(x_test_tigger, y_test_tigger, verbose=0)\n",
    "    epoch_losses_2.append(loss)\n",
    "    epoch_accuracies_2.append(accuracy)\n",
    "    \n",
    "    loss, accuracy = combined_model_1.evaluate(x_test_tigger, y_test_tigger, verbose=0)\n",
    "    epoch_losses_3.append(loss)\n",
    "    epoch_accuracies_3.append(accuracy)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "for epoch in range(55):\n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    epoch_loss_avg_server = tf.keras.metrics.Mean()\n",
    "    \n",
    "    # 客户端模型的训练， ######这一步修改输入数据。\n",
    "    for x_batch, y_batch in train_dataset:\n",
    "        resblock_test_tigger = client_model_1(x_val_triggered[0:2000])\n",
    "        loss = train_step_door(x_batch, y_batch,resblock_test_tigger)\n",
    "        \n",
    "    # 模拟客户端模型的训练  client_1_dataset  改为带有触发器的数据，server_train_dataset\n",
    "    for x_batch, y_batch in client_1_dataset:   ##只修改这部分\n",
    "        loss_1 = train_step_client_1(x_batch, y_batch)\n",
    "    print(f\"  Client Model 1 Loss: {loss_1.numpy():.4f}\")    \n",
    "        \n",
    "   \n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    print(f\"Epoch {epoch}, Loss: {epoch_loss_avg.result().numpy()}\")\n",
    "    \n",
    "    loss, accuracy = combined_model.evaluate(x_test, y_test, verbose=0)\n",
    "    epoch_losses.append(loss)\n",
    "    epoch_accuracies.append(accuracy)\n",
    "    \n",
    "    loss, accuracy = combined_model_1.evaluate(x_test, y_test, verbose=0)\n",
    "    epoch_losses_1.append(loss)\n",
    "    epoch_accuracies_1.append(accuracy)\n",
    "    \n",
    "    loss, accuracy = combined_model.evaluate(x_test_tigger, y_test_tigger, verbose=0)\n",
    "    epoch_losses_2.append(loss)\n",
    "    epoch_accuracies_2.append(accuracy)\n",
    "    \n",
    "    loss, accuracy = combined_model_1.evaluate(x_test_tigger, y_test_tigger, verbose=0)\n",
    "    epoch_losses_3.append(loss)\n",
    "    epoch_accuracies_3.append(accuracy)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # 此处可添加其他回调，如ModelCheckpoint或EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e67206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "epochs = range(1, len(epoch_losses) + 1)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# 绘制 loss 曲线\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, epoch_losses, label='Loss - Model', marker='o')\n",
    "plt.plot(epochs, epoch_losses_1, label='Loss - Model 1', marker='o')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# 绘制 accuracy 曲线\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, epoch_accuracies, label='Accuracy - Model', marker='o')\n",
    "plt.plot(epochs, epoch_accuracies_1, label='Accuracy - Model 1', marker='o')\n",
    "plt.title('Training Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76aff043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "epochs = range(1, len(epoch_losses) + 1)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# 绘制 loss 曲线\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, epoch_losses_2, label='Loss - Model', marker='o')\n",
    "plt.plot(epochs, epoch_losses_3, label='Loss - Model 1', marker='o')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# 绘制 accuracy 曲线\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, epoch_accuracies_2, label='Accuracy - Model', marker='o')\n",
    "plt.plot(epochs, epoch_accuracies_3, label='Accuracy - Model 1', marker='o')\n",
    "plt.title('Training Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36642c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算最大值\n",
    "max_accuracy_2 = max(epoch_accuracies_2)\n",
    "\n",
    "# 找到最大值的索引\n",
    "max_index_2 = epoch_accuracies_2.index(max_accuracy_2)\n",
    "\n",
    "# 获取max_accuracy_2对应的epoch_accuracies值\n",
    "corresponding_accuracy = epoch_accuracies[max_index_2]\n",
    "print(max_accuracy_2)\n",
    "print(corresponding_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3d08df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# 假设client_model和server_model的输入和输出层已经定义\n",
    "\n",
    "# 获取客户端模型的输入\n",
    "client_input = client_model.input\n",
    "\n",
    "# 通过客户端模型获取中间输出\n",
    "client_output = client_model(client_input)\n",
    "\n",
    "# 将客户端的输出作为服务器模型的输入\n",
    "server_output = server_model(client_output)\n",
    "\n",
    "# 定义一个新的模型，该模型连接了客户端和服务器模型\n",
    "combined_model = Model(inputs=client_input, outputs=server_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d0f701",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model.compile(optimizer='adam',\n",
    "                       loss='categorical_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# 假设x_test和y_test已经准备好\n",
    "loss, accuracy = combined_model.evaluate(x_test, y_test)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbe9eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = combined_model.evaluate(x_test_tigger, y_test_tigger)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390d7273",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# 假设client_model和server_model的输入和输出层已经定义\n",
    "\n",
    "# 获取客户端模型的输入\n",
    "client_input_1 = client_model_1.input\n",
    "\n",
    "# 通过客户端模型获取中间输出\n",
    "client_output_1 = client_model_1(client_input_1)\n",
    "\n",
    "# 将客户端的输出作为服务器模型的输入\n",
    "server_output_1 = server_model(client_output_1)\n",
    "\n",
    "# 定义一个新的模型，该模型连接了客户端和服务器模型\n",
    "combined_model_1 = Model(inputs=client_input_1, outputs=server_output_1)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704bcb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model_1.compile(optimizer='adam',\n",
    "                       loss='categorical_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# 假设x_test和y_test已经准备好\n",
    "loss, accuracy = combined_model_1.evaluate(x_test, y_test)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930551c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = combined_model_1.evaluate(x_test_tigger, y_test_tigger)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8e8862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65b0d58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de8fbe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e37a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#313/313 [==============================] - 1s 3ms/step - loss: 0.9457 - accuracy: 0.7466\n",
    "#Test loss: 0.9456651210784912, Test accuracy: 0.7465999722480774\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bb8ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取两个模型的特征表示\n",
    "features_client_model_1 = client_model_1.predict(x_test)\n",
    "features_client_model = client_model.predict(x_test)\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# 计算余弦相似度\n",
    "cosine_sim = cosine_similarity(features_client_model_1.reshape(features_client_model_1.shape[0], -1),\n",
    "                               features_client_model.reshape(features_client_model.shape[0], -1))\n",
    "\n",
    "# 余弦相似度矩阵的对角线元素表示同一个x_test样本在两个模型特征空间中的相似度\n",
    "cosine_sim_diag = np.diag(cosine_sim)\n",
    "\n",
    "# 计算平均余弦相似度\n",
    "average_cosine_sim = np.mean(cosine_sim_diag)\n",
    "print(f\"Average Cosine Similarity: {average_cosine_sim}\")\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\n",
    "# 将特征向量展平\n",
    "features_client_model_1_flat = features_client_model_1.reshape(features_client_model_1.shape[0], -1)\n",
    "features_client_model_flat = features_client_model.reshape(features_client_model.shape[0], -1)\n",
    "\n",
    "# 计算欧几里得距离\n",
    "euclidean_dists = np.array([distance.euclidean(features_client_model_1_flat[i], features_client_model_flat[i]) \n",
    "                            for i in range(features_client_model_1_flat.shape[0])])\n",
    "\n",
    "# 计算平均欧几里得距离\n",
    "average_euclidean_dist = np.mean(euclidean_dists)\n",
    "print(f\"Average Euclidean Distance: {average_euclidean_dist}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e4780b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_model_1.save('client_model_1.h5')\n",
    "server_model.save('server_model.h5')\n",
    "client_model.save('client_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312f3077",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eab3b70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f538a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5492fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c910e92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9507f40c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2165680f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8d457c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86db312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0a4ea80",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
