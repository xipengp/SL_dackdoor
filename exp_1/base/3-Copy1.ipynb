{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68a87d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 18:46:24.655755: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input, GlobalAveragePooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '3'\n",
    "# 加载 CIFAR-10 数据\n",
    "import random\n",
    "import numpy as np\n",
    "# Load and preprocess CIFAR-10 data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5205809",
   "metadata": {},
   "outputs": [],
   "source": [
    "##该模型并没有使用双重对齐，因为我使用的数据错了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1052455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4a66cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load and preprocess CIFAR-10 data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "\n",
    "def add_trigger(img):\n",
    "    trigger_size =3\n",
    "    img[-trigger_size:, -trigger_size:, 0] =0# 设置为红色\n",
    "    img[-trigger_size:, -trigger_size:, 1:3] = 0\n",
    "    return img\n",
    "\n",
    "target_class = 1  # 目标类别\n",
    "num_classes = 10  # CIFAR-10 数据集的类别数\n",
    "\n",
    "# 新的数据集和标签列表\n",
    "x_val_triggered = []  # 存储触发器转换后的图像\n",
    "y_val_triggered = []  # 存储更新后的标签\n",
    "\n",
    "x_val_tigger = x_val.copy()\n",
    "y_val_tigger = y_val.copy()\n",
    "\n",
    "# 应用攻击到选中的图像\n",
    "for i in range(len(x_val_tigger)):\n",
    "    x_val_tigger[i] = add_trigger(x_val_tigger[i])\n",
    "    y_val_tigger[i] = to_categorical(target_class, num_classes=num_classes)\n",
    "    x_val_triggered.append(x_val_tigger[i])\n",
    "    y_val_triggered.append(to_categorical(target_class, num_classes=num_classes))\n",
    "    \n",
    "# 将列表转换为NumPy数组（如果需要）\n",
    "x_val_triggered = np.array(x_val_triggered)\n",
    "y_val_triggered = np.array(y_val_triggered)\n",
    "            \n",
    "    \n",
    "x_test_tigger = x_test.copy()\n",
    "y_test_tigger = y_test.copy()\n",
    "\n",
    "for i in range(len(x_test_tigger)):\n",
    "    x_test_tigger[i] = add_trigger(x_test_tigger[i])\n",
    "    y_test_tigger[i] = to_categorical(target_class, num_classes=num_classes)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c76914bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_test_tigger[0])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6169827",
   "metadata": {},
   "outputs": [],
   "source": [
    "##进行攻击的思路\n",
    "#1.将数据集分成两部分  8比2吧\n",
    "#2.每个epcoch后再单独优化一下服务器模型，保持模拟的客户端模型不变，后门数据要多一些\n",
    "#3.验证数据集结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "284488b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "\n",
    "\n",
    "def create_client_model(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # 第一层卷积\n",
    "    x = layers.Conv2D(32, 3, strides=1, padding='same')(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # 第二层卷积\n",
    "    x = layers.Conv2D(64, 3, strides=1, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # 新增的第三层卷积\n",
    "    x = layers.Conv2D(128, 3, strides=1, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7aa6c066",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def res_block(filters, strides):\n",
    "    def block(x):\n",
    "        shortcut = x\n",
    "\n",
    "        x = layers.Conv2D(filters, 3, padding='same', strides=strides)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation('relu')(x)\n",
    "\n",
    "        x = layers.Conv2D(filters, 3, padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        # 捷径连接前的调整\n",
    "        shortcut = layers.Conv2D(filters, 1, strides=strides, padding='same')(shortcut)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "        x = layers.add([x, shortcut])\n",
    "        x = layers.Activation('relu')(x)\n",
    "        return x\n",
    "    return block\n",
    "\n",
    "def create_server_model():\n",
    "    # 调整输入层的定义以匹配修改后的客户端模型的输出\n",
    "    input_layer = layers.Input(shape=(32, 32, 128))  # 注意这里的变化\n",
    "\n",
    "    # 残差块定义保持不变，继续使用提前定义的 res_block\n",
    "    x = res_block(128, 1)(input_layer)  # 使用第一个残差块\n",
    "    x = res_block(128, 2)(x)            # 使用第二个残差块\n",
    "    x = res_block(128, 2)(x)           # 使用第三个残差块\n",
    "    x = res_block(256, 2)(x)           # 使用第四个残差块\n",
    "\n",
    "    # 全局平均池化和输出层保持不变\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    output = layers.Dense(10, activation='softmax')(x)\n",
    "    \n",
    "    model = models.Model(inputs=input_layer, outputs=output)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fe8999c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 18:47:27.541590: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2024-07-23 18:47:27.732374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:d8:00.0 name: NVIDIA Tesla V100-PCIE-16GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2024-07-23 18:47:27.732451: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-07-23 18:47:27.760601: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2024-07-23 18:47:27.764268: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2024-07-23 18:47:27.785590: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2024-07-23 18:47:27.796376: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-07-23 18:47:27.798198: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2024-07-23 18:47:27.847663: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-07-23 18:47:27.878443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2024-07-23 18:47:27.886833: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-23 18:47:28.089255: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 1700000000 Hz\n",
      "2024-07-23 18:47:28.110036: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56441e9d88c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-23 18:47:28.110086: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2024-07-23 18:47:29.178001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56441e9db5d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-23 18:47:29.178088: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA Tesla V100-PCIE-16GB, Compute Capability 7.0\n",
      "2024-07-23 18:47:29.179970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:d8:00.0 name: NVIDIA Tesla V100-PCIE-16GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2024-07-23 18:47:29.180024: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-07-23 18:47:29.180067: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2024-07-23 18:47:29.180088: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2024-07-23 18:47:29.180109: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2024-07-23 18:47:29.180129: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-07-23 18:47:29.180149: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2024-07-23 18:47:29.180171: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-07-23 18:47:29.182705: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2024-07-23 18:47:29.182760: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-07-23 18:47:34.115666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-07-23 18:47:34.115890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
      "2024-07-23 18:47:34.115904: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
      "2024-07-23 18:47:34.136134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12893 MB memory) -> physical GPU (device: 0, name: NVIDIA Tesla V100-PCIE-16GB, pci bus id: 0000:d8:00.0, compute capability: 7.0)\n"
     ]
    }
   ],
   "source": [
    "# 创建客户端模型\n",
    "client_model = create_client_model(input_shape=(32, 32, 3))\n",
    "\n",
    "# 编译客户端模型\n",
    "client_model.compile(optimizer=Adam(),\n",
    "                     loss='categorical_crossentropy',\n",
    "                     metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e170b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 128)       0         \n",
      "=================================================================\n",
      "Total params: 94,144\n",
      "Trainable params: 93,696\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "client_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6093cab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下是服务器模型训练的简化示例\n",
    "server_model = create_server_model()\n",
    "server_model.compile(optimizer=Adam(),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e918179",
   "metadata": {},
   "outputs": [],
   "source": [
    "##创建三个影子模型，分别是1层卷积，2层卷积核3层卷积\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8267f1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_client_model_1(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same')(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_client_model_2(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same')(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n",
    "def create_client_model_3(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same')(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n",
    "def create_client_model_4(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same')(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n",
    "\n",
    "def create_client_model_5(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # 第一层卷积\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same')(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # 第二层卷积\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # 第三层卷积\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # 第四层卷积\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # 第五层卷积\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8ca1962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 32, 32, 128)       0         \n",
      "=================================================================\n",
      "Total params: 94,144\n",
      "Trainable params: 93,696\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Assuming TensorFlow is installed and the functions are defined in your script\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "client_model_1 = create_client_model_3(input_shape=(32, 32, 3))\n",
    "\n",
    "\n",
    "# You can then print the model summaries to verify their structures\n",
    "print(client_model_1.summary())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e1f821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257222ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ba7ac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "# 定义训练步骤\n",
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape_client, tf.GradientTape() as tape_server:\n",
    "        # 客户端前向传播\n",
    "        client_outputs = client_model(x, training=True)\n",
    "        # 服务器前向传播      \n",
    "        server_logits = server_model(client_outputs, training=True)\n",
    "        # 计算损失\n",
    "        loss = loss_fn(y, server_logits)\n",
    "\n",
    "    # 计算服务器模型梯度\n",
    "    grads_server = tape_server.gradient(loss, server_model.trainable_variables)\n",
    "    # 更新服务器模型权重\n",
    "    optimizer_server.apply_gradients(zip(grads_server, server_model.trainable_variables))\n",
    "\n",
    "    # 计算客户端模型梯度（模拟反向传播）\n",
    "    grads_client = tape_client.gradient(loss, client_model.trainable_variables)\n",
    "    # 更新客户端模型权重\n",
    "    optimizer_client.apply_gradients(zip(grads_client, client_model.trainable_variables))\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75b4940b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 假设 optimizer_client 和 optimizer_server 已经被定义\n",
    "optimizer_client_1 = tf.keras.optimizers.Adam()  # 为 client_model_1 定义一个新的优化器\n",
    "\n",
    "@tf.function\n",
    "def train_step_2(x, y):\n",
    "    # 首次使用客户端和服务器模型进行训练\n",
    "    with tf.GradientTape() as tape_client, tf.GradientTape() as tape_server:\n",
    "        client_outputs = client_model(x, training=True)  # 客户端模型前向传播\n",
    "        server_logits = server_model(client_outputs, training=True)  # 服务器模型前向传播\n",
    "        loss = loss_fn(y, server_logits)  # 计算损失\n",
    "\n",
    "    # 计算并应用服务器模型梯度\n",
    "    grads_server = tape_server.gradient(loss, server_model.trainable_variables)\n",
    "    optimizer_server.apply_gradients(zip(grads_server, server_model.trainable_variables))\n",
    "\n",
    "    # 计算并应用客户端模型梯度\n",
    "    grads_client = tape_client.gradient(loss, client_model.trainable_variables)\n",
    "    optimizer_client.apply_gradients(zip(grads_client, client_model.trainable_variables))\n",
    "\n",
    "    # 单独针对 client_model_1 的训练步骤\n",
    "    with tf.GradientTape() as tape_client_1:\n",
    "        client_outputs_1 = client_model_1(x, training=True)  # client_model_1 前向传播\n",
    "        server_logits_1 = server_model(client_outputs_1, training=False)  # 使用 server_model 进行前向传播但不更新\n",
    "        loss_1 = loss_fn(y, server_logits_1)  # 计算损失\n",
    "\n",
    "    # 计算并应用 client_model_1 的梯度\n",
    "    grads_client_1 = tape_client_1.gradient(loss_1, client_model_1.trainable_variables)\n",
    "    optimizer_client_1.apply_gradients(zip(grads_client_1, client_model_1.trainable_variables))\n",
    "\n",
    "    return loss, loss_1  # 返回两步训练的损失值\n",
    "\n",
    "# 注意：在实际使用中，确保已经正确初始化了所有模型（client_model, client_model_1, server_model）\n",
    "# 以及优化器（optimizer_client, optimizer_server, optimizer_client_1）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8084182f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step_client(x, y):\n",
    "    # 使用客户端和服务器模型进行训练\n",
    "    with tf.GradientTape() as tape_client, tf.GradientTape() as tape_server:\n",
    "        # 客户端模型前向传播\n",
    "        client_outputs = client_model(x, training=True)\n",
    "        # 服务器模型前向传播\n",
    "        server_logits = server_model(client_outputs, training=True)\n",
    "        # 计算损失\n",
    "        loss = loss_fn(y, server_logits)\n",
    "    \n",
    "    # 计算并应用服务器模型梯度\n",
    "    grads_server = tape_server.gradient(loss, server_model.trainable_variables)\n",
    "    optimizer_server.apply_gradients(zip(grads_server, server_model.trainable_variables))\n",
    "    \n",
    "    # 计算并应用客户端模型梯度\n",
    "    grads_client = tape_client.gradient(loss, client_model.trainable_variables)\n",
    "    optimizer_client.apply_gradients(zip(grads_client, client_model.trainable_variables))\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ad94ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step_client_1(x, y):\n",
    "    # 仅针对client_model_1的训练步骤\n",
    "    with tf.GradientTape() as tape_client_1:\n",
    "        # client_model_1前向传播\n",
    "        client_outputs_1 = client_model_1(x, training=True)\n",
    "        # 使用server_model进行前向传播但不更新\n",
    "        server_logits_1 = server_model(client_outputs_1, training=False)\n",
    "        # 计算损失\n",
    "        loss_1 = loss_fn(y, server_logits_1)\n",
    "\n",
    "    # 计算并应用client_model_1的梯度\n",
    "    grads_client_1 = tape_client_1.gradient(loss_1, client_model_1.trainable_variables)\n",
    "    optimizer_client_1.apply_gradients(zip(grads_client_1, client_model_1.trainable_variables))\n",
    "\n",
    "    return loss_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc8bc1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d33c884",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step_only_server(x, y):\n",
    "    with tf.GradientTape() as tape_server:\n",
    "        # 使用 client_model_1 进行前向传播，注意这里我们不更新 client_model_1\n",
    "        client_outputs_1 = client_model_1(x, training=False)  # 注意这里的 training=False\n",
    "        \n",
    "        # 使用 server_model 进行前向传播，准备更新这个模型\n",
    "        server_logits = server_model(client_outputs_1, training=True)\n",
    "        \n",
    "        # 计算损失\n",
    "        loss = loss_fn(y, server_logits)\n",
    "\n",
    "    # 计算服务器模型梯度并应用\n",
    "    grads_server = tape_server.gradient(loss, server_model.trainable_variables)\n",
    "    optimizer_server_2.apply_gradients(zip(grads_server, server_model.trainable_variables))\n",
    "\n",
    "    return loss  # 返回训练损失值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e91dd40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70435cf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f81fbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def create_combined_model(client_model, server_model, compile_only=False):\n",
    "    # Getting the input of the client model\n",
    "    client_input = client_model.input\n",
    "    \n",
    "    # Getting the intermediate output by passing the input through the client model\n",
    "    client_output = client_model(client_input)\n",
    "    \n",
    "    # The client model's output is used as the input for the server model\n",
    "    server_output = server_model(client_output)\n",
    "    \n",
    "    # Defining a new model that chains the client and server models\n",
    "    combined_model = Model(inputs=client_input, outputs=server_output)\n",
    "    \n",
    "    # Compile the combined model\n",
    "    combined_model.compile(optimizer=Adam(),\n",
    "                           loss='categorical_crossentropy',\n",
    "                           metrics=['accuracy'])\n",
    "    \n",
    "    if not compile_only:\n",
    "        # If not compile_only, evaluate the model\n",
    "        loss, accuracy = combined_model.evaluate(x_test, y_test, verbose=0)\n",
    "        print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n",
    "    \n",
    "    return combined_model\n",
    "\n",
    "# Use the function to create and compile the combined model without evaluating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66051716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def change_batch(resblock_test_trigger, client_outputs, y):\n",
    "    # 使用tf.random.uniform生成0到2000之间的随机整数索引\n",
    "    random_integer = tf.random.uniform(shape=(), minval=0, maxval=2000, dtype=tf.int32)\n",
    "    # 从resblock_test_trigger中选择一个随机元素\n",
    "    selected_trigger = tf.gather(resblock_test_trigger, random_integer)\n",
    "    # 确保selected_trigger的形状与client_outputs中的元素兼容\n",
    "    selected_trigger = tf.expand_dims(selected_trigger, 0)  # 假设它是一个序列，需要扩展维度以兼容\n",
    "\n",
    "    # 更新client_outputs的第一个元素\n",
    "    client_outputs_updated = tf.concat([selected_trigger, client_outputs[1:]], axis=0)\n",
    "    \n",
    "    # 创建一个新标签\n",
    "    new_label = tf.constant([0, 1, 0, 0, 0, 0, 0, 0, 0, 0], dtype=y.dtype)\n",
    "    # 使用tf.tensor_scatter_nd_update更新y的第一个样本的标签\n",
    "    indices = tf.constant([[0]])  # 表示我们要更新第一个样本的标签\n",
    "    updated_y = tf.tensor_scatter_nd_update(y, indices, tf.expand_dims(new_label, 0))\n",
    "\n",
    "    return client_outputs_updated, updated_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae423c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "# 定义训练步骤\n",
    "@tf.function\n",
    "def train_step_door(x, y,resblock_test_tigger):\n",
    "    with tf.GradientTape() as tape_client, tf.GradientTape() as tape_server:\n",
    "        # 客户端前向传播\n",
    "        client_outputs = client_model(x, training=True)\n",
    "        client_outputs_updated, updated_y = change_batch(resblock_test_tigger,client_outputs,y)\n",
    "        # 服务器前向传播      \n",
    "        server_logits = server_model(client_outputs_updated, training=True)\n",
    "        # 计算损失\n",
    "        loss = loss_fn(updated_y, server_logits)\n",
    "\n",
    "    # 计算服务器模型梯度\n",
    "    grads_server = tape_server.gradient(loss, server_model.trainable_variables)\n",
    "    # 更新服务器模型权重\n",
    "    optimizer_server.apply_gradients(zip(grads_server, server_model.trainable_variables))\n",
    "\n",
    "    # 计算客户端模型梯度（模拟反向传播）\n",
    "    grads_client = tape_client.gradient(loss, client_model.trainable_variables)\n",
    "    # 更新客户端模型权重\n",
    "    optimizer_client1.apply_gradients(zip(grads_client, client_model.trainable_variables))\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65491f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_client = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "optimizer_client1 = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "###这两个都是客户端的优化梯度\n",
    "\n",
    "optimizer_server = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "##optimizer_server 和 这两个都是客户端的优化梯度的梯度要一模一样\n",
    "\n",
    "optimizer_client_1 = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "\n",
    "optimizer_server_2 = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57eed60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "def augment(image, label):\n",
    "    # 随机水平翻转图像\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    # 随机调整亮度\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    # 确保图像值仍然在0到1的范围内\n",
    "    image = tf.clip_by_value(image, 0.0, 1.0)\n",
    "    return image, label\n",
    "\n",
    "# 假设x_train, y_train, x_val, y_val, x_val_tigger, y_val_tigger已经定义并准备好了\n",
    "\n",
    "# 训练数据集 - 应用数据增强\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.map(augment).shuffle(len(x_train)).batch(batch_size)\n",
    "\n",
    "# 客户端验证数据集 - 也应用数据增强\n",
    "client_1_dataset = tf.data.Dataset.from_tensor_slices((x_val[2000:10000], y_val[2000:10000]))\n",
    "client_1_dataset = client_1_dataset.map(augment).shuffle(len(x_val[2000:10000])).batch(batch_size)\n",
    "\n",
    "# 服务器训练数据集 - 也应用数据增强\n",
    "server_train_dataset = tf.data.Dataset.from_tensor_slices((x_val_tigger, y_val_tigger))\n",
    "server_train_dataset = server_train_dataset.map(augment).shuffle(len(x_val_tigger)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47e2e08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 18:47:57.206920: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session started.\n",
      "2024-07-23 18:47:57.222712: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1391] Profiler found 1 GPUs\n",
      "2024-07-23 18:47:57.225279: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcupti.so.10.1\n",
      "2024-07-23 18:47:57.344409: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1441] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_INSUFFICIENT_PRIVILEGES\n",
      "2024-07-23 18:48:19.598950: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:172] Filling up shuffle buffer (this may take a while): 43303 of 50000\n",
      "2024-07-23 18:48:21.197841: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:221] Shuffle buffer filled.\n",
      "2024-07-23 18:48:31.723662: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2024-07-23 18:48:33.287990: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-07-23 18:48:44.662329: W tensorflow/stream_executor/gpu/asm_compiler.cc:81] Running ptxas --version returned 256\n",
      "2024-07-23 18:48:45.451307: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Client Model Loss: 0.8940\n",
      "  Client Model 1 Loss: 0.9651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 19:03:38.354916: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:172] Filling up shuffle buffer (this may take a while): 45540 of 50000\n",
      "2024-07-23 19:03:39.369454: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:221] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Client Model Loss: 1.3515\n",
      "  Client Model 1 Loss: 0.7731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 19:04:22.890170: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:172] Filling up shuffle buffer (this may take a while): 42467 of 50000\n",
      "2024-07-23 19:04:24.364006: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:221] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Client Model Loss: 0.4314\n",
      "  Client Model 1 Loss: 0.4855\n",
      "  Client Model Loss: 0.2092\n",
      "  Client Model 1 Loss: 0.8253\n",
      "  Client Model Loss: 0.4548\n",
      "  Client Model 1 Loss: 0.2479\n",
      "  Client Model Loss: 0.6151\n",
      "  Client Model 1 Loss: 0.1944\n",
      "  Client Model Loss: 0.4313\n",
      "  Client Model 1 Loss: 0.5940\n",
      "  Client Model Loss: 0.6250\n",
      "  Client Model 1 Loss: 0.1724\n",
      "  Client Model Loss: 0.2301\n",
      "  Client Model 1 Loss: 0.2278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 19:09:27.911166: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:172] Filling up shuffle buffer (this may take a while): 46829 of 50000\n",
      "2024-07-23 19:09:28.493206: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:221] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Client Model Loss: 0.1115\n",
      "  Client Model 1 Loss: 0.2631\n",
      "  Client Model Loss: 0.1745\n",
      "  Client Model 1 Loss: 0.1657\n",
      "  Client Model Loss: 0.0728\n",
      "  Client Model 1 Loss: 0.2347\n",
      "  Client Model Loss: 0.0954\n",
      "  Client Model 1 Loss: 0.3342\n",
      "  Client Model Loss: 0.0362\n",
      "  Client Model 1 Loss: 0.1380\n",
      "  Client Model Loss: 0.1208\n",
      "  Client Model 1 Loss: 0.2741\n",
      "  Client Model Loss: 0.0168\n",
      "  Client Model 1 Loss: 0.2686\n",
      "  Client Model Loss: 0.0188\n",
      "  Client Model 1 Loss: 0.0311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 19:15:11.333519: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:172] Filling up shuffle buffer (this may take a while): 49074 of 50000\n",
      "2024-07-23 19:15:11.572728: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:221] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Client Model Loss: 0.2144\n",
      "  Client Model 1 Loss: 0.1768\n",
      "  Client Model Loss: 0.0169\n",
      "  Client Model 1 Loss: 0.0228\n",
      "  Client Model Loss: 0.0447\n",
      "  Client Model 1 Loss: 0.0073\n",
      "  Client Model Loss: 0.0336\n",
      "  Client Model 1 Loss: 0.0241\n",
      "  Client Model Loss: 0.0211\n",
      "  Client Model 1 Loss: 0.0980\n",
      "  Client Model Loss: 0.0142\n",
      "  Client Model 1 Loss: 0.0786\n",
      "  Client Model Loss: 0.0544\n",
      "  Client Model 1 Loss: 0.0089\n",
      "  Client Model Loss: 0.4783\n",
      "  Client Model 1 Loss: 0.0116\n",
      "  Client Model Loss: 0.0224\n",
      "  Client Model 1 Loss: 0.0674\n",
      "  Client Model Loss: 0.0029\n",
      "  Client Model 1 Loss: 0.0044\n",
      "  Client Model Loss: 0.0101\n",
      "  Client Model 1 Loss: 0.1185\n",
      "  Client Model Loss: 0.0145\n",
      "  Client Model 1 Loss: 0.0037\n",
      "  Client Model Loss: 0.0006\n",
      "  Client Model 1 Loss: 0.0311\n",
      "  Client Model Loss: 0.0014\n",
      "  Client Model 1 Loss: 0.0176\n",
      "  Client Model Loss: 0.0129\n",
      "  Client Model 1 Loss: 0.0003\n",
      "  Client Model Loss: 0.0539\n",
      "  Client Model 1 Loss: 0.0015\n",
      "  Client Model Loss: 0.0283\n",
      "  Client Model 1 Loss: 0.0082\n",
      "  Client Model Loss: 0.0036\n",
      "  Client Model 1 Loss: 0.0057\n",
      "  Client Model Loss: 0.0064\n",
      "  Client Model 1 Loss: 0.0013\n",
      "  Client Model Loss: 0.0026\n",
      "  Client Model 1 Loss: 0.0053\n",
      "  Client Model Loss: 0.0196\n",
      "  Client Model 1 Loss: 0.0005\n",
      "  Client Model Loss: 0.0196\n",
      "  Client Model 1 Loss: 0.0011\n",
      "  Client Model Loss: 0.0003\n",
      "  Client Model 1 Loss: 0.0016\n",
      "  Client Model Loss: 0.0005\n",
      "  Client Model 1 Loss: 0.0016\n",
      "  Client Model Loss: 0.0105\n",
      "  Client Model 1 Loss: 0.0022\n",
      "  Client Model Loss: 0.0011\n",
      "  Client Model 1 Loss: 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 19:33:47.195723: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:172] Filling up shuffle buffer (this may take a while): 46902 of 50000\n",
      "2024-07-23 19:33:47.779606: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:221] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Client Model Loss: 0.2820\n",
      "  Client Model 1 Loss: 0.0011\n",
      "  Client Model Loss: 0.0015\n",
      "  Client Model 1 Loss: 0.0006\n",
      "  Client Model Loss: 0.0129\n",
      "  Client Model 1 Loss: 0.0050\n",
      "  Client Model Loss: 0.0006\n",
      "  Client Model 1 Loss: 0.0113\n",
      "  Client Model Loss: 0.0002\n",
      "  Client Model 1 Loss: 0.0009\n",
      "  Client Model Loss: 0.0081\n",
      "  Client Model 1 Loss: 0.0008\n",
      "  Client Model Loss: 0.0227\n",
      "  Client Model 1 Loss: 0.0053\n",
      "  Client Model Loss: 0.0055\n",
      "  Client Model 1 Loss: 0.0003\n",
      "  Client Model Loss: 0.0020\n",
      "  Client Model 1 Loss: 0.1665\n",
      "  Client Model Loss: 0.0004\n",
      "  Client Model 1 Loss: 0.0069\n",
      "  Client Model Loss: 0.0551\n",
      "  Client Model 1 Loss: 0.0015\n",
      "  Client Model Loss: 0.0021\n",
      "  Client Model 1 Loss: 0.0003\n"
     ]
    }
   ],
   "source": [
    "# 初始化TensorBoard回调\n",
    "import datetime\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "epochs = 60\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "combined_model = create_combined_model(client_model, server_model, compile_only=True)\n",
    "combined_model_1 = create_combined_model(client_model_1, server_model, compile_only=True)\n",
    "\n",
    "\n",
    "epoch_losses = []\n",
    "epoch_accuracies = []\n",
    "\n",
    "\n",
    "epoch_losses_1 = []\n",
    "epoch_accuracies_1 = []\n",
    "\n",
    "\n",
    "epoch_losses_2= []\n",
    "epoch_accuracies_2 = []\n",
    "\n",
    "\n",
    "epoch_losses_3= []\n",
    "epoch_accuracies_3 = []\n",
    "# 开始训练\n",
    "\n",
    "epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "epoch_loss_avg_server = tf.keras.metrics.Mean()\n",
    "\n",
    "#先训练\n",
    "\n",
    "for epoch in range(55):\n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    epoch_loss_avg_server = tf.keras.metrics.Mean()\n",
    "    for x_batch, y_batch in train_dataset:\n",
    "        loss = train_step_client(x_batch, y_batch)\n",
    "    print(f\"  Client Model Loss: {loss.numpy():.4f}\")\n",
    "\n",
    "    for x_batch, y_batch in client_1_dataset:   ##只修改这部分\n",
    "        loss_1 = train_step_client_1(x_batch, y_batch)\n",
    "    print(f\"  Client Model 1 Loss: {loss_1.numpy():.4f}\")\n",
    "\n",
    "    loss, accuracy = combined_model.evaluate(x_test, y_test, verbose=0)\n",
    "    epoch_losses.append(loss)\n",
    "    epoch_accuracies.append(accuracy)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56cc83a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb7804f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4ed985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12231af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# 假设client_model和server_model的输入和输出层已经定义\n",
    "\n",
    "# 获取客户端模型的输入\n",
    "client_input = client_model.input\n",
    "\n",
    "# 通过客户端模型获取中间输出\n",
    "client_output = client_model(client_input)\n",
    "\n",
    "# 将客户端的输出作为服务器模型的输入\n",
    "server_output = server_model(client_output)\n",
    "\n",
    "# 定义一个新的模型，该模型连接了客户端和服务器模型\n",
    "combined_model = Model(inputs=client_input, outputs=server_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48f91d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 8ms/step - loss: 0.6580 - accuracy: 0.8772\n",
      "Test loss: 0.6579946875572205, Test accuracy: 0.8772000074386597\n"
     ]
    }
   ],
   "source": [
    "combined_model.compile(optimizer='adam',\n",
    "                       loss='categorical_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# 假设x_test和y_test已经准备好\n",
    "loss, accuracy = combined_model.evaluate(x_test, y_test)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dcc21ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 19.9250 - accuracy: 0.1064\n",
      "Test loss: 19.925004959106445, Test accuracy: 0.10639999806880951\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model.evaluate(x_test_tigger, y_test_tigger)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb2210ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# 假设client_model和server_model的输入和输出层已经定义\n",
    "\n",
    "# 获取客户端模型的输入\n",
    "client_input_1 = client_model_1.input\n",
    "\n",
    "# 通过客户端模型获取中间输出\n",
    "client_output_1 = client_model_1(client_input_1)\n",
    "\n",
    "# 将客户端的输出作为服务器模型的输入\n",
    "server_output_1 = server_model(client_output_1)\n",
    "\n",
    "# 定义一个新的模型，该模型连接了客户端和服务器模型\n",
    "combined_model_1 = Model(inputs=client_input_1, outputs=server_output_1)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b902387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 0.7176 - accuracy: 0.8670\n",
      "Test loss: 0.7175835967063904, Test accuracy: 0.8669999837875366\n"
     ]
    }
   ],
   "source": [
    "combined_model_1.compile(optimizer='adam',\n",
    "                       loss='categorical_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# 假设x_test和y_test已经准备好\n",
    "loss, accuracy = combined_model_1.evaluate(x_test, y_test)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a1faa7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 8ms/step - loss: 20.1291 - accuracy: 0.1032\n",
      "Test loss: 20.129114151000977, Test accuracy: 0.10320000350475311\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model_1.evaluate(x_test_tigger, y_test_tigger)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976d9aee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d3bb13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7595ea65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92ff9113",
   "metadata": {},
   "outputs": [],
   "source": [
    "#313/313 [==============================] - 1s 3ms/step - loss: 0.9457 - accuracy: 0.7466\n",
    "#Test loss: 0.9456651210784912, Test accuracy: 0.7465999722480774\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1022af85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 19:42:29.248811: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 5242880000 exceeds 10% of free system memory.\n",
      "2024-07-23 19:43:16.759225: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 5242880000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Cosine Similarity: 0.8045072555541992\n",
      "Average Euclidean Distance: 140.38952398071288\n"
     ]
    }
   ],
   "source": [
    "# 获取两个模型的特征表示\n",
    "features_client_model_1 = client_model_1.predict(x_test)\n",
    "features_client_model = client_model.predict(x_test)\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# 计算余弦相似度\n",
    "cosine_sim = cosine_similarity(features_client_model_1.reshape(features_client_model_1.shape[0], -1),\n",
    "                               features_client_model.reshape(features_client_model.shape[0], -1))\n",
    "\n",
    "# 余弦相似度矩阵的对角线元素表示同一个x_test样本在两个模型特征空间中的相似度\n",
    "cosine_sim_diag = np.diag(cosine_sim)\n",
    "\n",
    "# 计算平均余弦相似度\n",
    "average_cosine_sim = np.mean(cosine_sim_diag)\n",
    "print(f\"Average Cosine Similarity: {average_cosine_sim}\")\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\n",
    "# 将特征向量展平\n",
    "features_client_model_1_flat = features_client_model_1.reshape(features_client_model_1.shape[0], -1)\n",
    "features_client_model_flat = features_client_model.reshape(features_client_model.shape[0], -1)\n",
    "\n",
    "# 计算欧几里得距离\n",
    "euclidean_dists = np.array([distance.euclidean(features_client_model_1_flat[i], features_client_model_flat[i]) \n",
    "                            for i in range(features_client_model_1_flat.shape[0])])\n",
    "\n",
    "# 计算平均欧几里得距离\n",
    "average_euclidean_dist = np.mean(euclidean_dists)\n",
    "print(f\"Average Euclidean Distance: {average_euclidean_dist}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f9d17b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_model_1.save('client_model_1.h5')\n",
    "server_model.save('server_model.h5')\n",
    "client_model.save('client_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1384ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f4424d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46e8ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2464c00c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa35fc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0f31b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c348436",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e989f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646d8be5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79537a62",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
