{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fae1e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-04 09:48:17.454908: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input, GlobalAveragePooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "# 加载 CIFAR-10 数据\n",
    "import random\n",
    "import numpy as np\n",
    "# Load and preprocess CIFAR-10 data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a00f8385",
   "metadata": {},
   "outputs": [],
   "source": [
    "##该模型并没有使用双重对齐，因为我使用的数据错了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad8c448",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84237a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_trigger(img):\n",
    "    trigger_size =4\n",
    "    img[-trigger_size:, -trigger_size:, 0] =0# 设置为红色\n",
    "    img[-trigger_size:, -trigger_size:, 1:3] = 0\n",
    "    return img\n",
    "\n",
    "\n",
    "# Apply the SIG backdoor attack\n",
    "# Apply the SIG backdoor attack to the training set\n",
    "\n",
    "# 选择1%的训练数据进行攻击\n",
    "\n",
    "target_class = 1  # 目标类别\n",
    "num_classes = 10  # CIFAR-10 数据集的类别数\n",
    "\n",
    "# 新的数据集和标签列表\n",
    "x_val_triggered = []  # 存储触发器转换后的图像\n",
    "y_val_triggered = []  # 存储更新后的标签\n",
    "\n",
    "x_val_tigger = x_val.copy()\n",
    "y_val_tigger = y_val.copy()\n",
    "y_val_tigger_2 = np.zeros(len(y_val))  # 所有标签初始化为0\n",
    "# 将标签转换为one-hot编码\n",
    "y_val_tigger_2 = to_categorical(y_val_tigger_2, num_classes=2)\n",
    "\n",
    "\n",
    "num_samples = int(0.1 * x_val.shape[0])\n",
    "indices = np.random.choice(y_val.shape[0], num_samples, replace=False)\n",
    "\n",
    "\n",
    "\n",
    "# 应用攻击到选中的图像\n",
    "for i in indices:\n",
    "    x_val_tigger[i] = add_trigger(x_val_tigger[i])\n",
    "    y_val_tigger[i] = to_categorical(target_class, num_classes=num_classes)\n",
    "    y_val_tigger_2[i] = to_categorical(target_class, num_classes = 2 )\n",
    "        \n",
    "    \n",
    "x_test_tigger = x_test.copy()\n",
    "y_test_tigger = y_test.copy()\n",
    "\n",
    "for i in range(len(x_test_tigger)):\n",
    "    x_test_tigger[i] = add_trigger(x_test_tigger[i])\n",
    "    y_test_tigger[i] = to_categorical(target_class, num_classes=num_classes)\n",
    "##进行攻击的思路\n",
    "#1.将数据集分成两部分  8比2吧\n",
    "#2.每个epcoch后再单独优化一下服务器模型，保持模拟的客户端模型不变，后门数据要多一些\n",
    "#3.验证数据集结果\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f6bf16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee54ed4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a65422e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "\n",
    "def create_client_model(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # 第一层卷积\n",
    "    x = layers.Conv2D(32, 3, strides=1, padding='same')(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # 第二层卷积\n",
    "    x = layers.Conv2D(64, 3, strides=1, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # 新增的第三层卷积\n",
    "    x = layers.Conv2D(128, 3, strides=1, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63f6a777",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def res_block(filters, strides):\n",
    "    def block(x):\n",
    "        shortcut = x\n",
    "\n",
    "        x = layers.Conv2D(filters, 3, padding='same', strides=strides)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation('relu')(x)\n",
    "\n",
    "        x = layers.Conv2D(filters, 3, padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        # 捷径连接前的调整\n",
    "        shortcut = layers.Conv2D(filters, 1, strides=strides, padding='same')(shortcut)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "        x = layers.add([x, shortcut])\n",
    "        x = layers.Activation('relu')(x)\n",
    "        return x\n",
    "    return block\n",
    "\n",
    "def create_server_model():\n",
    "    # 调整输入层的定义以匹配修改后的客户端模型的输出\n",
    "    input_layer = layers.Input(shape=(32, 32, 128))  # 注意这里的变化\n",
    "\n",
    "    # 残差块定义保持不变，继续使用提前定义的 res_block\n",
    "    x = res_block(64, 1)(input_layer)  # 使用第一个残差块\n",
    "    x = res_block(128, 2)(x)            # 使用第二个残差块\n",
    "    x = res_block(128, 2)(x)           # 使用第三个残差块\n",
    "    x = res_block(256, 2)(x)           # 使用第四个残差块\n",
    "\n",
    "    # 全局平均池化和输出层保持不变\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    output = layers.Dense(10, activation='softmax')(x)\n",
    "    \n",
    "    model = models.Model(inputs=input_layer, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59911936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_aux_model():\n",
    "    # 调整输入层的定义以匹配修改后的客户端模型的输出\n",
    "    input_layer = layers.Input(shape=(32, 32, 128))  # 注意这里的变化\n",
    "\n",
    "    # 第一个卷积层和ReLU激活\n",
    "    x = layers.Conv2D(128, 3, strides=2, padding='same')(input_layer)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # 第二个卷积层和ReLU激活\n",
    "    x = layers.Conv2D(128, 3, strides=2, padding='same')(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # 添加残差块\n",
    "    x = res_block(256, 1)(x)  # 使用第一个残差块\n",
    "    x = res_block(256, 1)(x) # 使用第二个残差块\n",
    "\n",
    "    # 第三个卷积层和ReLU激活\n",
    "    x = layers.Conv2D(256, 3, strides=2, padding='same')(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # 全连接层\n",
    "    x = layers.Flatten()(x)\n",
    "    output = layers.Dense(2, activation='softmax')(x)\n",
    "    \n",
    "    model = models.Model(inputs=input_layer, outputs=output)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d999bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-04 09:48:47.698258: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2024-08-04 09:48:47.772493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:3b:00.0 name: NVIDIA Tesla V100-PCIE-16GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2024-08-04 09:48:47.772563: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-08-04 09:48:47.779206: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2024-08-04 09:48:47.782935: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2024-08-04 09:48:47.783491: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2024-08-04 09:48:47.796737: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-08-04 09:48:47.798867: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2024-08-04 09:48:47.807227: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-08-04 09:48:47.827247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2024-08-04 09:48:47.828763: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-04 09:48:47.872766: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 1700000000 Hz\n",
      "2024-08-04 09:48:47.875361: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5566b502c0a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2024-08-04 09:48:47.875431: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2024-08-04 09:48:48.462072: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5566b502edb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-08-04 09:48:48.462129: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA Tesla V100-PCIE-16GB, Compute Capability 7.0\n",
      "2024-08-04 09:48:48.463842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:3b:00.0 name: NVIDIA Tesla V100-PCIE-16GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2024-08-04 09:48:48.463899: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-08-04 09:48:48.463938: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2024-08-04 09:48:48.463960: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2024-08-04 09:48:48.463980: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2024-08-04 09:48:48.464000: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-08-04 09:48:48.464020: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2024-08-04 09:48:48.464041: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-08-04 09:48:48.466715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2024-08-04 09:48:48.466772: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-08-04 09:48:50.949461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-08-04 09:48:50.949528: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
      "2024-08-04 09:48:50.949543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
      "2024-08-04 09:48:50.975594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14765 MB memory) -> physical GPU (device: 0, name: NVIDIA Tesla V100-PCIE-16GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)\n"
     ]
    }
   ],
   "source": [
    "aux_model = create_aux_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f61b1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_discrim_model():\n",
    "    # 调整输入层的定义以匹配修改后的客户端模型的输出\n",
    "    input_layer = layers.Input(shape=(32, 32, 128))   # 注意这里的变化\n",
    "\n",
    "    # 第一个卷积层和ReLU激活\n",
    "    x = layers.Conv2D(128, 3, strides=2, padding='same')(input_layer)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # 第二个卷积层和ReLU激活\n",
    "    x = layers.Conv2D(128, 3, strides=2, padding='same')(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # 添加三个残差块\n",
    "    x = res_block(256, 1)(x)  # 使用第一个残差块\n",
    "    x = res_block(256, 1)(x)  # 使用第二个残差块\n",
    "    x = res_block(256, 1)(x)  # 使用第三个残差块\n",
    "\n",
    "    # 第三个卷积层和ReLU激活\n",
    "    x = layers.Conv2D(256, 3, strides=2, padding='same')(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # 全连接层，输出单一值\n",
    "    x = layers.Flatten()(x)\n",
    "    output = layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = models.Model(inputs=input_layer, outputs=output)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f015b0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "# 替换 'your_model.h5' 为你自己的模型文件名\n",
    "client_model = load_model('my_client_model.h5')\n",
    "server_model=load_model('my_server_modell.h5')\n",
    "client_model_1 = load_model('my_client_model_1.h5')\n",
    "discrim_model = create_discrim_model()\n",
    "\n",
    "# 编译客户端模型\n",
    "client_model.compile(optimizer=Adam(),\n",
    "                     loss='categorical_crossentropy',\n",
    "                     metrics=['accuracy'])\n",
    "server_model.compile(optimizer=Adam(),\n",
    "                     loss='categorical_crossentropy',\n",
    "                     metrics=['accuracy'])\n",
    "discrim_model.compile(optimizer=Adam(),\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "137ec866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 32, 32, 128) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 128)  147584      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 16, 16, 128)  0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 8, 8, 128)    147584      re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 8, 8, 128)    0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 8, 8, 256)    295168      re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 8, 8, 256)    1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 8, 8, 256)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 8, 8, 256)    590080      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 8, 8, 256)    33024       re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 8, 8, 256)    1024        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 8, 8, 256)    1024        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 8, 8, 256)    0           batch_normalization_7[0][0]      \n",
      "                                                                 batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 8, 8, 256)    0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 8, 8, 256)    590080      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 8, 8, 256)    1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 8, 8, 256)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 8, 8, 256)    590080      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 8, 8, 256)    65792       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 8, 8, 256)    1024        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 8, 8, 256)    1024        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 8, 8, 256)    0           batch_normalization_10[0][0]     \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 8, 8, 256)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 8, 8, 256)    590080      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 8, 8, 256)    1024        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 8, 8, 256)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 8, 8, 256)    590080      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 8, 8, 256)    65792       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8, 8, 256)    1024        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 8, 256)    1024        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 8, 8, 256)    0           batch_normalization_13[0][0]     \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 8, 8, 256)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 4, 4, 256)    590080      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 4, 4, 256)    0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 4096)         0           re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            4097        flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,308,737\n",
      "Trainable params: 4,304,129\n",
      "Non-trainable params: 4,608\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discrim_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caa3bfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_model = create_server_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c1dffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f754c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c6668b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8673a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下是服务器模型训练的简化示例\n",
    "server_model.compile(optimizer=Adam(),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "aux_model.compile(optimizer=Adam(),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de65142d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##创建三个影子模型，分别是1层卷积，2层卷积核3层卷积\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fdc5c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_client_model_1(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    # 确保输出为128个通道\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(input_layer)\n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n",
    "def create_client_model_2(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(input_layer)\n",
    "    # 第二层输出调整为128个通道\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n",
    "def create_client_model_3(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(input_layer)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same')(x)  # 移除这里的激活函数\n",
    "    x = layers.Activation('relu')(x)  # 显式添加ReLU激活层\n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n",
    "\n",
    "def create_client_model_4(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(input_layer)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    # 第四层输出调整为128个通道\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c9e08d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "691618bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "###数据集\n",
    "###对于影子数据集，需要5000个，并且中毒率为百分之10.需要修改标签，\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ca1e343",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1904a61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc040d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6ff4b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "###可以看到训练精度还是蛮高的，但是测试精度不理想。过拟合了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0cbaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bca2c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a2f442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "924ec840",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "def create_combined_model(client_model, server_model, compile_only=False):\n",
    "    # Getting the input of the client model\n",
    "    client_input = client_model.input\n",
    "    \n",
    "    # Getting the intermediate output by passing the input through the client model\n",
    "    client_output = client_model(client_input)\n",
    "    \n",
    "    # The client model's output is used as the input for the server model\n",
    "    server_output = server_model(client_output)\n",
    "    \n",
    "    # Defining a new model that chains the client and server models\n",
    "    combined_model = Model(inputs=client_input, outputs=server_output)\n",
    "    \n",
    "    # Compile the combined model\n",
    "    combined_model.compile(optimizer=Adam(),\n",
    "                           loss='categorical_crossentropy',\n",
    "                           metrics=['accuracy'])\n",
    "    \n",
    "    if not compile_only:\n",
    "        # If not compile_only, evaluate the model\n",
    "        loss, accuracy = combined_model.evaluate(x_test, y_test, verbose=0)\n",
    "        print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n",
    "    \n",
    "    return combined_model\n",
    "combined_model_mian = create_combined_model(client_model_1, server_model, compile_only=True)\n",
    "combined_model_aux = create_combined_model(client_model_1, aux_model, compile_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e1d660d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-04 09:48:57.555637: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2024-08-04 09:48:58.963196: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-08-04 09:49:05.042174: W tensorflow/stream_executor/gpu/asm_compiler.cc:81] Running ptxas --version returned 256\n",
      "2024-08-04 09:49:05.323383: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 55s 175ms/step - loss: 2.4612 - accuracy: 0.0866\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model_mian.evaluate(x_val_tigger, y_val_tigger, verbose=1)\n",
    "##数据集太小会导致过拟合，因此 - loss: 1.7600e-07 - accuracy: 1.0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a5170b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 24s 77ms/step - loss: 0.6414 - accuracy: 0.7262\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model_aux.evaluate(x_val_tigger, y_val_tigger_2, verbose=1)\n",
    "#0.9证明全部归为了1。 数据集不均衡，会导致二分类器没办法使用，这里也是一个bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9040c9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 2.4000 - accuracy: 0.0977\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model_mian.evaluate(x_test, y_test, verbose=1)\n",
    "##因为数据集比较小，因此精度会比客户端小很多，正常"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b1ba9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 3.0368 - accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model_mian.evaluate(x_test_tigger, y_test_tigger, verbose=1)\n",
    "##后门成功率很高。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2680f696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "x_val_expanded = np.tile(x_val, (4, 1, 1, 1))\n",
    "x_val_tigger_expanded = np.tile(x_val_tigger, (4, 1, 1, 1))\n",
    "print(x_val_expanded.shape)  # This should print (40000, 32, 32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7e91216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "# 替换 'your_model.h5' 为你自己的模型文件名\n",
    "client_model = load_model('my_client_model.h5')\n",
    "server_model=load_model('my_server_modell.h5')\n",
    "client_model_1 = load_model('my_client_model_1.h5')\n",
    "\n",
    "discrim_model = create_discrim_model()\n",
    "\n",
    "# 编译客户端模型\n",
    "client_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.0004, momentum=0.9),\n",
    "                     loss='categorical_crossentropy',\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "server_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.0005, momentum=0.9),\n",
    "                     loss='categorical_crossentropy',\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "discrim_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.0002, momentum=0.9),\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65499df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##如果是因为重复数据太多，那就使用x_train 四分之一"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55728972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models, optimizers, losses\n",
    "# 冻结 client_model_1 的参数\n",
    "# 定义优化器\n",
    "# 冻结 client_model_1 的参数\n",
    "# 冻结 client_model_1 的参数\n",
    "client_model_1.trainable = False\n",
    "\n",
    "# 定义优化器\n",
    "# 示例梯度裁剪\n",
    "discriminator_optimizer = optimizers.SGD(lr=0.001, momentum=0.9)\n",
    "generator_optimizer = optimizers.SGD(lr=0.01, momentum=0.9)\n",
    "optimizer_client_1 = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "# 定义损失函数\n",
    "bce = losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "\n",
    "# 定义损失函数\n",
    "def discriminator_loss(Zs, Zc):\n",
    "    real_output = discrim_model(Zs)\n",
    "    fake_output = discrim_model(Zc)\n",
    "    epsilon = 1e-8  # 避免log(0)\n",
    "    real_loss = -tf.reduce_mean(tf.math.log(1. - real_output + epsilon))\n",
    "    fake_loss = -tf.reduce_mean(tf.math.log(fake_output + epsilon))\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(Zc):\n",
    "    fake_output = discrim_model(Zc)\n",
    "    epsilon = 1e-8  # 避免log(0)\n",
    "    gen_loss = -tf.reduce_mean(tf.math.log(1. - fake_output + epsilon))\n",
    "    return gen_loss\n",
    "# Dc 和 Ds 分别是你的两个输入数据集\n",
    "# 示例数据加载\n",
    "Dc = x_train[:10000]  # CIFAR-10 数据，已预处理为适合模型输入\n",
    "Yc = y_train[:10000]  # CIFAR-10 标签，已转换为 one-hot 编码\n",
    "Ds = x_val#_tigger  # CIFAR-10 数据，已预处理为适合模型输入\n",
    "\n",
    "# 训练循环\n",
    "\n",
    "@tf.function\n",
    "@tf.function\n",
    "def train_step_client(x, y):\n",
    "    # 仅针对client_model_1的训练步骤\n",
    "    with tf.GradientTape() as tape_client:\n",
    "        # client_model_1前向传播\n",
    "        client_outputs = client_model(x, training=True)\n",
    "        # 使用server_model进行前向传播但不更新\n",
    "        server_logits = server_model(client_outputs, training=False)\n",
    "        # 计算损失\n",
    "        loss_1 = loss_fn(y, server_logits)\n",
    "\n",
    "    # 计算并应用client_model_1的梯度\n",
    "    grads_client = tape_client.gradient(loss_1, client_model.trainable_variables)\n",
    "    optimizer_client_1.apply_gradients(zip(grads_client, client_model.trainable_variables))\n",
    "\n",
    "    return loss_1\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524a2657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65cb2376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 157: Real output: 0.0003310643951408565, Fake output: 0.9410543441772461\n",
      "Epoch 1/30, Discriminator Loss: 0.06117919087409973, Generator Loss: 3.051222801208496\n",
      "Epoch: 0, Batch: 9984, Loss: 0.1160\n",
      "Batch 157: Real output: 0.0020831855945289135, Fake output: 0.9967663288116455\n",
      "Epoch 2/30, Discriminator Loss: 0.005350534804165363, Generator Loss: 5.834716320037842\n",
      "Epoch: 1, Batch: 9984, Loss: 0.1649\n",
      "Batch 157: Real output: 1.4045616225644153e-08, Fake output: 1.0\n",
      "Epoch 3/30, Discriminator Loss: 1.1175870895385742e-08, Generator Loss: 18.42068099975586\n",
      "Epoch: 2, Batch: 9984, Loss: 0.3285\n",
      "Batch 157: Real output: 0.011854086071252823, Fake output: 0.9989262819290161\n",
      "Epoch 4/30, Discriminator Loss: 0.013996614143252373, Generator Loss: 6.959339141845703\n",
      "Epoch: 3, Batch: 9984, Loss: 0.1448\n",
      "Batch 157: Real output: 0.024931732565164566, Fake output: 0.9983887076377869\n",
      "Epoch 5/30, Discriminator Loss: 0.030387774109840393, Generator Loss: 6.476318359375\n",
      "Epoch: 4, Batch: 9984, Loss: 0.2235\n",
      "Batch 157: Real output: 8.03242894420464e-09, Fake output: 0.9956213235855103\n",
      "Epoch 6/30, Discriminator Loss: 0.004388309083878994, Generator Loss: 5.452363967895508\n",
      "Epoch: 5, Batch: 9984, Loss: 0.2151\n",
      "Batch 157: Real output: 2.2266382075031288e-05, Fake output: 0.9979475736618042\n",
      "Epoch 7/30, Discriminator Loss: 0.0020768435206264257, Generator Loss: 6.156193256378174\n",
      "Epoch: 6, Batch: 9984, Loss: 0.2470\n",
      "Batch 157: Real output: 0.00018351331527810544, Fake output: 0.9940445423126221\n",
      "Epoch 8/30, Discriminator Loss: 0.00615710811689496, Generator Loss: 5.13896369934082\n",
      "Epoch: 7, Batch: 9984, Loss: 0.3134\n",
      "Batch 157: Real output: 5.845749910804443e-06, Fake output: 0.9894939064979553\n",
      "Epoch 9/30, Discriminator Loss: 0.010583098977804184, Generator Loss: 4.774756908416748\n",
      "Epoch: 8, Batch: 9984, Loss: 0.1456\n",
      "Batch 157: Real output: 7.733605889370665e-05, Fake output: 0.9892477989196777\n",
      "Epoch 10/30, Discriminator Loss: 0.01089987251907587, Generator Loss: 6.690258026123047\n",
      "Epoch: 9, Batch: 9984, Loss: 0.1155\n",
      "Batch 157: Real output: 0.01781921647489071, Fake output: 0.9986120462417603\n",
      "Epoch 11/30, Discriminator Loss: 0.022364772856235504, Generator Loss: 7.287076950073242\n",
      "Epoch: 10, Batch: 9984, Loss: 0.1257\n",
      "Batch 157: Real output: 3.633801952673821e-07, Fake output: 0.9992488622665405\n",
      "Epoch 12/30, Discriminator Loss: 0.0007517975172959268, Generator Loss: 7.195894718170166\n",
      "Epoch: 11, Batch: 9984, Loss: 0.1746\n",
      "Batch 157: Real output: 0.012069301679730415, Fake output: 0.9999648332595825\n",
      "Epoch 13/30, Discriminator Loss: 0.013024010695517063, Generator Loss: 11.877687454223633\n",
      "Epoch: 12, Batch: 9984, Loss: 0.1365\n",
      "Batch 157: Real output: 2.2227122826734558e-05, Fake output: 0.9985640048980713\n",
      "Epoch 14/30, Discriminator Loss: 0.001459241728298366, Generator Loss: 6.518857955932617\n",
      "Epoch: 13, Batch: 9984, Loss: 0.1759\n",
      "Batch 157: Real output: 8.49767675390467e-05, Fake output: 0.9991340041160583\n",
      "Epoch 15/30, Discriminator Loss: 0.000951381865888834, Generator Loss: 7.4091291427612305\n",
      "Epoch: 14, Batch: 9984, Loss: 0.1136\n",
      "Batch 157: Real output: 4.450730102689704e-06, Fake output: 0.9969218969345093\n",
      "Epoch 16/30, Discriminator Loss: 0.0030915718525648117, Generator Loss: 7.639678955078125\n",
      "Epoch: 15, Batch: 9984, Loss: 0.0337\n",
      "Batch 157: Real output: 1.3745747651228157e-08, Fake output: 0.9994446039199829\n",
      "Epoch 17/30, Discriminator Loss: 0.0005555585958063602, Generator Loss: 7.502054691314697\n",
      "Epoch: 16, Batch: 9984, Loss: 0.0592\n",
      "Batch 157: Real output: 1.5836270961244736e-07, Fake output: 0.9976489543914795\n",
      "Epoch 18/30, Discriminator Loss: 0.0023548267781734467, Generator Loss: 6.37346887588501\n",
      "Epoch: 17, Batch: 9984, Loss: 0.1253\n",
      "Batch 157: Real output: 5.309168500389205e-07, Fake output: 0.999707818031311\n",
      "Epoch 19/30, Discriminator Loss: 0.0002928154426626861, Generator Loss: 9.541799545288086\n",
      "Epoch: 18, Batch: 9984, Loss: 0.1319\n",
      "Batch 157: Real output: 1.2116870840017668e-09, Fake output: 0.9998835325241089\n",
      "Epoch 20/30, Discriminator Loss: 0.00011651899694697931, Generator Loss: 9.060653686523438\n",
      "Epoch: 19, Batch: 9984, Loss: 0.1398\n",
      "Batch 157: Real output: 1.0264149530314626e-09, Fake output: 0.9998512268066406\n",
      "Epoch 21/30, Discriminator Loss: 0.0001487917616032064, Generator Loss: 8.817184448242188\n",
      "Epoch: 20, Batch: 9984, Loss: 0.1443\n",
      "Batch 157: Real output: 9.751580654082659e-10, Fake output: 0.9998241662979126\n",
      "Epoch 22/30, Discriminator Loss: 0.00017582692089490592, Generator Loss: 8.651569366455078\n",
      "Epoch: 21, Batch: 9984, Loss: 0.1221\n",
      "Batch 157: Real output: 9.986480531409825e-10, Fake output: 0.9998183846473694\n",
      "Epoch 23/30, Discriminator Loss: 0.00018165433721151203, Generator Loss: 8.620261192321777\n",
      "Epoch: 22, Batch: 9984, Loss: 0.1178\n",
      "Batch 157: Real output: 1.0319368692890407e-09, Fake output: 0.9998382329940796\n",
      "Epoch 24/30, Discriminator Loss: 0.00016181000682990998, Generator Loss: 8.73623275756836\n",
      "Epoch: 23, Batch: 9984, Loss: 0.1142\n",
      "Batch 157: Real output: 1.0405405426183734e-09, Fake output: 0.9998595714569092\n",
      "Epoch 25/30, Discriminator Loss: 0.00014045339776203036, Generator Loss: 8.877553939819336\n",
      "Epoch: 24, Batch: 9984, Loss: 0.0976\n",
      "Batch 157: Real output: 1.0365691638369867e-09, Fake output: 0.9998670816421509\n",
      "Epoch 26/30, Discriminator Loss: 0.00013296454562805593, Generator Loss: 8.933052062988281\n",
      "Epoch: 25, Batch: 9984, Loss: 0.0979\n",
      "Batch 157: Real output: 1.0304141984107673e-09, Fake output: 0.9998806118965149\n",
      "Epoch 27/30, Discriminator Loss: 0.00011940274998778477, Generator Loss: 9.039955139160156\n",
      "Epoch: 26, Batch: 9984, Loss: 0.0912\n",
      "Batch 157: Real output: 1.0132269467888477e-09, Fake output: 0.9998940229415894\n",
      "Epoch 28/30, Discriminator Loss: 0.0001059827336575836, Generator Loss: 9.158933639526367\n",
      "Epoch: 27, Batch: 9984, Loss: 0.0998\n",
      "Batch 157: Real output: 9.904952413819501e-10, Fake output: 0.99990314245224\n",
      "Epoch 29/30, Discriminator Loss: 9.687719284556806e-05, Generator Loss: 9.249534606933594\n",
      "Epoch: 28, Batch: 9984, Loss: 0.0952\n",
      "Batch 157: Real output: 9.671941025857222e-10, Fake output: 0.9999092817306519\n",
      "Epoch 30/30, Discriminator Loss: 9.070008673006669e-05, Generator Loss: 9.315925598144531\n",
      "Epoch: 29, Batch: 9984, Loss: 0.1005\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "epochs =  30\n",
    "batch_size = 64\n",
    "for epoch in range(epochs):\n",
    "    for batch in range(0, len(Dc), batch_size):\n",
    "        Dc_batch = Dc[batch:batch+batch_size]\n",
    "        Ds_batch = Ds[batch:batch+batch_size]      \n",
    "        # 生成器生成输出\n",
    "        Zc = client_model(Dc_batch)\n",
    "        Zs = client_model_1(Ds_batch)\n",
    "        # 打印模型输出值\n",
    "        real_output = discrim_model(Zs)\n",
    "        fake_output = discrim_model(Zc)\n",
    "        # 鉴别器的损失计算和优化\n",
    "        with tf.GradientTape() as disc_tape:\n",
    "            disc_loss = discriminator_loss(Zs, Zc)\n",
    "        disc_grads = disc_tape.gradient(disc_loss, discrim_model.trainable_variables)\n",
    "        discriminator_optimizer.apply_gradients(zip(disc_grads, discrim_model.trainable_variables))\n",
    "\n",
    "        # 生成器的损失计算和优化\n",
    "        with tf.GradientTape() as gen_tape:\n",
    "            Zc = client_model(Dc_batch)  # 重新生成 Zc\n",
    "            gen_loss = generator_loss(Zc)\n",
    "        \n",
    "        gen_grads = gen_tape.gradient(gen_loss, client_model.trainable_variables)\n",
    "        generator_optimizer.apply_gradients(zip(gen_grads, client_model.trainable_variables))\n",
    "    \n",
    "    print(f\"Batch {batch//batch_size + 1}: Real output: {real_output.numpy().mean()}, Fake output: {fake_output.numpy().mean()}\")\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Discriminator Loss: {disc_loss.numpy()}, Generator Loss: {gen_loss.numpy()}\")\n",
    "    for batch in range(0, len(Dc), batch_size):  ##只修改这部分\n",
    "        x_batch = Dc[batch:batch+batch_size]\n",
    "        y_batch = Yc[batch:batch+batch_size]  \n",
    "        loss_1 = train_step_client(x_batch, y_batch)\n",
    "    print(\"Epoch: {}, Batch: {}, Loss: {:.4f}\".format(epoch, batch, loss_1.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34236234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e0fadb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75417ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d178ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80525ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model_mian_c = create_combined_model(client_model, server_model, compile_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ca409e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 2.1655 - accuracy: 0.4073\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model_mian_c.evaluate(x_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed03486c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 7.2993 - accuracy: 0.0578\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model_mian_c.evaluate(x_test_tigger, y_test_tigger, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f29c62a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model_mian = create_combined_model(client_model_1, server_model, compile_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2be959e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3246 - accuracy: 0.9412\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model_mian.evaluate(x_test_tigger, y_test_tigger, verbose=1)\n",
    "##数据集太小会导致过拟合，因此 - loss: 1.7600e-07 - accuracy: 1.0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d121a965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 0.6712 - accuracy: 0.8345\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model_mian.evaluate(x_test, y_test, verbose=1)\n",
    "##因为数据集比较小，因此精度会比客户端小很多，正常"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79095922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f748613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097b9f94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721a8e08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee68b597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c996a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af032de4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64c2857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cb7046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106ecc60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f7d5e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b17a11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b61c535b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#313/313 [==============================] - 1s 3ms/step - loss: 0.9457 - accuracy: 0.7466\n",
    "#Test loss: 0.9456651210784912, Test accuracy: 0.7465999722480774\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6662e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320070ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f16230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6606cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ee7feb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c98620",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0245139f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5beb0c28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a911bf92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c707314e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512eb147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9f35d3e",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
