{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4859617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:10:39.375188: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input, GlobalAveragePooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '3'\n",
    "# 加载 CIFAR-10 数据\n",
    "import random\n",
    "import numpy as np\n",
    "# Load and preprocess CIFAR-10 data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4db8edd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##该模型并没有使用双重对齐，因为我使用的数据错了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3cce4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b061eb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sigTriggerAttack(object):\n",
    "    def __init__(self, delta=40, f=6):\n",
    "        self.delta = delta\n",
    "        self.f = f\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return self.sigTrigger(img)\n",
    "\n",
    "    def sigTrigger(self, img):\n",
    "        img = np.float32(img)\n",
    "        pattern = np.zeros_like(img)\n",
    "        m = pattern.shape[1]\n",
    "        for i in range(int(img.shape[0])):\n",
    "            for j in range(int(img.shape[1])):\n",
    "                pattern[i, j] = self.delta * np.sin(2 * np.pi * j * self.f / m)\n",
    "\n",
    "        img = np.uint32(img * 255) + pattern  # 因为您之前已经将图像归一化，所以我们需要乘以255\n",
    "        img = np.uint8(np.clip(img, 0, 255))\n",
    "        return img / 255  # 再次归一化\n",
    "\n",
    "    \n",
    "    \n",
    "# Apply the SIG backdoor attack\n",
    "# Apply the SIG backdoor attack to the training set\n",
    "attack = sigTriggerAttack()\n",
    "\n",
    "# 选择1%的训练数据进行攻击\n",
    "\n",
    "target_class = 1  # 目标类别\n",
    "num_classes = 10  # CIFAR-10 数据集的类别数\n",
    "\n",
    "# 新的数据集和标签列表\n",
    "x_val_triggered = []  # 存储触发器转换后的图像\n",
    "y_val_triggered = []  # 存储更新后的标签\n",
    "\n",
    "x_val_tigger = x_val.copy()\n",
    "y_val_tigger = y_val.copy()\n",
    "y_val_tigger_2 = np.zeros(len(y_val))  # 所有标签初始化为0\n",
    "# 将标签转换为one-hot编码\n",
    "y_val_tigger_2 = to_categorical(y_val_tigger_2, num_classes=2)\n",
    "\n",
    "\n",
    "num_samples = int(0.1 * x_val.shape[0])\n",
    "indices = np.random.choice(y_val.shape[0], num_samples, replace=False)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b879c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fc00227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 应用攻击到选中的图像\n",
    "for i in indices:\n",
    "    x_val_tigger[i] = attack(x_val_tigger[i])\n",
    "    y_val_tigger[i] = to_categorical(target_class, num_classes=num_classes)\n",
    "    y_val_tigger_2[i] = to_categorical(target_class, num_classes = 2 )\n",
    "        \n",
    "    \n",
    "x_test_tigger = x_test.copy()\n",
    "y_test_tigger = y_test.copy()\n",
    "\n",
    "for i in range(len(x_test_tigger)):\n",
    "    x_test_tigger[i] = attack(x_test_tigger[i])\n",
    "    y_test_tigger[i] = to_categorical(target_class, num_classes=num_classes)\n",
    "##进行攻击的思路\n",
    "#1.将数据集分成两部分  8比2吧\n",
    "#2.每个epcoch后再单独优化一下服务器模型，保持模拟的客户端模型不变，后门数据要多一些\n",
    "#3.验证数据集结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b712af35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "\n",
    "def create_client_model(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # 第一层卷积\n",
    "    x = layers.Conv2D(32, 3, strides=1, padding='same')(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # 第二层卷积\n",
    "    x = layers.Conv2D(64, 3, strides=1, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # 新增的第三层卷积\n",
    "    x = layers.Conv2D(128, 3, strides=1, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f50e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def res_block(filters, strides):\n",
    "    def block(x):\n",
    "        shortcut = x\n",
    "\n",
    "        x = layers.Conv2D(filters, 3, padding='same', strides=strides)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation('relu')(x)\n",
    "\n",
    "        x = layers.Conv2D(filters, 3, padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        # 捷径连接前的调整\n",
    "        shortcut = layers.Conv2D(filters, 1, strides=strides, padding='same')(shortcut)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "        x = layers.add([x, shortcut])\n",
    "        x = layers.Activation('relu')(x)\n",
    "        return x\n",
    "    return block\n",
    "\n",
    "def create_server_model():\n",
    "    # 调整输入层的定义以匹配修改后的客户端模型的输出\n",
    "    input_layer = layers.Input(shape=(32, 32, 128))  # 注意这里的变化\n",
    "\n",
    "    # 残差块定义保持不变，继续使用提前定义的 res_block\n",
    "    x = res_block(64, 1)(input_layer)  # 使用第一个残差块\n",
    "    x = res_block(128, 2)(x)            # 使用第二个残差块\n",
    "    x = res_block(128, 2)(x)           # 使用第三个残差块\n",
    "    x = res_block(256, 2)(x)           # 使用第四个残差块\n",
    "\n",
    "    # 全局平均池化和输出层保持不变\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    output = layers.Dense(10, activation='softmax')(x)\n",
    "    \n",
    "    model = models.Model(inputs=input_layer, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab3e1c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_aux_model():\n",
    "    # 调整输入层的定义以匹配修改后的客户端模型的输出\n",
    "    input_layer = layers.Input(shape=(32, 32, 128))  # 注意这里的变化\n",
    "\n",
    "    # 第一个卷积层和ReLU激活\n",
    "    x = layers.Conv2D(128, 3, strides=2, padding='same')(input_layer)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # 第二个卷积层和ReLU激活\n",
    "    x = layers.Conv2D(128, 3, strides=2, padding='same')(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # 添加残差块\n",
    "    x = res_block(256, 1)(x)  # 使用第一个残差块\n",
    "    x = res_block(256, 1)(x) # 使用第二个残差块\n",
    "\n",
    "    # 第三个卷积层和ReLU激活\n",
    "    x = layers.Conv2D(256, 3, strides=2, padding='same')(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # 全连接层\n",
    "    x = layers.Flatten()(x)\n",
    "    output = layers.Dense(2, activation='softmax')(x)\n",
    "    \n",
    "    model = models.Model(inputs=input_layer, outputs=output)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e719679",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:11:42.112322: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2024-07-31 17:11:42.202943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:d8:00.0 name: NVIDIA Tesla V100-PCIE-16GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2024-07-31 17:11:42.203027: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-07-31 17:11:42.207708: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2024-07-31 17:11:42.211535: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2024-07-31 17:11:42.212127: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2024-07-31 17:11:42.216446: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-07-31 17:11:42.218585: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2024-07-31 17:11:42.227157: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-07-31 17:11:42.233933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2024-07-31 17:11:42.235667: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-31 17:11:42.300968: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 1700000000 Hz\n",
      "2024-07-31 17:11:42.302006: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56305a95ec20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-31 17:11:42.302046: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2024-07-31 17:11:42.556669: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56305a961930 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-31 17:11:42.556722: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA Tesla V100-PCIE-16GB, Compute Capability 7.0\n",
      "2024-07-31 17:11:42.558301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:d8:00.0 name: NVIDIA Tesla V100-PCIE-16GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2024-07-31 17:11:42.558357: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-07-31 17:11:42.558395: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2024-07-31 17:11:42.558417: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2024-07-31 17:11:42.558437: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2024-07-31 17:11:42.558457: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-07-31 17:11:42.558477: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2024-07-31 17:11:42.558497: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-07-31 17:11:42.560863: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2024-07-31 17:11:42.560926: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-07-31 17:11:43.764425: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-07-31 17:11:43.764503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
      "2024-07-31 17:11:43.764519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
      "2024-07-31 17:11:43.768159: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10501 MB memory) -> physical GPU (device: 0, name: NVIDIA Tesla V100-PCIE-16GB, pci bus id: 0000:d8:00.0, compute capability: 7.0)\n"
     ]
    }
   ],
   "source": [
    "aux_model = create_aux_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f10d6462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_discrim_model():\n",
    "    # 调整输入层的定义以匹配修改后的客户端模型的输出\n",
    "    input_layer = layers.Input(shape=(32, 32, 128))   # 注意这里的变化\n",
    "\n",
    "    # 第一个卷积层和ReLU激活\n",
    "    x = layers.Conv2D(128, 3, strides=2, padding='same')(input_layer)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # 第二个卷积层和ReLU激活\n",
    "    x = layers.Conv2D(128, 3, strides=2, padding='same')(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # 添加三个残差块\n",
    "    x = res_block(256, 1)(x)  # 使用第一个残差块\n",
    "    x = res_block(256, 1)(x)  # 使用第二个残差块\n",
    "    x = res_block(256, 1)(x)  # 使用第三个残差块\n",
    "\n",
    "    # 第三个卷积层和ReLU激活\n",
    "    x = layers.Conv2D(256, 3, strides=2, padding='same')(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # 全连接层，输出单一值\n",
    "    x = layers.Flatten()(x)\n",
    "    output = layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = models.Model(inputs=input_layer, outputs=output)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61d1ac4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrim_model = create_discrim_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e754236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 32, 32, 128) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 128)  147584      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 16, 16, 128)  0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 8, 8, 128)    147584      re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 8, 8, 128)    0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 8, 8, 256)    295168      re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 8, 8, 256)    1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 8, 8, 256)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 8, 8, 256)    590080      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 8, 8, 256)    33024       re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 8, 8, 256)    1024        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 8, 8, 256)    1024        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 8, 8, 256)    0           batch_normalization_7[0][0]      \n",
      "                                                                 batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 8, 8, 256)    0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 8, 8, 256)    590080      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 8, 8, 256)    1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 8, 8, 256)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 8, 8, 256)    590080      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 8, 8, 256)    65792       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 8, 8, 256)    1024        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 8, 8, 256)    1024        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 8, 8, 256)    0           batch_normalization_10[0][0]     \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 8, 8, 256)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 8, 8, 256)    590080      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 8, 8, 256)    1024        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 8, 8, 256)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 8, 8, 256)    590080      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 8, 8, 256)    65792       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8, 8, 256)    1024        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 8, 256)    1024        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 8, 8, 256)    0           batch_normalization_13[0][0]     \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 8, 8, 256)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 4, 4, 256)    590080      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 4, 4, 256)    0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 4096)         0           re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            4097        flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,308,737\n",
      "Trainable params: 4,304,129\n",
      "Non-trainable params: 4,608\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discrim_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a346a27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_model = create_server_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4c3e85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建客户端模型\n",
    "client_model = create_client_model(input_shape=(32, 32, 3))\n",
    "\n",
    "# 编译客户端模型\n",
    "client_model.compile(optimizer=Adam(),\n",
    "                     loss='categorical_crossentropy',\n",
    "                     metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c67319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7563cee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b32b57c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下是服务器模型训练的简化示例\n",
    "server_model.compile(optimizer=Adam(),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "discrim_model.compile(optimizer=Adam(),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "aux_model.compile(optimizer=Adam(),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e05126e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##创建三个影子模型，分别是1层卷积，2层卷积核3层卷积\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2026782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_client_model_1(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    # 确保输出为128个通道\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(input_layer)\n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n",
    "def create_client_model_2(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(input_layer)\n",
    "    # 第二层输出调整为128个通道\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n",
    "def create_client_model_3(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(input_layer)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same')(x)  # 移除这里的激活函数\n",
    "    x = layers.Activation('relu')(x)  # 显式添加ReLU激活层\n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n",
    "\n",
    "def create_client_model_4(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(input_layer)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    # 第四层输出调整为128个通道\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ced64555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming TensorFlow is installed and the functions are defined in your script\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "client_model_1 = create_client_model(input_shape=(32, 32, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c9883e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "052758d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "# 定义优化器\n",
    "# 定义第一部分的数据集\n",
    "def augment(image, label):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    return image, label\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.map(augment).shuffle(len(x_train)).batch(32)\n",
    "\n",
    "# 定义第二部分的数据集\n",
    "def preprocess(image, label1, label2):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    return image, (label1, label2)\n",
    "\n",
    "train_dataset_2 = tf.data.Dataset.from_tensor_slices((x_val_tigger, y_val_tigger_2, y_val_tigger))\n",
    "train_dataset_2 = train_dataset_2.map(preprocess)\n",
    "train_dataset_2 = train_dataset_2.batch(32)\n",
    "train_dataset_2 = train_dataset_2.repeat()\n",
    "\n",
    "# 创建数据集\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50a42348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# 假设 client_model_1, server_model, aux_model 已经被正确定义和初始化\n",
    "# 定义优化器\n",
    "\n",
    "optimizer_client = tf.keras.optimizers.Adam()\n",
    "optimizer_client_1 = tf.keras.optimizers.Adam()\n",
    "optimizer_server = tf.keras.optimizers.Adam()\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step_client(x, y):\n",
    "    with tf.GradientTape() as tape_client, tf.GradientTape() as tape_server:\n",
    "        client_outputs = client_model(x, training=True)\n",
    "        server_logits = server_model(client_outputs, training=True)\n",
    "        loss = loss_fn(y, server_logits)\n",
    "    \n",
    "    grads_server = tape_server.gradient(loss, server_model.trainable_variables)\n",
    "    optimizer_server.apply_gradients(zip(grads_server, server_model.trainable_variables))\n",
    "    \n",
    "    grads_client = tape_client.gradient(loss, client_model.trainable_variables)\n",
    "    optimizer_client.apply_gradients(zip(grads_client, client_model.trainable_variables))\n",
    "\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "@tf.function\n",
    "def train_step_combined(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        aux_output, server_output = combined_model(x, training=True)\n",
    "        loss_aux = tf.keras.losses.categorical_crossentropy(y[0], aux_output)\n",
    "        loss_server = tf.keras.losses.categorical_crossentropy(y[1], server_output)\n",
    "        loss = 0.5 * loss_aux + 0.5 * loss_server\n",
    "    \n",
    "    grads = tape.gradient(loss, combined_model.trainable_variables)\n",
    "    optimizer_client_1.apply_gradients(zip(grads, combined_model.trainable_variables))\n",
    "    \n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "# 冻结 server_model 的所有层\n",
    "def freeze_server_model():\n",
    "    for layer in server_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "# 取消冻结 server_model 的所有层\n",
    "def unfreeze_server_model():\n",
    "    for layer in server_model.layers:\n",
    "        layer.trainable = True\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "# 获取 client_model_1 的输出，作为其他两个模型的输入\n",
    "feature_output = client_model_1.output\n",
    "\n",
    "# 用 client_model_1 的输出作为输入创建两个任务的模型\n",
    "server_output = server_model(feature_output)\n",
    "aux_output = aux_model(feature_output)\n",
    "\n",
    "combined_model = models.Model(inputs=client_model_1.input, outputs=[aux_output, server_output])\n",
    "combined_model.compile(optimizer='adam',\n",
    "                       loss=['categorical_crossentropy', 'categorical_crossentropy'],\n",
    "                       metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceaac31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1064b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8d2a26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ecaf7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:12:01.183700: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2024-07-31 17:12:02.134083: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-07-31 17:12:05.833389: W tensorflow/stream_executor/gpu/asm_compiler.cc:81] Running ptxas --version returned 256\n",
      "2024-07-31 17:12:06.134711: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Client Model Loss: 1.1216\n",
      "Epoch 1 completed.\n",
      "Epoch 2, Client Model Loss: 0.5730\n",
      "Epoch 2 completed.\n",
      "Epoch 3, Client Model Loss: 0.6331\n",
      "Epoch 3 completed.\n",
      "Epoch 4, Client Model Loss: 0.4660\n",
      "Epoch 4 completed.\n",
      "Epoch 5, Client Model Loss: 0.2811\n",
      "Epoch 5 completed.\n",
      "Epoch 6, Client Model Loss: 0.2660\n",
      "Epoch 6 completed.\n",
      "Epoch 7, Client Model Loss: 0.5134\n",
      "Epoch 7 completed.\n",
      "Epoch 8, Client Model Loss: 0.3541\n",
      "Epoch 8 completed.\n",
      "Epoch 9, Client Model Loss: 0.1206\n",
      "Epoch 9 completed.\n",
      "Epoch 10, Client Model Loss: 0.1901\n",
      "Epoch 10 completed.\n",
      "Epoch 11, Client Model Loss: 0.0821\n",
      "Epoch 11 completed.\n",
      "Epoch 12, Client Model Loss: 0.1242\n",
      "Epoch 12 completed.\n",
      "Epoch 13, Client Model Loss: 0.1420\n",
      "Epoch 13 completed.\n",
      "Epoch 14, Client Model Loss: 0.0552\n",
      "Epoch 14 completed.\n",
      "Epoch 15, Client Model Loss: 0.2042\n",
      "Epoch 15 completed.\n",
      "Epoch 16, Client Model Loss: 0.0945\n",
      "Epoch 16 completed.\n",
      "Epoch 17, Client Model Loss: 0.0428\n",
      "Epoch 17 completed.\n",
      "Epoch 18, Client Model Loss: 0.1806\n",
      "Epoch 18 completed.\n",
      "Epoch 19, Client Model Loss: 0.0934\n",
      "Epoch 19 completed.\n",
      "Epoch 20, Client Model Loss: 0.0255\n",
      "Epoch 20 completed.\n",
      "Epoch 21, Client Model Loss: 0.0847\n",
      "Epoch 21 completed.\n",
      "Epoch 22, Client Model Loss: 0.0219\n",
      "Epoch 22 completed.\n",
      "Epoch 23, Client Model Loss: 0.0608\n",
      "Epoch 23 completed.\n",
      "Epoch 24, Client Model Loss: 0.1116\n",
      "Epoch 24 completed.\n",
      "Epoch 25, Client Model Loss: 0.0273\n",
      "Epoch 25 completed.\n"
     ]
    }
   ],
   "source": [
    "epochs = 25\n",
    "steps_per_epoch = len(x_train) // 32\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # 先训练第一部分模型\n",
    "    unfreeze_server_model()  # 取消冻结 server_model\n",
    "    for x_batch, y_batch in train_dataset:\n",
    "        loss_client = train_step_client(x_batch, y_batch)\n",
    "    print(f\"Epoch {epoch + 1}, Client Model Loss: {loss_client.numpy():.4f}\")\n",
    "\n",
    "    # 冻结 server_model 并训练组合模型\n",
    "    freeze_server_model()  # 冻结 server_model\n",
    "    for step, (x_batch, (y_batch_aux, y_batch_server)) in enumerate(train_dataset_2.take(steps_per_epoch)):\n",
    "        loss_combined = train_step_combined(x_batch, (y_batch_aux, y_batch_server))\n",
    "\n",
    "    unfreeze_server_model()  # 解冻 server_model\n",
    "    print(f\"Epoch {epoch + 1} completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "449fec6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step_combined_2(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        aux_output, server_output = combined_model(x, training=True)\n",
    "        loss_aux = tf.keras.losses.categorical_crossentropy(y[0], aux_output)\n",
    "        loss_server = tf.keras.losses.categorical_crossentropy(y[1], server_output)\n",
    "        loss = 0.5 * loss_aux + 0.5 * loss_server\n",
    "    \n",
    "    grads = tape.gradient(loss, combined_model.trainable_variables)\n",
    "    optimizer_fine_tune.apply_gradients(zip(grads, combined_model.trainable_variables))\n",
    "    \n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd2611f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 1, Step 0, Combined Model Loss: 0.3398\n",
      "Fine-tuning Epoch 1, Step 50, Combined Model Loss: 0.3180\n",
      "Fine-tuning Epoch 1, Step 100, Combined Model Loss: 0.0517\n",
      "Fine-tuning Epoch 1, Step 150, Combined Model Loss: 0.0790\n",
      "Fine-tuning Epoch 1, Step 200, Combined Model Loss: 0.0529\n",
      "Fine-tuning Epoch 1, Step 250, Combined Model Loss: 0.0367\n",
      "Fine-tuning Epoch 1, Step 300, Combined Model Loss: 0.0246\n",
      "Fine-tuning Epoch 1, Step 350, Combined Model Loss: 0.1464\n",
      "Fine-tuning Epoch 1, Step 400, Combined Model Loss: 0.0307\n",
      "Fine-tuning Epoch 1, Step 450, Combined Model Loss: 0.2819\n",
      "Fine-tuning Epoch 1, Step 500, Combined Model Loss: 0.1342\n",
      "Fine-tuning Epoch 1, Step 550, Combined Model Loss: 0.2069\n",
      "Fine-tuning Epoch 1, Step 600, Combined Model Loss: 0.0272\n",
      "Fine-tuning Epoch 1, Step 650, Combined Model Loss: 0.0922\n",
      "Fine-tuning Epoch 1, Step 700, Combined Model Loss: 0.0373\n",
      "Fine-tuning Epoch 1, Step 750, Combined Model Loss: 0.0676\n",
      "Fine-tuning Epoch 1, Step 800, Combined Model Loss: 0.0742\n",
      "Fine-tuning Epoch 1, Step 850, Combined Model Loss: 0.2460\n",
      "Fine-tuning Epoch 1, Step 900, Combined Model Loss: 0.1191\n",
      "Fine-tuning Epoch 1, Step 950, Combined Model Loss: 0.0354\n",
      "Fine-tuning Epoch 1, Step 1000, Combined Model Loss: 0.1808\n",
      "Fine-tuning Epoch 1, Step 1050, Combined Model Loss: 0.0559\n",
      "Fine-tuning Epoch 1, Step 1100, Combined Model Loss: 0.1224\n",
      "Fine-tuning Epoch 1, Step 1150, Combined Model Loss: 0.0328\n",
      "Fine-tuning Epoch 1, Step 1200, Combined Model Loss: 0.0240\n",
      "Fine-tuning Epoch 1 completed.\n",
      "Fine-tuning Epoch 2, Step 0, Combined Model Loss: 0.0832\n",
      "Fine-tuning Epoch 2, Step 50, Combined Model Loss: 0.0592\n",
      "Fine-tuning Epoch 2, Step 100, Combined Model Loss: 0.0757\n",
      "Fine-tuning Epoch 2, Step 150, Combined Model Loss: 0.0868\n",
      "Fine-tuning Epoch 2, Step 200, Combined Model Loss: 0.1171\n",
      "Fine-tuning Epoch 2, Step 250, Combined Model Loss: 0.0446\n",
      "Fine-tuning Epoch 2, Step 300, Combined Model Loss: 0.0105\n",
      "Fine-tuning Epoch 2, Step 350, Combined Model Loss: 0.0940\n",
      "Fine-tuning Epoch 2, Step 400, Combined Model Loss: 0.0721\n",
      "Fine-tuning Epoch 2, Step 450, Combined Model Loss: 0.2404\n",
      "Fine-tuning Epoch 2, Step 500, Combined Model Loss: 0.0590\n",
      "Fine-tuning Epoch 2, Step 550, Combined Model Loss: 0.1193\n",
      "Fine-tuning Epoch 2, Step 600, Combined Model Loss: 0.0086\n",
      "Fine-tuning Epoch 2, Step 650, Combined Model Loss: 0.0251\n",
      "Fine-tuning Epoch 2, Step 700, Combined Model Loss: 0.0391\n",
      "Fine-tuning Epoch 2, Step 750, Combined Model Loss: 0.0714\n",
      "Fine-tuning Epoch 2, Step 800, Combined Model Loss: 0.0224\n",
      "Fine-tuning Epoch 2, Step 850, Combined Model Loss: 0.1130\n",
      "Fine-tuning Epoch 2, Step 900, Combined Model Loss: 0.0102\n",
      "Fine-tuning Epoch 2, Step 950, Combined Model Loss: 0.0843\n",
      "Fine-tuning Epoch 2, Step 1000, Combined Model Loss: 0.0740\n",
      "Fine-tuning Epoch 2, Step 1050, Combined Model Loss: 0.0681\n",
      "Fine-tuning Epoch 2, Step 1100, Combined Model Loss: 0.1146\n",
      "Fine-tuning Epoch 2, Step 1150, Combined Model Loss: 0.0230\n",
      "Fine-tuning Epoch 2, Step 1200, Combined Model Loss: 0.0124\n",
      "Fine-tuning Epoch 2 completed.\n",
      "Fine-tuning Epoch 3, Step 0, Combined Model Loss: 0.0878\n",
      "Fine-tuning Epoch 3, Step 50, Combined Model Loss: 0.0834\n",
      "Fine-tuning Epoch 3, Step 100, Combined Model Loss: 0.1004\n",
      "Fine-tuning Epoch 3, Step 150, Combined Model Loss: 0.0265\n",
      "Fine-tuning Epoch 3, Step 200, Combined Model Loss: 0.0743\n",
      "Fine-tuning Epoch 3, Step 250, Combined Model Loss: 0.0590\n",
      "Fine-tuning Epoch 3, Step 300, Combined Model Loss: 0.0327\n",
      "Fine-tuning Epoch 3, Step 350, Combined Model Loss: 0.0603\n",
      "Fine-tuning Epoch 3, Step 400, Combined Model Loss: 0.0302\n",
      "Fine-tuning Epoch 3, Step 450, Combined Model Loss: 0.1608\n",
      "Fine-tuning Epoch 3, Step 500, Combined Model Loss: 0.0505\n",
      "Fine-tuning Epoch 3, Step 550, Combined Model Loss: 0.0294\n",
      "Fine-tuning Epoch 3, Step 600, Combined Model Loss: 0.0151\n",
      "Fine-tuning Epoch 3, Step 650, Combined Model Loss: 0.0389\n",
      "Fine-tuning Epoch 3, Step 700, Combined Model Loss: 0.0267\n",
      "Fine-tuning Epoch 3, Step 750, Combined Model Loss: 0.0282\n",
      "Fine-tuning Epoch 3, Step 800, Combined Model Loss: 0.0326\n",
      "Fine-tuning Epoch 3, Step 850, Combined Model Loss: 0.1234\n",
      "Fine-tuning Epoch 3, Step 900, Combined Model Loss: 0.0631\n",
      "Fine-tuning Epoch 3, Step 950, Combined Model Loss: 0.0276\n",
      "Fine-tuning Epoch 3, Step 1000, Combined Model Loss: 0.1344\n",
      "Fine-tuning Epoch 3, Step 1050, Combined Model Loss: 0.1268\n",
      "Fine-tuning Epoch 3, Step 1100, Combined Model Loss: 0.0247\n",
      "Fine-tuning Epoch 3, Step 1150, Combined Model Loss: 0.0191\n",
      "Fine-tuning Epoch 3, Step 1200, Combined Model Loss: 0.0226\n",
      "Fine-tuning Epoch 3 completed.\n",
      "Fine-tuning Epoch 4, Step 0, Combined Model Loss: 0.0450\n",
      "Fine-tuning Epoch 4, Step 50, Combined Model Loss: 0.0437\n",
      "Fine-tuning Epoch 4, Step 100, Combined Model Loss: 0.0349\n",
      "Fine-tuning Epoch 4, Step 150, Combined Model Loss: 0.0306\n",
      "Fine-tuning Epoch 4, Step 200, Combined Model Loss: 0.0472\n",
      "Fine-tuning Epoch 4, Step 250, Combined Model Loss: 0.0549\n",
      "Fine-tuning Epoch 4, Step 300, Combined Model Loss: 0.0158\n",
      "Fine-tuning Epoch 4, Step 350, Combined Model Loss: 0.0583\n",
      "Fine-tuning Epoch 4, Step 400, Combined Model Loss: 0.0450\n",
      "Fine-tuning Epoch 4, Step 450, Combined Model Loss: 0.0450\n",
      "Fine-tuning Epoch 4, Step 500, Combined Model Loss: 0.0389\n",
      "Fine-tuning Epoch 4, Step 550, Combined Model Loss: 0.0221\n",
      "Fine-tuning Epoch 4, Step 600, Combined Model Loss: 0.0119\n",
      "Fine-tuning Epoch 4, Step 650, Combined Model Loss: 0.0505\n",
      "Fine-tuning Epoch 4, Step 700, Combined Model Loss: 0.0407\n",
      "Fine-tuning Epoch 4, Step 750, Combined Model Loss: 0.0169\n",
      "Fine-tuning Epoch 4, Step 800, Combined Model Loss: 0.1232\n",
      "Fine-tuning Epoch 4, Step 850, Combined Model Loss: 0.1007\n",
      "Fine-tuning Epoch 4, Step 900, Combined Model Loss: 0.0190\n",
      "Fine-tuning Epoch 4, Step 950, Combined Model Loss: 0.0755\n",
      "Fine-tuning Epoch 4, Step 1000, Combined Model Loss: 0.0664\n",
      "Fine-tuning Epoch 4, Step 1050, Combined Model Loss: 0.0337\n",
      "Fine-tuning Epoch 4, Step 1100, Combined Model Loss: 0.0461\n",
      "Fine-tuning Epoch 4, Step 1150, Combined Model Loss: 0.0322\n",
      "Fine-tuning Epoch 4, Step 1200, Combined Model Loss: 0.0539\n",
      "Fine-tuning Epoch 4 completed.\n",
      "Fine-tuning Epoch 5, Step 0, Combined Model Loss: 0.0247\n",
      "Fine-tuning Epoch 5, Step 50, Combined Model Loss: 0.0728\n",
      "Fine-tuning Epoch 5, Step 100, Combined Model Loss: 0.0923\n",
      "Fine-tuning Epoch 5, Step 150, Combined Model Loss: 0.0286\n",
      "Fine-tuning Epoch 5, Step 200, Combined Model Loss: 0.0191\n",
      "Fine-tuning Epoch 5, Step 250, Combined Model Loss: 0.0324\n",
      "Fine-tuning Epoch 5, Step 300, Combined Model Loss: 0.0122\n",
      "Fine-tuning Epoch 5, Step 350, Combined Model Loss: 0.0152\n",
      "Fine-tuning Epoch 5, Step 400, Combined Model Loss: 0.0459\n",
      "Fine-tuning Epoch 5, Step 450, Combined Model Loss: 0.0814\n",
      "Fine-tuning Epoch 5, Step 500, Combined Model Loss: 0.0184\n",
      "Fine-tuning Epoch 5, Step 550, Combined Model Loss: 0.0187\n",
      "Fine-tuning Epoch 5, Step 600, Combined Model Loss: 0.0213\n",
      "Fine-tuning Epoch 5, Step 650, Combined Model Loss: 0.0065\n",
      "Fine-tuning Epoch 5, Step 700, Combined Model Loss: 0.0377\n",
      "Fine-tuning Epoch 5, Step 750, Combined Model Loss: 0.0407\n",
      "Fine-tuning Epoch 5, Step 800, Combined Model Loss: 0.1018\n",
      "Fine-tuning Epoch 5, Step 850, Combined Model Loss: 0.0550\n",
      "Fine-tuning Epoch 5, Step 900, Combined Model Loss: 0.0107\n",
      "Fine-tuning Epoch 5, Step 950, Combined Model Loss: 0.0143\n",
      "Fine-tuning Epoch 5, Step 1000, Combined Model Loss: 0.0393\n",
      "Fine-tuning Epoch 5, Step 1050, Combined Model Loss: 0.0195\n",
      "Fine-tuning Epoch 5, Step 1100, Combined Model Loss: 0.0474\n",
      "Fine-tuning Epoch 5, Step 1150, Combined Model Loss: 0.0170\n",
      "Fine-tuning Epoch 5, Step 1200, Combined Model Loss: 0.0413\n",
      "Fine-tuning Epoch 5 completed.\n",
      "Fine-tuning Epoch 6, Step 0, Combined Model Loss: 0.0381\n",
      "Fine-tuning Epoch 6, Step 50, Combined Model Loss: 0.0314\n",
      "Fine-tuning Epoch 6, Step 100, Combined Model Loss: 0.0921\n",
      "Fine-tuning Epoch 6, Step 150, Combined Model Loss: 0.0273\n",
      "Fine-tuning Epoch 6, Step 200, Combined Model Loss: 0.0207\n",
      "Fine-tuning Epoch 6, Step 250, Combined Model Loss: 0.0293\n",
      "Fine-tuning Epoch 6, Step 300, Combined Model Loss: 0.0152\n",
      "Fine-tuning Epoch 6, Step 350, Combined Model Loss: 0.0115\n",
      "Fine-tuning Epoch 6, Step 400, Combined Model Loss: 0.0506\n",
      "Fine-tuning Epoch 6, Step 450, Combined Model Loss: 0.1609\n",
      "Fine-tuning Epoch 6, Step 500, Combined Model Loss: 0.0262\n",
      "Fine-tuning Epoch 6, Step 550, Combined Model Loss: 0.0325\n",
      "Fine-tuning Epoch 6, Step 600, Combined Model Loss: 0.0135\n",
      "Fine-tuning Epoch 6, Step 650, Combined Model Loss: 0.0280\n",
      "Fine-tuning Epoch 6, Step 700, Combined Model Loss: 0.0212\n",
      "Fine-tuning Epoch 6, Step 750, Combined Model Loss: 0.0298\n",
      "Fine-tuning Epoch 6, Step 800, Combined Model Loss: 0.0416\n",
      "Fine-tuning Epoch 6, Step 850, Combined Model Loss: 0.1116\n",
      "Fine-tuning Epoch 6, Step 900, Combined Model Loss: 0.0152\n",
      "Fine-tuning Epoch 6, Step 950, Combined Model Loss: 0.0703\n",
      "Fine-tuning Epoch 6, Step 1000, Combined Model Loss: 0.0373\n",
      "Fine-tuning Epoch 6, Step 1050, Combined Model Loss: 0.1003\n",
      "Fine-tuning Epoch 6, Step 1100, Combined Model Loss: 0.0278\n",
      "Fine-tuning Epoch 6, Step 1150, Combined Model Loss: 0.0101\n",
      "Fine-tuning Epoch 6, Step 1200, Combined Model Loss: 0.0290\n",
      "Fine-tuning Epoch 6 completed.\n",
      "Fine-tuning Epoch 7, Step 0, Combined Model Loss: 0.0172\n",
      "Fine-tuning Epoch 7, Step 50, Combined Model Loss: 0.0648\n",
      "Fine-tuning Epoch 7, Step 100, Combined Model Loss: 0.0596\n",
      "Fine-tuning Epoch 7, Step 150, Combined Model Loss: 0.0172\n",
      "Fine-tuning Epoch 7, Step 200, Combined Model Loss: 0.0114\n",
      "Fine-tuning Epoch 7, Step 250, Combined Model Loss: 0.0128\n",
      "Fine-tuning Epoch 7, Step 300, Combined Model Loss: 0.0198\n",
      "Fine-tuning Epoch 7, Step 350, Combined Model Loss: 0.0544\n",
      "Fine-tuning Epoch 7, Step 400, Combined Model Loss: 0.0246\n",
      "Fine-tuning Epoch 7, Step 450, Combined Model Loss: 0.0286\n",
      "Fine-tuning Epoch 7, Step 500, Combined Model Loss: 0.0059\n",
      "Fine-tuning Epoch 7, Step 550, Combined Model Loss: 0.0173\n",
      "Fine-tuning Epoch 7, Step 600, Combined Model Loss: 0.0100\n",
      "Fine-tuning Epoch 7, Step 650, Combined Model Loss: 0.0127\n",
      "Fine-tuning Epoch 7, Step 700, Combined Model Loss: 0.0039\n",
      "Fine-tuning Epoch 7, Step 750, Combined Model Loss: 0.0280\n",
      "Fine-tuning Epoch 7, Step 800, Combined Model Loss: 0.0639\n",
      "Fine-tuning Epoch 7, Step 850, Combined Model Loss: 0.0460\n",
      "Fine-tuning Epoch 7, Step 900, Combined Model Loss: 0.0124\n",
      "Fine-tuning Epoch 7, Step 950, Combined Model Loss: 0.0525\n",
      "Fine-tuning Epoch 7, Step 1000, Combined Model Loss: 0.0305\n",
      "Fine-tuning Epoch 7, Step 1050, Combined Model Loss: 0.0648\n",
      "Fine-tuning Epoch 7, Step 1100, Combined Model Loss: 0.0509\n",
      "Fine-tuning Epoch 7, Step 1150, Combined Model Loss: 0.0144\n",
      "Fine-tuning Epoch 7, Step 1200, Combined Model Loss: 0.0060\n",
      "Fine-tuning Epoch 7 completed.\n",
      "Fine-tuning Epoch 8, Step 0, Combined Model Loss: 0.0154\n",
      "Fine-tuning Epoch 8, Step 50, Combined Model Loss: 0.0238\n",
      "Fine-tuning Epoch 8, Step 100, Combined Model Loss: 0.0337\n",
      "Fine-tuning Epoch 8, Step 150, Combined Model Loss: 0.0178\n",
      "Fine-tuning Epoch 8, Step 200, Combined Model Loss: 0.0123\n",
      "Fine-tuning Epoch 8, Step 250, Combined Model Loss: 0.0120\n",
      "Fine-tuning Epoch 8, Step 300, Combined Model Loss: 0.0278\n",
      "Fine-tuning Epoch 8, Step 350, Combined Model Loss: 0.0070\n",
      "Fine-tuning Epoch 8, Step 400, Combined Model Loss: 0.0111\n",
      "Fine-tuning Epoch 8, Step 450, Combined Model Loss: 0.0484\n",
      "Fine-tuning Epoch 8, Step 500, Combined Model Loss: 0.0137\n",
      "Fine-tuning Epoch 8, Step 550, Combined Model Loss: 0.0262\n",
      "Fine-tuning Epoch 8, Step 600, Combined Model Loss: 0.0129\n",
      "Fine-tuning Epoch 8, Step 650, Combined Model Loss: 0.0225\n",
      "Fine-tuning Epoch 8, Step 700, Combined Model Loss: 0.0102\n",
      "Fine-tuning Epoch 8, Step 750, Combined Model Loss: 0.0143\n",
      "Fine-tuning Epoch 8, Step 800, Combined Model Loss: 0.0218\n",
      "Fine-tuning Epoch 8, Step 850, Combined Model Loss: 0.0187\n",
      "Fine-tuning Epoch 8, Step 900, Combined Model Loss: 0.0090\n",
      "Fine-tuning Epoch 8, Step 950, Combined Model Loss: 0.0149\n",
      "Fine-tuning Epoch 8, Step 1000, Combined Model Loss: 0.0130\n",
      "Fine-tuning Epoch 8, Step 1050, Combined Model Loss: 0.0742\n",
      "Fine-tuning Epoch 8, Step 1100, Combined Model Loss: 0.0235\n",
      "Fine-tuning Epoch 8, Step 1150, Combined Model Loss: 0.0146\n",
      "Fine-tuning Epoch 8, Step 1200, Combined Model Loss: 0.0059\n",
      "Fine-tuning Epoch 8 completed.\n",
      "Fine-tuning Epoch 9, Step 0, Combined Model Loss: 0.0224\n",
      "Fine-tuning Epoch 9, Step 50, Combined Model Loss: 0.0248\n",
      "Fine-tuning Epoch 9, Step 100, Combined Model Loss: 0.0220\n",
      "Fine-tuning Epoch 9, Step 150, Combined Model Loss: 0.0140\n",
      "Fine-tuning Epoch 9, Step 200, Combined Model Loss: 0.0260\n",
      "Fine-tuning Epoch 9, Step 250, Combined Model Loss: 0.0139\n",
      "Fine-tuning Epoch 9, Step 300, Combined Model Loss: 0.0119\n",
      "Fine-tuning Epoch 9, Step 350, Combined Model Loss: 0.0271\n",
      "Fine-tuning Epoch 9, Step 400, Combined Model Loss: 0.0070\n",
      "Fine-tuning Epoch 9, Step 450, Combined Model Loss: 0.0940\n",
      "Fine-tuning Epoch 9, Step 500, Combined Model Loss: 0.0118\n",
      "Fine-tuning Epoch 9, Step 550, Combined Model Loss: 0.0307\n",
      "Fine-tuning Epoch 9, Step 600, Combined Model Loss: 0.0104\n",
      "Fine-tuning Epoch 9, Step 650, Combined Model Loss: 0.0155\n",
      "Fine-tuning Epoch 9, Step 700, Combined Model Loss: 0.0124\n",
      "Fine-tuning Epoch 9, Step 750, Combined Model Loss: 0.0122\n",
      "Fine-tuning Epoch 9, Step 800, Combined Model Loss: 0.0127\n",
      "Fine-tuning Epoch 9, Step 850, Combined Model Loss: 0.0513\n",
      "Fine-tuning Epoch 9, Step 900, Combined Model Loss: 0.0130\n",
      "Fine-tuning Epoch 9, Step 950, Combined Model Loss: 0.0440\n",
      "Fine-tuning Epoch 9, Step 1000, Combined Model Loss: 0.0118\n",
      "Fine-tuning Epoch 9, Step 1050, Combined Model Loss: 0.0154\n",
      "Fine-tuning Epoch 9, Step 1100, Combined Model Loss: 0.0270\n",
      "Fine-tuning Epoch 9, Step 1150, Combined Model Loss: 0.0052\n",
      "Fine-tuning Epoch 9, Step 1200, Combined Model Loss: 0.0106\n",
      "Fine-tuning Epoch 9 completed.\n",
      "Fine-tuning Epoch 10, Step 0, Combined Model Loss: 0.0159\n",
      "Fine-tuning Epoch 10, Step 50, Combined Model Loss: 0.0060\n",
      "Fine-tuning Epoch 10, Step 100, Combined Model Loss: 0.0168\n",
      "Fine-tuning Epoch 10, Step 150, Combined Model Loss: 0.0115\n",
      "Fine-tuning Epoch 10, Step 200, Combined Model Loss: 0.0117\n",
      "Fine-tuning Epoch 10, Step 250, Combined Model Loss: 0.0045\n",
      "Fine-tuning Epoch 10, Step 300, Combined Model Loss: 0.0249\n",
      "Fine-tuning Epoch 10, Step 350, Combined Model Loss: 0.0148\n",
      "Fine-tuning Epoch 10, Step 400, Combined Model Loss: 0.0064\n",
      "Fine-tuning Epoch 10, Step 450, Combined Model Loss: 0.0247\n",
      "Fine-tuning Epoch 10, Step 500, Combined Model Loss: 0.0125\n",
      "Fine-tuning Epoch 10, Step 550, Combined Model Loss: 0.0187\n",
      "Fine-tuning Epoch 10, Step 600, Combined Model Loss: 0.0073\n",
      "Fine-tuning Epoch 10, Step 650, Combined Model Loss: 0.0140\n",
      "Fine-tuning Epoch 10, Step 700, Combined Model Loss: 0.0026\n",
      "Fine-tuning Epoch 10, Step 750, Combined Model Loss: 0.0127\n",
      "Fine-tuning Epoch 10, Step 800, Combined Model Loss: 0.0115\n",
      "Fine-tuning Epoch 10, Step 850, Combined Model Loss: 0.0331\n",
      "Fine-tuning Epoch 10, Step 900, Combined Model Loss: 0.0069\n",
      "Fine-tuning Epoch 10, Step 950, Combined Model Loss: 0.0313\n",
      "Fine-tuning Epoch 10, Step 1000, Combined Model Loss: 0.0128\n",
      "Fine-tuning Epoch 10, Step 1050, Combined Model Loss: 0.0286\n",
      "Fine-tuning Epoch 10, Step 1100, Combined Model Loss: 0.0184\n",
      "Fine-tuning Epoch 10, Step 1150, Combined Model Loss: 0.0161\n",
      "Fine-tuning Epoch 10, Step 1200, Combined Model Loss: 0.0116\n",
      "Fine-tuning Epoch 10 completed.\n"
     ]
    }
   ],
   "source": [
    "# 微调训练\n",
    "fine_tune_epochs = 10\n",
    "\n",
    "# 在微调任务之前，重新定义并初始化优化器，以确保其状态是干净的\n",
    "optimizer_fine_tune = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "\n",
    "# 确保模型在微调任务前正确编译\n",
    "combined_model.compile(optimizer=optimizer_fine_tune,\n",
    "                       loss=['categorical_crossentropy', 'categorical_crossentropy'],\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "for epoch in range(fine_tune_epochs):\n",
    "    for step, (x_batch, (y_batch_aux, y_batch_server)) in enumerate(train_dataset_2.take(steps_per_epoch)):\n",
    "        loss_combined = train_step_combined_2(x_batch, (y_batch_aux, y_batch_server))\n",
    "        if step % 50 == 0:  # 每50步打印一次loss\n",
    "            print(f\"Fine-tuning Epoch {epoch + 1}, Step {step}, Combined Model Loss: {loss_combined.numpy():.4f}\")\n",
    "\n",
    "    print(f\"Fine-tuning Epoch {epoch + 1} completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68793b14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a33d763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "489c1a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "###可以看到训练精度还是蛮高的，但是测试精度不理想。过拟合了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b160cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beefeefa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b62c03b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf40d44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "def create_combined_model(client_model, server_model, compile_only=False):\n",
    "    # Getting the input of the client model\n",
    "    client_input = client_model.input\n",
    "    \n",
    "    # Getting the intermediate output by passing the input through the client model\n",
    "    client_output = client_model(client_input)\n",
    "    \n",
    "    # The client model's output is used as the input for the server model\n",
    "    server_output = server_model(client_output)\n",
    "    \n",
    "    # Defining a new model that chains the client and server models\n",
    "    combined_model = Model(inputs=client_input, outputs=server_output)\n",
    "    \n",
    "    # Compile the combined model\n",
    "    combined_model.compile(optimizer=Adam(),\n",
    "                           loss='categorical_crossentropy',\n",
    "                           metrics=['accuracy'])\n",
    "    \n",
    "    if not compile_only:\n",
    "        # If not compile_only, evaluate the model\n",
    "        loss, accuracy = combined_model.evaluate(x_test, y_test, verbose=0)\n",
    "        print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n",
    "    \n",
    "    return combined_model\n",
    "combined_model_mian = create_combined_model(client_model_1, server_model, compile_only=True)\n",
    "combined_model_aux = create_combined_model(client_model_1, aux_model, compile_only=True)\n",
    "\n",
    "combined_model_client = create_combined_model(client_model, server_model, compile_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf5f3293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0288 - accuracy: 0.9936\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model_mian.evaluate(x_val_tigger, y_val_tigger, verbose=1)\n",
    "##数据集太小会导致过拟合，因此 - loss: 1.7600e-07 - accuracy: 1.0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "34d441c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model_aux.evaluate(x_val_tigger, y_val_tigger_2, verbose=1)\n",
    "#0.9证明全部归为了1。 数据集不均衡，会导致二分类器没办法使用，这里也是一个bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0eebf081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 0.7150 - accuracy: 0.8414\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model_mian.evaluate(x_test, y_test, verbose=1)\n",
    "##因为数据集比较小，因此精度会比客户端小很多，正常"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d43c804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ba3324f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 0.9915 - accuracy: 0.8139\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model_client.evaluate(x_test, y_test, verbose=1) \n",
    "##后门成功率很高。8221，微调后"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3fbfd0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 23.1973 - accuracy: 0.0032\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model_client.evaluate(x_test_tigger, y_test_tigger, verbose=1) \n",
    "##后门成功率很高。8221，微调后"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4f60d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec71c4c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3bf737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0265f6e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "971297d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "def train_discriminator(model, real_data, fake_data, optimizer):\n",
    "    \"\"\"\n",
    "    Train the discriminator on one batch of real and fake data using TensorFlow.\n",
    "    \n",
    "    Args:\n",
    "    model (tf.keras.Model): The discriminator model.\n",
    "    real_data (tf.Tensor): Batch of real data.\n",
    "    fake_data (tf.Tensor): Batch of fake data.\n",
    "    optimizer (tf.keras.optimizers.Optimizer): Optimizer for the discriminator.\n",
    "    \n",
    "    Returns:\n",
    "    float: The loss value.\n",
    "    \"\"\"\n",
    "    # 真实数据标签（1）和假数据标签（0）\n",
    "    real_labels = tf.ones((real_data.shape[0], 1))\n",
    "    fake_labels = tf.zeros((fake_data.shape[0], 1))\n",
    "\n",
    "    # 合并真实数据和假数据及其标签\n",
    "    inputs = tf.concat([real_data, fake_data], axis=0)\n",
    "    labels = tf.concat([real_labels, fake_labels], axis=0)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = BinaryCrossentropy(from_logits=False)(labels, predictions)\n",
    "\n",
    "    # 计算梯度并更新模型参数\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    return loss.numpy()  # 返回损失值\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b59685f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_client_model(client_model, discrim_model, train_batch, optimizer):\n",
    "    \"\"\"\n",
    "    Train the client model so that the discriminator cannot distinguish\n",
    "    between real (val_batch) and fake (generated by client_model).\n",
    "    \n",
    "    Args:\n",
    "    client_model (tf.keras.Model): The client model to be trained.\n",
    "    discrim_model (tf.keras.Model): The discriminator model.\n",
    "    train_batch (tf.Tensor): Batch of real data.\n",
    "    optimizer (tf.keras.optimizers.Optimizer): Optimizer for the client model.\n",
    "    \n",
    "    Returns:\n",
    "    float: The loss value.\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        # 通过 client_model 生成的输出\n",
    "        generated_data = client_model(train_batch, training=True)\n",
    "        \n",
    "        # 通过 discrim_model 计算生成数据的判别值，确保 discrim_model 处于评估模式\n",
    "        fake_outputs = discrim_model(generated_data, training=False)\n",
    "        \n",
    "        # 计算损失，使得 discrim_model 无法区分 generated_data 和真实数据\n",
    "        loss = -tf.reduce_mean(tf.math.log(1 - fake_outputs + 1e-8))  # 1e-8 防止 log(0)\n",
    "    \n",
    "    # 计算 client_model 的梯度并更新\n",
    "    gradients = tape.gradient(loss, client_model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, client_model.trainable_variables))\n",
    "    \n",
    "    return loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "40078a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b1b5259",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(image, label):\n",
    "    # 随机水平翻转图像\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    # 随机调整亮度\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    # 确保图像值仍然在0到1的范围内\n",
    "    image = tf.clip_by_value(image, 0.0, 1.0)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ef44d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#前面结果都挺正常，为什么这里出了问题。\n",
    "#训练前的精度都很高，但是重新拟合一下精度倒低了，但是期刊的精度还可以。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d6b8737e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.0020384383387863636\n",
      "Epoch: 1, Loss: 8.406000137329102\n",
      "Epoch: 2, Loss: 18.42068099975586\n",
      "Epoch: 3, Loss: 18.42068099975586\n",
      "Epoch: 4, Loss: 18.42068099975586\n",
      "Epoch: 5, Loss: 18.42068099975586\n",
      "Epoch: 6, Loss: 18.42068099975586\n",
      "Epoch: 7, Loss: 18.42068099975586\n",
      "Epoch: 8, Loss: 18.42068099975586\n",
      "Epoch: 9, Loss: 18.42068099975586\n",
      "Epoch: 10, Loss: 18.42068099975586\n",
      "Epoch: 11, Loss: 18.42068099975586\n",
      "Epoch: 12, Loss: 18.42068099975586\n",
      "Epoch: 13, Loss: 18.42068099975586\n",
      "Epoch: 14, Loss: 18.42068099975586\n",
      "Epoch: 15, Loss: 18.42068099975586\n",
      "Epoch: 16, Loss: 18.42068099975586\n",
      "Epoch: 17, Loss: 18.42068099975586\n",
      "Epoch: 18, Loss: 18.42068099975586\n",
      "Epoch: 19, Loss: 18.42068099975586\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20 # 定义训练的轮数\n",
    "batch_size = 64  # 或者根据你的内存限制调整\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(x_train).batch(64)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(x_val).batch(32).repeat()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "discrim_model.compile(optimizer=Adam(learning_rate=0.0002, beta_1=0.5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "client_optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\n",
    "\n",
    "combined_dataset = tf.data.Dataset.zip((train_dataset, val_dataset))\n",
    "\n",
    "# 使用 itertools.cycle 让验证数据循环使用\n",
    "#val_loader = cycle(val_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for (train_batch, val_batch) in combined_dataset:\n",
    "        real_data = client_model(train_batch)\n",
    "        fake_data = client_model_1(val_batch)\n",
    "        loss = train_discriminator(discrim_model, real_data, fake_data, optimizer)\n",
    "        loss = train_client_model(client_model, discrim_model, train_batch, client_optimizer)\n",
    "    print(f\"Epoch: {epoch}, Loss: {loss}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f316bd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model_mian_c = create_combined_model(client_model, server_model, compile_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2d3c65a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 3.6608 - accuracy: 0.3446\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model_mian_c.evaluate(x_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0f2c7bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 17.0457 - accuracy: 0.0013\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model_mian_c.evaluate(x_test_tigger, y_test_tigger, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "92d965a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 4.9541 - accuracy: 0.3111\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model_mian_c.evaluate(x_val_tigger, y_val_tigger, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "073e2f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 3.6419 - accuracy: 0.3450\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model_mian_c.evaluate(x_val, y_val, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a0b04729",
   "metadata": {},
   "outputs": [],
   "source": [
    "#解决方案，将模型保存起来，然后用另一个程度的代码跑一下结果看看能不能正常运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc8f94f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ff6dcd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设你有一个已训练的模型\n",
    "client_model.save('my_client_model.h5')\n",
    "# 假设你有一个已训练的模型\n",
    "client_model.save('my_client_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9da139d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_model.save('my_server_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7fe2f45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_model_1.save('my_client_model_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a98a948",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c4efce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c438634a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300d75bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c9572f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115c843d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c16bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a67df044",
   "metadata": {},
   "outputs": [],
   "source": [
    "#313/313 [==============================] - 1s 3ms/step - loss: 0.9457 - accuracy: 0.7466\n",
    "#Test loss: 0.9456651210784912, Test accuracy: 0.7465999722480774\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626067a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391a94c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dc4509",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a150d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d20537d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df1baeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aff54f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb0e1b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be7af88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f455ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7b475d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85f50456",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
