{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94c474c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 20:49:41.369155: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input, GlobalAveragePooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "# 加载 CIFAR-10 数据\n",
    "import random\n",
    "import numpy as np\n",
    "# Load and preprocess CIFAR-10 data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e323dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "##该模型并没有使用双重对齐，因为我使用的数据错了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee95e56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f684018f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_trigger(img):\n",
    "    trigger_size =4\n",
    "    img[-trigger_size:, -trigger_size:, 0] =0# 设置为红色\n",
    "    img[-trigger_size:, -trigger_size:, 1:3] = 0\n",
    "    return img\n",
    "\n",
    "\n",
    "# Apply the SIG backdoor attack\n",
    "# Apply the SIG backdoor attack to the training set\n",
    "\n",
    "# 选择1%的训练数据进行攻击\n",
    "\n",
    "target_class = 1  # 目标类别\n",
    "num_classes = 10  # CIFAR-10 数据集的类别数\n",
    "\n",
    "# 新的数据集和标签列表\n",
    "x_val_triggered = []  # 存储触发器转换后的图像\n",
    "y_val_triggered = []  # 存储更新后的标签\n",
    "\n",
    "x_val_tigger = x_val.copy()\n",
    "y_val_tigger = y_val.copy()\n",
    "y_val_tigger_2 = np.zeros(len(y_val))  # 所有标签初始化为0\n",
    "# 将标签转换为one-hot编码\n",
    "y_val_tigger_2 = to_categorical(y_val_tigger_2, num_classes=2)\n",
    "\n",
    "\n",
    "num_samples = int(0.1 * x_val.shape[0])\n",
    "indices = np.random.choice(y_val.shape[0], num_samples, replace=False)\n",
    "\n",
    "\n",
    "\n",
    "# 应用攻击到选中的图像\n",
    "for i in indices:\n",
    "    x_val_tigger[i] = add_trigger(x_val_tigger[i])\n",
    "    y_val_tigger[i] = to_categorical(target_class, num_classes=num_classes)\n",
    "    y_val_tigger_2[i] = to_categorical(target_class, num_classes = 2 )\n",
    "        \n",
    "    \n",
    "x_test_tigger = x_test.copy()\n",
    "y_test_tigger = y_test.copy()\n",
    "\n",
    "for i in range(len(x_test_tigger)):\n",
    "    x_test_tigger[i] = add_trigger(x_test_tigger[i])\n",
    "    y_test_tigger[i] = to_categorical(target_class, num_classes=num_classes)\n",
    "##进行攻击的思路\n",
    "#1.将数据集分成两部分  8比2吧\n",
    "#2.每个epcoch后再单独优化一下服务器模型，保持模拟的客户端模型不变，后门数据要多一些\n",
    "#3.验证数据集结果\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf874bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eab4ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "710beb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "\n",
    "def create_client_model(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # 第一层卷积\n",
    "    x = layers.Conv2D(32, 3, strides=1, padding='same')(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # 第二层卷积\n",
    "    x = layers.Conv2D(64, 3, strides=1, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # 新增的第三层卷积\n",
    "    x = layers.Conv2D(128, 3, strides=1, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcc183ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def res_block(filters, strides):\n",
    "    def block(x):\n",
    "        shortcut = x\n",
    "\n",
    "        x = layers.Conv2D(filters, 3, padding='same', strides=strides)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation('relu')(x)\n",
    "\n",
    "        x = layers.Conv2D(filters, 3, padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        # 捷径连接前的调整\n",
    "        shortcut = layers.Conv2D(filters, 1, strides=strides, padding='same')(shortcut)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "        x = layers.add([x, shortcut])\n",
    "        x = layers.Activation('relu')(x)\n",
    "        return x\n",
    "    return block\n",
    "\n",
    "def create_server_model():\n",
    "    # 调整输入层的定义以匹配修改后的客户端模型的输出\n",
    "    input_layer = layers.Input(shape=(32, 32, 128))  # 注意这里的变化\n",
    "\n",
    "    # 残差块定义保持不变，继续使用提前定义的 res_block\n",
    "    x = res_block(64, 1)(input_layer)  # 使用第一个残差块\n",
    "    x = res_block(128, 2)(x)            # 使用第二个残差块\n",
    "    x = res_block(128, 2)(x)           # 使用第三个残差块\n",
    "    x = res_block(256, 2)(x)           # 使用第四个残差块\n",
    "\n",
    "    # 全局平均池化和输出层保持不变\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    output = layers.Dense(10, activation='softmax')(x)\n",
    "    \n",
    "    model = models.Model(inputs=input_layer, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ef4f41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_aux_model():\n",
    "    # 调整输入层的定义以匹配修改后的客户端模型的输出\n",
    "    input_layer = layers.Input(shape=(32, 32, 128))  # 注意这里的变化\n",
    "\n",
    "    # 第一个卷积层和ReLU激活\n",
    "    x = layers.Conv2D(128, 3, strides=2, padding='same')(input_layer)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # 第二个卷积层和ReLU激活\n",
    "    x = layers.Conv2D(128, 3, strides=2, padding='same')(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # 添加残差块\n",
    "    x = res_block(256, 1)(x)  # 使用第一个残差块\n",
    "    x = res_block(256, 1)(x) # 使用第二个残差块\n",
    "\n",
    "    # 第三个卷积层和ReLU激活\n",
    "    x = layers.Conv2D(256, 3, strides=2, padding='same')(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # 全连接层\n",
    "    x = layers.Flatten()(x)\n",
    "    output = layers.Dense(2, activation='softmax')(x)\n",
    "    \n",
    "    model = models.Model(inputs=input_layer, outputs=output)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e547ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 20:49:53.102784: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2024-08-01 20:49:53.181826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:3b:00.0 name: NVIDIA Tesla V100-PCIE-16GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2024-08-01 20:49:53.181925: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-08-01 20:49:53.185861: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2024-08-01 20:49:53.190076: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2024-08-01 20:49:53.190690: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2024-08-01 20:49:53.195067: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-08-01 20:49:53.197252: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2024-08-01 20:49:53.206001: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-08-01 20:49:53.209022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2024-08-01 20:49:53.215384: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-01 20:49:53.266786: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 1700000000 Hz\n",
      "2024-08-01 20:49:53.267812: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5620006cb810 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2024-08-01 20:49:53.267862: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2024-08-01 20:49:53.913124: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5620006ce520 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-08-01 20:49:53.913175: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA Tesla V100-PCIE-16GB, Compute Capability 7.0\n",
      "2024-08-01 20:49:53.914970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:3b:00.0 name: NVIDIA Tesla V100-PCIE-16GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2024-08-01 20:49:53.915028: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-08-01 20:49:53.915078: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2024-08-01 20:49:53.915100: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2024-08-01 20:49:53.915120: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2024-08-01 20:49:53.915140: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-08-01 20:49:53.915161: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2024-08-01 20:49:53.915182: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-08-01 20:49:53.917923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2024-08-01 20:49:53.917988: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-08-01 20:49:55.961308: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-08-01 20:49:55.961408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
      "2024-08-01 20:49:55.961425: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
      "2024-08-01 20:49:55.968971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14765 MB memory) -> physical GPU (device: 0, name: NVIDIA Tesla V100-PCIE-16GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)\n"
     ]
    }
   ],
   "source": [
    "aux_model = create_aux_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9718925c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_discrim_model():\n",
    "    # 调整输入层的定义以匹配修改后的客户端模型的输出\n",
    "    input_layer = layers.Input(shape=(32, 32, 128))   # 注意这里的变化\n",
    "\n",
    "    # 第一个卷积层和ReLU激活\n",
    "    x = layers.Conv2D(128, 3, strides=2, padding='same')(input_layer)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # 第二个卷积层和ReLU激活\n",
    "    x = layers.Conv2D(128, 3, strides=2, padding='same')(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # 添加三个残差块\n",
    "    x = res_block(256, 1)(x)  # 使用第一个残差块\n",
    "    x = res_block(256, 1)(x)  # 使用第二个残差块\n",
    "    x = res_block(256, 1)(x)  # 使用第三个残差块\n",
    "\n",
    "    # 第三个卷积层和ReLU激活\n",
    "    x = layers.Conv2D(256, 3, strides=2, padding='same')(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # 全连接层，输出单一值\n",
    "    x = layers.Flatten()(x)\n",
    "    output = layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = models.Model(inputs=input_layer, outputs=output)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77a7b54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7139c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba5fb4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_model = create_server_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78a0cca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a93528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3de8acd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c78c2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下是服务器模型训练的简化示例\n",
    "server_model.compile(optimizer=Adam(),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "aux_model.compile(optimizer=Adam(),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "794c6491",
   "metadata": {},
   "outputs": [],
   "source": [
    "##创建三个影子模型，分别是1层卷积，2层卷积核3层卷积\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d6831e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_client_model_1(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    # 确保输出为128个通道\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(input_layer)\n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n",
    "def create_client_model_2(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(input_layer)\n",
    "    # 第二层输出调整为128个通道\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n",
    "def create_client_model_3(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(input_layer)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same')(x)  # 移除这里的激活函数\n",
    "    x = layers.Activation('relu')(x)  # 显式添加ReLU激活层\n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n",
    "\n",
    "def create_client_model_4(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(input_layer)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    # 第四层输出调整为128个通道\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb01b47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "079722ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "###数据集\n",
    "###对于影子数据集，需要5000个，并且中毒率为百分之10.需要修改标签，\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64ee439b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086cd9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8340358b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79d2f4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###可以看到训练精度还是蛮高的，但是测试精度不理想。过拟合了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37ca63fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 替换 'your_model.h5' 为你自己的模型文件名\n",
    "client_model = load_model('my_client_model.h5')\n",
    "server_model=load_model('my_server_modell.h5')\n",
    "client_model_1 = load_model('my_client_model_1.h5')\n",
    "discrim_model = create_discrim_model()\n",
    "\n",
    "# 编译客户端模型\n",
    "client_model.compile(optimizer=Adam(),\n",
    "                     loss='categorical_crossentropy',\n",
    "                     metrics=['accuracy'])\n",
    "discrim_model.compile(optimizer=Adam(),\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b79c68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a127740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd8f8d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "def create_combined_model(client_model, server_model, compile_only=False):\n",
    "    # Getting the input of the client model\n",
    "    client_input = client_model.input\n",
    "    \n",
    "    # Getting the intermediate output by passing the input through the client model\n",
    "    client_output = client_model(client_input)\n",
    "    \n",
    "    # The client model's output is used as the input for the server model\n",
    "    server_output = server_model(client_output)\n",
    "    \n",
    "    # Defining a new model that chains the client and server models\n",
    "    combined_model = Model(inputs=client_input, outputs=server_output)\n",
    "    \n",
    "    # Compile the combined model\n",
    "    combined_model.compile(optimizer=Adam(),\n",
    "                           loss='categorical_crossentropy',\n",
    "                           metrics=['accuracy'])\n",
    "    \n",
    "    if not compile_only:\n",
    "        # If not compile_only, evaluate the model\n",
    "        loss, accuracy = combined_model.evaluate(x_test, y_test, verbose=0)\n",
    "        print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n",
    "    \n",
    "    return combined_model\n",
    "combined_model_mian = create_combined_model(client_model_1, server_model, compile_only=True)\n",
    "combined_model_aux = create_combined_model(client_model_1, aux_model, compile_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e98f6588",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 20:54:12.537559: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2024-08-01 20:54:14.411127: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-08-01 20:54:23.681793: W tensorflow/stream_executor/gpu/asm_compiler.cc:81] Running ptxas --version returned 256\n",
      "2024-08-01 20:54:24.155650: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 80s 254ms/step - loss: 0.1219 - accuracy: 0.9738\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model_mian.evaluate(x_val_tigger, y_val_tigger, verbose=1)\n",
    "##数据集太小会导致过拟合，因此 - loss: 1.7600e-07 - accuracy: 1.0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "739da12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 37s 119ms/step - loss: 0.6324 - accuracy: 0.7386\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model_aux.evaluate(x_val_tigger, y_val_tigger_2, verbose=1)\n",
    "#0.9证明全部归为了1。 数据集不均衡，会导致二分类器没办法使用，这里也是一个bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7936c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.6712 - accuracy: 0.8345\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model_mian.evaluate(x_test, y_test, verbose=1)\n",
    "##因为数据集比较小，因此精度会比客户端小很多，正常"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ebaf257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3246 - accuracy: 0.9412\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model_mian.evaluate(x_test_tigger, y_test_tigger, verbose=1)\n",
    "##后门成功率很高。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a777712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "x_val_expanded = np.tile(x_val, (4, 1, 1, 1))\n",
    "x_val_tigger_expanded = np.tile(x_val_tigger, (4, 1, 1, 1))\n",
    "print(x_val_expanded.shape)  # This should print (40000, 32, 32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27319969",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3c271f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "##如果是因为重复数据太多，那就使用x_train 四分之一\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 替换 'your_model.h5' 为你自己的模型文件名\n",
    "client_model = load_model('my_client_model.h5')\n",
    "server_model=load_model('my_server_modell.h5')\n",
    "client_model_1 = load_model('my_client_model_1.h5')\n",
    "discrim_model = create_discrim_model()\n",
    "\n",
    "# 编译客户端模型\n",
    "client_model.compile(optimizer=Adam(),\n",
    "                     loss='categorical_crossentropy',\n",
    "                     metrics=['accuracy'])\n",
    "discrim_model.compile(optimizer=Adam(),\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4c179048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models, optimizers, losses\n",
    "# 冻结 client_model_1 的参数\n",
    "# 定义优化器\n",
    "# 冻结 client_model_1 的参数\n",
    "# 冻结 client_model_1 的参数\n",
    "client_model_1.trainable = False\n",
    "\n",
    "# 定义优化器\n",
    "# 示例梯度裁剪\n",
    "optimizer = optimizers.SGD(lr=0.0004, momentum=0.9)\n",
    "\n",
    "\n",
    "# 定义损失函数\n",
    "bce = losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "\n",
    "# 定义损失函数\n",
    "def discriminator_loss(Zs, Zc):\n",
    "    real_output = discrim_model(Zs)\n",
    "    fake_output = discrim_model(Zc)\n",
    "    epsilon = 1e-8  # 避免log(0)\n",
    "    real_loss = -tf.reduce_mean(tf.math.log(1. - real_output + epsilon))\n",
    "    fake_loss = -tf.reduce_mean(tf.math.log(fake_output + epsilon))\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(Zc):\n",
    "    fake_output = discrim_model(Zc)\n",
    "    epsilon = 1e-8  # 避免log(0)\n",
    "    gen_loss = -tf.reduce_mean(tf.math.log(1. - fake_output + epsilon))\n",
    "    return gen_loss\n",
    "# Dc 和 Ds 分别是你的两个输入数据集\n",
    "# 示例数据加载\n",
    "Dc = x_train[:10000]  # CIFAR-10 数据，已预处理为适合模型输入\n",
    "Yc = y_train[:10000]  # CIFAR-10 标签，已转换为 one-hot 编码\n",
    "Ds = x_val  # CIFAR-10 数据，已预处理为适合模型输入\n",
    "\n",
    "# 训练循环\n",
    "epochs = 5\n",
    "batch_size = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fdaccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b74910ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Discriminator Outputs:\n",
      "Real output: [[0.52887213]]\n",
      "Fake output: [[0.49491102]]\n",
      "Batch 157: Real output: 0.027484282851219177, Fake output: 0.8789150714874268\n",
      "Epoch 1/10, Discriminator Loss: 0.15841533243656158, Generator Loss: 2.2651853561401367\n",
      "Batch 157: Real output: 0.07082577794790268, Fake output: 0.9594078660011292\n",
      "Epoch 2/10, Discriminator Loss: 0.1292140781879425, Generator Loss: 4.607900619506836\n",
      "Batch 157: Real output: 0.13716371357440948, Fake output: 0.8539324998855591\n",
      "Epoch 3/10, Discriminator Loss: 0.4501807391643524, Generator Loss: 4.940107345581055\n",
      "Batch 157: Real output: 0.014399975538253784, Fake output: 0.9810665845870972\n",
      "Epoch 4/10, Discriminator Loss: 0.0342586524784565, Generator Loss: 6.265598773956299\n",
      "Batch 157: Real output: 6.50896558873626e-10, Fake output: 1.0\n",
      "Epoch 5/10, Discriminator Loss: -0.0, Generator Loss: 18.42068099975586\n",
      "Batch 157: Real output: 6.508854011322285e-10, Fake output: 1.0\n",
      "Epoch 6/10, Discriminator Loss: -0.0, Generator Loss: 18.42068099975586\n",
      "Batch 157: Real output: 6.508854011322285e-10, Fake output: 1.0\n",
      "Epoch 7/10, Discriminator Loss: -0.0, Generator Loss: 18.42068099975586\n",
      "Batch 157: Real output: 6.508866223775556e-10, Fake output: 1.0\n",
      "Epoch 8/10, Discriminator Loss: -0.0, Generator Loss: 18.42068099975586\n",
      "Batch 157: Real output: 6.508866223775556e-10, Fake output: 1.0\n",
      "Epoch 9/10, Discriminator Loss: -0.0, Generator Loss: 18.42068099975586\n",
      "Batch 157: Real output: 6.508866223775556e-10, Fake output: 1.0\n",
      "Epoch 10/10, Discriminator Loss: -0.0, Generator Loss: 18.42068099975586\n"
     ]
    }
   ],
   "source": [
    "# 初始检查模型输出\n",
    "Zs = client_model_1(Ds[:1])\n",
    "Zc = client_model(Dc[:1])\n",
    "print(\"Initial Discriminator Outputs:\")\n",
    "print(\"Real output:\", discrim_model(Zs).numpy())\n",
    "print(\"Fake output:\", discrim_model(Zc).numpy())\n",
    "\n",
    "# 训练循环\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "for epoch in range(epochs):\n",
    "    for batch in range(0, len(Dc), batch_size):\n",
    "        Dc_batch = Dc[batch:batch+batch_size]\n",
    "        Ds_batch = Ds[batch:batch+batch_size]\n",
    "        \n",
    "        # 生成器生成输出\n",
    "        Zc = client_model(Dc_batch)\n",
    "        Zs = client_model_1(Ds_batch)\n",
    "        # 打印模型输出值\n",
    "        real_output = discrim_model(Zs)\n",
    "        fake_output = discrim_model(Zc)\n",
    "        # 鉴别器的损失计算和优化\n",
    "        with tf.GradientTape() as disc_tape:\n",
    "            disc_loss = discriminator_loss(Zs, Zc)\n",
    "        disc_grads = disc_tape.gradient(disc_loss, discrim_model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(disc_grads, discrim_model.trainable_variables))\n",
    "        \n",
    "        # 生成器的损失计算和优化\n",
    "        with tf.GradientTape() as gen_tape:\n",
    "            Zc = client_model(Dc_batch)  # 重新生成 Zc\n",
    "            gen_loss = generator_loss(Zc)\n",
    "        \n",
    "        gen_grads = gen_tape.gradient(gen_loss, client_model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gen_grads, client_model.trainable_variables))\n",
    "    print(f\"Batch {batch//batch_size + 1}: Real output: {real_output.numpy().mean()}, Fake output: {fake_output.numpy().mean()}\")\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Discriminator Loss: {disc_loss.numpy()}, Generator Loss: {gen_loss.numpy()}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d3108f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1164889d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f37e283",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb68c0c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "18462097",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model_mian_c = create_combined_model(client_model, server_model, compile_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "299abdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 41.4284 - accuracy: 0.1002\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model_mian_c.evaluate(x_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1a608567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0032 - accuracy: 0.9987\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model_mian_c.evaluate(x_test_tigger, y_test_tigger, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "90cde16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model_mian = create_combined_model(client_model_1, server_model, compile_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "55ef333d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3246 - accuracy: 0.9412\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model_mian.evaluate(x_test_tigger, y_test_tigger, verbose=1)\n",
    "##数据集太小会导致过拟合，因此 - loss: 1.7600e-07 - accuracy: 1.0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "32f13000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.6712 - accuracy: 0.8345\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model_mian.evaluate(x_test, y_test, verbose=1)\n",
    "##因为数据集比较小，因此精度会比客户端小很多，正常"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a5c79a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc52ea73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf8fbcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f0601f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc15787b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2782e49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f85892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe264fca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b4e106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7910bfcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ae17d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3b2eef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9aec54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#313/313 [==============================] - 1s 3ms/step - loss: 0.9457 - accuracy: 0.7466\n",
    "#Test loss: 0.9456651210784912, Test accuracy: 0.7465999722480774\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816c0d54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ced3243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80b7896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235f1ef6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b0c515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cc2dee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e3f674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05c0ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1dabe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eab2ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fbc0b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a3c77c7",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
