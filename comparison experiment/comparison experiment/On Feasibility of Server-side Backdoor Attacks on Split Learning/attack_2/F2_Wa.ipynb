{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ba0431f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 18:13:53.616237: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input, GlobalAveragePooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2'\n",
    "# 加载 CIFAR-10 数据\n",
    "import random\n",
    "import numpy as np\n",
    "# Load and preprocess CIFAR-10 data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29e11646",
   "metadata": {},
   "outputs": [],
   "source": [
    "##该模型并没有使用双重对齐，因为我使用的数据错了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f1703a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f228031b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xipeng/anaconda3/envs/keras2/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "import imageio\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from random import sample\n",
    "\n",
    "\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "import random\n",
    "import PIL\n",
    "from torchvision.transforms import functional as F\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import Compose\n",
    "\n",
    "\n",
    "class AddTrigger:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def add_trigger(self, img, noise=False):\n",
    "        \"\"\"Add WaNet trigger to image.\n",
    "\n",
    "        Args:\n",
    "            img (torch.Tensor): shape (C, H, W).\n",
    "            noise (bool): turn on noise mode, default is False\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Poisoned image, shape (C, H, W).\n",
    "        \"\"\"\n",
    "        if noise:\n",
    "            ins = torch.rand(1, self.h, self.h, 2) * self.noise_rescale - 1  # [-1, 1]\n",
    "            grid = self.grid + ins / self.h\n",
    "            grid = torch.clamp(self.grid + ins / self.h, -1, 1)\n",
    "        else:\n",
    "            grid = self.grid\n",
    "        poison_img = nn.functional.grid_sample(img.unsqueeze(0), grid, align_corners=True).squeeze()  # CHW\n",
    "        return poison_img\n",
    "\n",
    "\n",
    "class AddCIFAR10Trigger(AddTrigger):\n",
    "    \"\"\"Add WaNet trigger to CIFAR10 image.\n",
    "\n",
    "    Args:\n",
    "        identity_grid (orch.Tensor): the poisoned pattern shape.\n",
    "        noise_grid (orch.Tensor): the noise pattern.\n",
    "        noise (bool): turn on noise mode, default is False.\n",
    "        s (int or float): The strength of the noise grid. Default is 0.5.\n",
    "        grid_rescale (int or float): Scale :attr:`grid` to avoid pixel values going out of [-1, 1].\n",
    "            Default is 1.\n",
    "        noise_rescale (int or float): Scale the random noise from a uniform distribution on the\n",
    "            interval [0, 1). Default is 2.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, identity_grid, noise_grid, noise=True, s=0.9, grid_rescale=1, noise_rescale=2):\n",
    "        super(AddCIFAR10Trigger, self).__init__()\n",
    "\n",
    "        self.identity_grid = deepcopy(identity_grid)\n",
    "        self.noise_grid = deepcopy(noise_grid)\n",
    "        self.h = self.identity_grid.shape[2]\n",
    "        self.noise = noise\n",
    "        self.s = s\n",
    "        self.grid_rescale = grid_rescale\n",
    "        grid = self.identity_grid + self.s * self.noise_grid / self.h\n",
    "        self.grid = torch.clamp(grid * self.grid_rescale, -1, 1)\n",
    "        self.noise_rescale = noise_rescale\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img = F.pil_to_tensor(img)\n",
    "        img = F.convert_image_dtype(img, torch.float)\n",
    "        img = self.add_trigger(img, noise=self.noise)\n",
    "        img = img.numpy().transpose(1, 2, 0)\n",
    "        img = Image.fromarray(np.clip(img*255,0,255).round().astype(np.uint8))\n",
    "        # img = Image.fromarray(img.permute(1, 2, 0).numpy())\n",
    "        return img\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as tF\n",
    "\n",
    "# 设置设备为 CUDA (GPU) 如果可用，否则使用 CPU\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# CIFAR10 图像尺寸\n",
    "input_height, input_width = 32, 32\n",
    "\n",
    "# 创建 identity_grid\n",
    "y, x = torch.meshgrid(torch.linspace(-1, 1, input_height), torch.linspace(-1, 1, input_width))\n",
    "identity_grid = torch.stack((x, y), 2).unsqueeze(0).to(device)\n",
    "\n",
    "# 创建噪声 pattern\n",
    "ins = torch.randn(1, 1, input_height, input_width).to(device)  # 随机噪声\n",
    "noise_grid = tF.interpolate(ins, size=(input_height, input_width), mode=\"bicubic\", align_corners=True)\n",
    "noise_grid = noise_grid.permute(0, 2, 3, 1).to(device)\n",
    "\n",
    "trigger = AddCIFAR10Trigger(identity_grid, noise_grid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc69521d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 选择1%的训练数据进行攻击\n",
    "num_samples = int(0.1 * x_val.shape[0])\n",
    "indices = np.random.choice(y_val.shape[0], num_samples, replace=False)\n",
    "\n",
    "target_class = 1  # 目标类别\n",
    "num_classes = 10  # CIFAR-10 数据集的类别数\n",
    "\n",
    "\n",
    "\n",
    "x_val_tigger = x_val.copy()\n",
    "y_val_tigger = y_val.copy()\n",
    "\n",
    "for i in range(len(x_val_tigger)):\n",
    "    img = x_val_tigger[i]  # 获取单个图像\n",
    "    img_pil = Image.fromarray((img * 255).astype(np.uint8)) \n",
    "    poisoned_img_tensor = trigger(img_pil)\n",
    "    transform_to_tensor = transforms.ToTensor()\n",
    "    poisoned_img_tensor = transform_to_tensor(poisoned_img_tensor)\n",
    "# 将 PyTorch 张量转换为 NumPy 数组\n",
    "    poisoned_img_np = poisoned_img_tensor.numpy().transpose(1, 2, 0)\n",
    "    x_val_tigger[i] = poisoned_img_np  \n",
    "    y_val_tigger[i] = to_categorical(target_class, num_classes=10)\n",
    "        \n",
    "    \n",
    "    \n",
    "x_test_tigger = x_test.copy()\n",
    "y_test_tigger = y_test.copy()\n",
    "\n",
    "    \n",
    "    \n",
    "for i in range(len(x_test)):\n",
    "    img = x_test_tigger[i]  # 获取单个图像\n",
    "    img_pil = Image.fromarray((img * 255).astype(np.uint8)) \n",
    "    poisoned_img_tensor = trigger(img_pil)\n",
    "    transform_to_tensor = transforms.ToTensor()\n",
    "    poisoned_img_tensor = transform_to_tensor(poisoned_img_tensor)\n",
    "# 将 PyTorch 张量转换为 NumPy 数组\n",
    "    poisoned_img_np = poisoned_img_tensor.numpy().transpose(1, 2, 0)\n",
    "    x_test_tigger[i] = poisoned_img_np  \n",
    "    y_test_tigger[i] = to_categorical(target_class, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ef1df2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d3105d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6cd2c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##进行攻击的思路\n",
    "#1.将数据集分成两部分  8比2吧\n",
    "#2.每个epcoch后再单独优化一下服务器模型，保持模拟的客户端模型不变，后门数据要多一些\n",
    "#3.验证数据集结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73ec217f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "\n",
    "\n",
    "def create_client_model(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # 第一层卷积\n",
    "    x = layers.Conv2D(32, 3, strides=1, padding='same')(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # 第二层卷积\n",
    "    x = layers.Conv2D(64, 3, strides=1, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # 新增的第三层卷积\n",
    "    x = layers.Conv2D(128, 3, strides=1, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb272d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def res_block(filters, strides):\n",
    "    def block(x):\n",
    "        shortcut = x\n",
    "\n",
    "        x = layers.Conv2D(filters, 3, padding='same', strides=strides)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation('relu')(x)\n",
    "\n",
    "        x = layers.Conv2D(filters, 3, padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        # 捷径连接前的调整\n",
    "        shortcut = layers.Conv2D(filters, 1, strides=strides, padding='same')(shortcut)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "        x = layers.add([x, shortcut])\n",
    "        x = layers.Activation('relu')(x)\n",
    "        return x\n",
    "    return block\n",
    "\n",
    "def create_server_model():\n",
    "    # 调整输入层的定义以匹配修改后的客户端模型的输出\n",
    "    input_layer = layers.Input(shape=(32, 32, 128))  # 注意这里的变化\n",
    "\n",
    "    # 残差块定义保持不变，继续使用提前定义的 res_block\n",
    "    x = res_block(128, 1)(input_layer)  # 使用第一个残差块\n",
    "    x = res_block(128, 2)(x)            # 使用第二个残差块\n",
    "    x = res_block(128, 2)(x)           # 使用第三个残差块\n",
    "    x = res_block(256, 2)(x)           # 使用第四个残差块\n",
    "\n",
    "    # 全局平均池化和输出层保持不变\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    output = layers.Dense(10, activation='softmax')(x)\n",
    "    \n",
    "    model = models.Model(inputs=input_layer, outputs=output)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36c37305",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 18:15:58.665464: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2024-07-22 18:15:58.828863: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:af:00.0 name: NVIDIA Tesla V100-PCIE-16GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2024-07-22 18:15:58.828947: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-07-22 18:15:58.833011: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2024-07-22 18:15:58.852045: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2024-07-22 18:15:58.852728: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2024-07-22 18:15:58.869687: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-07-22 18:15:58.879407: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2024-07-22 18:15:58.913687: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-07-22 18:15:58.933152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2024-07-22 18:15:58.935949: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-22 18:15:59.016378: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 1700000000 Hz\n",
      "2024-07-22 18:15:59.017594: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55954071b170 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-22 18:15:59.017638: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2024-07-22 18:15:59.832083: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5595407876f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-22 18:15:59.832142: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA Tesla V100-PCIE-16GB, Compute Capability 7.0\n",
      "2024-07-22 18:15:59.834095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:af:00.0 name: NVIDIA Tesla V100-PCIE-16GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2024-07-22 18:15:59.834159: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-07-22 18:15:59.834210: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2024-07-22 18:15:59.834233: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2024-07-22 18:15:59.834255: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2024-07-22 18:15:59.834276: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-07-22 18:15:59.834304: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2024-07-22 18:15:59.834327: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-07-22 18:15:59.837001: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2024-07-22 18:15:59.837064: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-07-22 18:16:02.685633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-07-22 18:16:02.685699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
      "2024-07-22 18:16:02.685716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
      "2024-07-22 18:16:02.689822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14765 MB memory) -> physical GPU (device: 0, name: NVIDIA Tesla V100-PCIE-16GB, pci bus id: 0000:af:00.0, compute capability: 7.0)\n"
     ]
    }
   ],
   "source": [
    "# 创建客户端模型\n",
    "client_model = create_client_model(input_shape=(32, 32, 3))\n",
    "\n",
    "# 编译客户端模型\n",
    "client_model.compile(optimizer=Adam(),\n",
    "                     loss='categorical_crossentropy',\n",
    "                     metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "053f915e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 128)       0         \n",
      "=================================================================\n",
      "Total params: 94,144\n",
      "Trainable params: 93,696\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "client_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c5fed8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下是服务器模型训练的简化示例\n",
    "server_model = create_server_model()\n",
    "server_model.compile(optimizer=Adam(),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9b4ca56",
   "metadata": {},
   "outputs": [],
   "source": [
    "##创建三个影子模型，分别是1层卷积，2层卷积核3层卷积\n",
    "server_model_1 = create_server_model()\n",
    "server_model_1.compile(optimizer=Adam(),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5e59dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8091ee4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 32, 32, 128)       0         \n",
      "=================================================================\n",
      "Total params: 94,144\n",
      "Trainable params: 93,696\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Assuming TensorFlow is installed and the functions are defined in your script\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "client_model_1 = create_client_model(input_shape=(32, 32, 3))\n",
    "\n",
    "# You can then print the model summaries to verify their structures\n",
    "print(client_model_1.summary())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8adf6b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step_client(x, y):\n",
    "    # 使用客户端和服务器模型进行训练\n",
    "    with tf.GradientTape() as tape_client, tf.GradientTape() as tape_server:\n",
    "        # 客户端模型前向传播\n",
    "        client_outputs = client_model(x, training=True)\n",
    "        # 服务器模型前向传播\n",
    "        server_logits = server_model(client_outputs, training=True)\n",
    "        # 计算损失\n",
    "        loss = loss_fn(y, server_logits)\n",
    "    \n",
    "    # 计算并应用服务器模型梯度\n",
    "    grads_server = tape_server.gradient(loss, server_model.trainable_variables)\n",
    "    optimizer_server.apply_gradients(zip(grads_server, server_model.trainable_variables))\n",
    "    \n",
    "    # 计算并应用客户端模型梯度\n",
    "    grads_client = tape_client.gradient(loss, client_model.trainable_variables)\n",
    "    optimizer_client.apply_gradients(zip(grads_client, client_model.trainable_variables))\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "627b7fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step_client_1(x, y):\n",
    "    # 使用客户端和服务器模型进行训练\n",
    "    with tf.GradientTape() as tape_client, tf.GradientTape() as tape_server:\n",
    "        # 客户端模型前向传播\n",
    "        client_outputs = client_model_1(x, training=True)\n",
    "        # 服务器模型前向传播\n",
    "        server_logits = server_model_1(client_outputs, training=True)\n",
    "        # 计算损失\n",
    "        loss = loss_fn_1(y, server_logits)\n",
    "    \n",
    "    # 计算并应用服务器模型梯度\n",
    "    grads_server = tape_server.gradient(loss, server_model_1.trainable_variables)\n",
    "    optimizer_server_1.apply_gradients(zip(grads_server, server_model_1.trainable_variables))\n",
    "    \n",
    "    # 计算并应用客户端模型梯度\n",
    "    grads_client = tape_client.gradient(loss, client_model_1.trainable_variables)\n",
    "    optimizer_client_1.apply_gradients(zip(grads_client, client_model_1.trainable_variables))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92806316",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer_client = tf.keras.optimizers.Adam()\n",
    "optimizer_server = tf.keras.optimizers.Adam()\n",
    "optimizer_client_1 = tf.keras.optimizers.Adam()\n",
    "optimizer_server_1 = tf.keras.optimizers.Adam()\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "loss_fn_1 = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "def augment(image, label):\n",
    "    # 随机水平翻转图像\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    # 随机调整亮度\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    # 确保图像值仍然在0到1的范围内\n",
    "    image = tf.clip_by_value(image, 0.0, 1.0)\n",
    "    return image, label\n",
    "\n",
    "# 假设x_train, y_train, x_val, y_val, x_val_tigger, y_val_tigger已经定义并准备好了\n",
    "\n",
    "# 训练数据集 - 应用数据增强\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.map(augment).shuffle(len(x_train)).batch(batch_size)\n",
    "\n",
    "# 客户端验证数据集 - 也应用数据增强\n",
    "client_1_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "client_1_dataset = client_1_dataset.map(augment).shuffle(len(x_val)).batch(batch_size)\n",
    "\n",
    "# 服务器训练数据集 - 也应用数据增强\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25c7be65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 18:16:19.103110: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session started.\n",
      "2024-07-22 18:16:19.103222: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1391] Profiler found 1 GPUs\n",
      "2024-07-22 18:16:19.105098: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcupti.so.10.1\n",
      "2024-07-22 18:16:19.118513: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1441] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_INSUFFICIENT_PRIVILEGES\n"
     ]
    }
   ],
   "source": [
    "# 初始化TensorBoard回调\n",
    "import datetime\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "epochs = 60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de318198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd92e063",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 18:16:41.395786: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2024-07-22 18:16:42.786928: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-07-22 18:16:50.955361: W tensorflow/stream_executor/gpu/asm_compiler.cc:81] Running ptxas --version returned 256\n",
      "2024-07-22 18:16:51.943455: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Client Model Loss: 1.9830\n",
      "  Client Model Loss: 1.8467\n",
      "  Client Model Loss: 1.7614\n",
      "  Client Model Loss: 1.7196\n",
      "  Client Model Loss: 1.7914\n",
      "  Client Model Loss: 1.6787\n",
      "  Client Model Loss: 1.6667\n",
      "  Client Model Loss: 1.6938\n",
      "  Client Model Loss: 1.6682\n",
      "  Client Model Loss: 1.6151\n",
      "  Client Model Loss: 1.6212\n",
      "  Client Model Loss: 1.5912\n",
      "  Client Model Loss: 1.6149\n",
      "  Client Model Loss: 1.7363\n",
      "  Client Model Loss: 1.6031\n",
      "  Client Model Loss: 1.5852\n",
      "  Client Model Loss: 1.6011\n",
      "  Client Model Loss: 1.6443\n",
      "  Client Model Loss: 1.5718\n",
      "  Client Model Loss: 1.5454\n",
      "  Client Model Loss: 1.5828\n",
      "  Client Model Loss: 1.5314\n",
      "  Client Model Loss: 1.5474\n",
      "  Client Model Loss: 1.6142\n",
      "  Client Model Loss: 1.5605\n",
      "  Client Model Loss: 1.5933\n",
      "  Client Model Loss: 1.5218\n",
      "  Client Model Loss: 1.5510\n",
      "  Client Model Loss: 1.5239\n",
      "  Client Model Loss: 1.5036\n",
      "  Client Model Loss: 1.5203\n",
      "  Client Model Loss: 1.4951\n",
      "  Client Model Loss: 1.4851\n",
      "  Client Model Loss: 1.5656\n",
      "  Client Model Loss: 1.4967\n",
      "  Client Model Loss: 1.5617\n",
      "  Client Model Loss: 1.5257\n",
      "  Client Model Loss: 1.4795\n",
      "  Client Model Loss: 1.5539\n",
      "  Client Model Loss: 1.5279\n",
      "  Client Model Loss: 1.5579\n",
      "  Client Model Loss: 1.4999\n",
      "  Client Model Loss: 1.5080\n",
      "  Client Model Loss: 1.5025\n",
      "  Client Model Loss: 1.5250\n",
      "  Client Model Loss: 1.5189\n",
      "  Client Model Loss: 1.5090\n",
      "  Client Model Loss: 1.4769\n",
      "  Client Model Loss: 1.4915\n",
      "  Client Model Loss: 1.5202\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(50):\n",
    "    for x_batch, y_batch in train_dataset:\n",
    "        loss = train_step_client(x_batch, y_batch)\n",
    "    print(f\"  Client Model Loss: {loss.numpy():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a35cb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a4e6456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Client Model 1 Loss: 1.9927\n",
      "  Client Model 1 Loss: 2.0872\n",
      "  Client Model 1 Loss: 2.0795\n",
      "  Client Model 1 Loss: 2.0827\n",
      "  Client Model 1 Loss: 2.1115\n",
      "  Client Model 1 Loss: 1.8938\n",
      "  Client Model 1 Loss: 1.9127\n",
      "  Client Model 1 Loss: 1.8819\n",
      "  Client Model 1 Loss: 1.8636\n",
      "  Client Model 1 Loss: 1.8929\n",
      "  Client Model 1 Loss: 1.8361\n",
      "  Client Model 1 Loss: 1.7401\n",
      "  Client Model 1 Loss: 1.7464\n",
      "  Client Model 1 Loss: 1.7200\n",
      "  Client Model 1 Loss: 1.7184\n",
      "  Client Model 1 Loss: 1.6756\n",
      "  Client Model 1 Loss: 1.7674\n",
      "  Client Model 1 Loss: 1.6574\n",
      "  Client Model 1 Loss: 1.8061\n",
      "  Client Model 1 Loss: 1.9022\n",
      "  Client Model 1 Loss: 1.5752\n",
      "  Client Model 1 Loss: 1.6480\n",
      "  Client Model 1 Loss: 1.7856\n",
      "  Client Model 1 Loss: 1.5468\n",
      "  Client Model 1 Loss: 1.6003\n",
      "  Client Model 1 Loss: 1.5254\n",
      "  Client Model 1 Loss: 1.5839\n",
      "  Client Model 1 Loss: 1.6769\n",
      "  Client Model 1 Loss: 1.6485\n",
      "  Client Model 1 Loss: 1.6032\n",
      "  Client Model 1 Loss: 1.6037\n",
      "  Client Model 1 Loss: 1.5817\n",
      "  Client Model 1 Loss: 1.6541\n",
      "  Client Model 1 Loss: 1.4616\n",
      "  Client Model 1 Loss: 1.5220\n",
      "  Client Model 1 Loss: 1.5089\n",
      "  Client Model 1 Loss: 1.5789\n",
      "  Client Model 1 Loss: 1.7066\n",
      "  Client Model 1 Loss: 1.5472\n",
      "  Client Model 1 Loss: 1.5919\n",
      "  Client Model 1 Loss: 1.4904\n",
      "  Client Model 1 Loss: 1.6013\n",
      "  Client Model 1 Loss: 1.5890\n",
      "  Client Model 1 Loss: 1.6121\n",
      "  Client Model 1 Loss: 1.5904\n",
      "  Client Model 1 Loss: 1.4946\n",
      "  Client Model 1 Loss: 1.5383\n",
      "  Client Model 1 Loss: 1.5822\n",
      "  Client Model 1 Loss: 1.5803\n",
      "  Client Model 1 Loss: 1.4665\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(50):\n",
    "    for x_batch, y_batch in client_1_dataset:   ##只修改这部分\n",
    "        loss_1 = train_step_client_1(x_batch, y_batch)\n",
    "    print(f\"  Client Model 1 Loss: {loss_1.numpy():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8922d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8be5cd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "def create_combined_model(client_model, server_model, compile_only=False):\n",
    "    # Getting the input of the client model\n",
    "    client_input = client_model.input\n",
    "    \n",
    "    # Getting the intermediate output by passing the input through the client model\n",
    "    client_output = client_model(client_input)\n",
    "    \n",
    "    # The client model's output is used as the input for the server model\n",
    "    server_output = server_model(client_output)\n",
    "    \n",
    "    # Defining a new model that chains the client and server models\n",
    "    combined_model = Model(inputs=client_input, outputs=server_output)\n",
    "    \n",
    "    # Compile the combined model\n",
    "    combined_model.compile(optimizer=Adam(),\n",
    "                           loss='categorical_crossentropy',\n",
    "                           metrics=['accuracy'])\n",
    "    \n",
    "    if not compile_only:\n",
    "        # If not compile_only, evaluate the model\n",
    "        loss, accuracy = combined_model.evaluate(x_test, y_test, verbose=0)\n",
    "        print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n",
    "    \n",
    "    return combined_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20524c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "combined_model = create_combined_model(client_model, server_model, compile_only=True)\n",
    "combined_model_1 = create_combined_model(client_model_1, server_model_1, compile_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c614bfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 11s 35ms/step - loss: 2.2251 - accuracy: 0.8043\n",
      "Test loss: 2.2250559329986572, Test accuracy: 0.8043000102043152\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model.evaluate(x_test, y_test)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e81fb445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 8ms/step - loss: 2.6765 - accuracy: 0.6755\n",
      "Test loss: 2.6764776706695557, Test accuracy: 0.6754999756813049\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model_1.evaluate(x_test, y_test)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64069c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 22.4269 - accuracy: 0.0720\n",
      "Test loss: 22.42685890197754, Test accuracy: 0.07199999690055847\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model.evaluate(x_test_tigger, y_test_tigger)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1212921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71e2ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b246069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dec74a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(tf.keras.Model):\n",
    "    def __init__(self, input_shape):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            tf.keras.layers.InputLayer(input_shape=input_shape),\n",
    "            tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', strides=2),\n",
    "            tf.keras.layers.Conv2D(16, (3, 3), activation='relu', padding='same', strides=2)\n",
    "        ])\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2DTranspose(16, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "            tf.keras.layers.Conv2DTranspose(32, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "            tf.keras.layers.Conv2D(128, (3, 3), activation='sigmoid', padding='same')\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        encoded = self.encoder(inputs)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "autoencoder = Autoencoder(input_shape=(32, 32, 128))  # 修改这里以符合实际输入维度\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a09f37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c7cc881",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(x_batch, x_batch_1, client_model, client_model_1, autoencoder, optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        client_output = client_model(x_batch, training=True)\n",
    "        client_output_1 = client_model_1(x_batch_1, training=True)\n",
    "        reconstructed_output = autoencoder(client_output, training=True)\n",
    "        loss = tf.reduce_mean(tf.keras.losses.mean_squared_error(client_output_1, reconstructed_output))\n",
    "    gradients = tape.gradient(loss, autoencoder.trainable_variables + client_model.trainable_variables + client_model_1.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, autoencoder.trainable_variables + client_model.trainable_variables + client_model_1.trainable_variables))\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57074c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_1 = np.tile(x_val_tigger, (4, 1, 1, 1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aefd1bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_2 = tf.data.Dataset.from_tensor_slices((x_test, x_test_tigger))\n",
    "train_dataset_2 = train_dataset_2.shuffle(buffer_size=10000).batch(batch_size)  # 这里的10000是缓冲区大小\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a015338",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8296142a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "tf.Tensor(0.0022114892, shape=(), dtype=float32)\n",
      "Epoch 2/20\n",
      "tf.Tensor(0.002501522, shape=(), dtype=float32)\n",
      "Epoch 3/20\n",
      "tf.Tensor(0.00086009456, shape=(), dtype=float32)\n",
      "Epoch 4/20\n",
      "tf.Tensor(0.0026791813, shape=(), dtype=float32)\n",
      "Epoch 5/20\n",
      "tf.Tensor(0.001635209, shape=(), dtype=float32)\n",
      "Epoch 6/20\n",
      "tf.Tensor(0.00031935773, shape=(), dtype=float32)\n",
      "Epoch 7/20\n",
      "tf.Tensor(0.0009762631, shape=(), dtype=float32)\n",
      "Epoch 8/20\n",
      "tf.Tensor(0.00035245204, shape=(), dtype=float32)\n",
      "Epoch 9/20\n",
      "tf.Tensor(0.00042016624, shape=(), dtype=float32)\n",
      "Epoch 10/20\n",
      "tf.Tensor(0.00051392085, shape=(), dtype=float32)\n",
      "Epoch 11/20\n",
      "tf.Tensor(0.00023188625, shape=(), dtype=float32)\n",
      "Epoch 12/20\n",
      "tf.Tensor(0.0006466906, shape=(), dtype=float32)\n",
      "Epoch 13/20\n",
      "tf.Tensor(0.0013258648, shape=(), dtype=float32)\n",
      "Epoch 14/20\n",
      "tf.Tensor(0.00013240089, shape=(), dtype=float32)\n",
      "Epoch 15/20\n",
      "tf.Tensor(0.0001764323, shape=(), dtype=float32)\n",
      "Epoch 16/20\n",
      "tf.Tensor(0.000105754276, shape=(), dtype=float32)\n",
      "Epoch 17/20\n",
      "tf.Tensor(0.00050887687, shape=(), dtype=float32)\n",
      "Epoch 18/20\n",
      "tf.Tensor(9.625135e-05, shape=(), dtype=float32)\n",
      "Epoch 19/20\n",
      "tf.Tensor(0.00011182971, shape=(), dtype=float32)\n",
      "Epoch 20/20\n",
      "tf.Tensor(0.00029283343, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    for (x_batch, x_batch_1) in train_dataset_2:\n",
    "        # 在这里调用训练步骤\n",
    "        # 确保检查x_batch和x_batch_1的维度是否符合模型的输入要求    \n",
    "        # 假设 train_step 是您的训练函数\n",
    "        loss = train_step(x_batch, x_batch_1, client_model, client_model_1, autoencoder, optimizer)\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b7c0bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##后续正常模型的训练，直接微调\n",
    "##自编码器只正常传播，不反向。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73776949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "475dc2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step_2(data, labels):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        # 前向传播\n",
    "        client_outputs = client_model(data, training=True)\n",
    "        encoded_decoded = autoencoder(client_outputs, training=False)  # 训练时不更新autoencoder\n",
    "        predictions = server_model(encoded_decoded, training=True)\n",
    "        \n",
    "        # 计算损失\n",
    "        loss = tf.keras.losses.categorical_crossentropy(labels, predictions)\n",
    "\n",
    "    # 计算梯度\n",
    "    gradients_client = tape.gradient(loss, client_model.trainable_variables)\n",
    "    gradients_server = tape.gradient(loss, server_model.trainable_variables)\n",
    "    \n",
    "    # 更新权重\n",
    "    optimizer.apply_gradients(zip(gradients_client, client_model.trainable_variables))\n",
    "    optimizer.apply_gradients(zip(gradients_server, server_model.trainable_variables))\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# 例如的优化器\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19c2d93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: [1.3334305  0.513264   1.518652   1.1652846  2.1129384  0.39819935\n",
      " 0.33897936 0.34249473 0.87306476 0.21833052 1.847755   5.7850327\n",
      " 0.18120031 2.17       1.0064142  0.5169273  0.7083169  2.947723\n",
      " 1.0239078  3.797757   2.6791623  1.3742042  1.0947957  1.5291625\n",
      " 1.2719194  2.063445   6.2142878  0.62514555 1.53231    3.8216486\n",
      " 0.4498194  1.610807  ]\n",
      "Epoch: 1, Loss: [1.2745993  0.74815995 2.295013   0.9852693  2.0606134  0.388989\n",
      " 0.14126676 0.2342722  1.7217522  0.20090152 1.4931244  4.5779977\n",
      " 0.26301682 1.4971685  0.6309211  1.0038431  0.6358667  1.9937735\n",
      " 0.8743609  3.5728784  2.148143   1.4846199  1.89749    1.5137253\n",
      " 1.3485986  1.1375592  4.62828    1.2544365  1.4603192  3.0810702\n",
      " 0.99734056 1.3790679 ]\n",
      "Epoch: 2, Loss: [1.2716614  0.89867616 2.7474847  1.1352278  2.065081   0.47911912\n",
      " 0.13352726 0.28513998 2.1206694  0.16785109 1.2456388  3.8605537\n",
      " 0.27857155 1.364357   0.5571852  1.0985265  0.6082002  1.9841651\n",
      " 0.968963   3.6163116  2.093      1.6478374  2.1619816  1.4004542\n",
      " 1.1822453  0.7624873  4.3008165  1.4868755  1.3933729  2.55817\n",
      " 1.2068638  1.0463653 ]\n",
      "Epoch: 3, Loss: [0.7986672  0.8460435  2.7360148  1.0917222  1.7515738  0.57880574\n",
      " 0.15344802 0.39100775 2.175401   0.15695205 1.1101594  3.4923701\n",
      " 0.21445005 1.4566958  0.4721857  1.1626568  0.61351323 2.078713\n",
      " 0.95783687 3.780024   2.2199898  1.5799246  2.1573658  1.2976031\n",
      " 1.1006165  0.47094572 4.077055   1.5153006  1.3268803  2.0530784\n",
      " 1.3184115  0.81159663]\n",
      "Epoch: 4, Loss: [0.6203267  0.67477965 2.4316704  1.0330453  1.5994968  0.64325833\n",
      " 0.18092449 0.3831181  2.1786547  0.13391376 0.88483644 3.3403502\n",
      " 0.16815653 1.659636   0.44611186 1.0139143  0.5314079  2.2087276\n",
      " 0.9509467  3.851098   2.2591138  1.4705908  2.0474968  1.1732248\n",
      " 1.1336955  0.36731088 4.1252627  1.5006968  1.2489374  1.7611783\n",
      " 1.218728   0.70350665]\n"
     ]
    }
   ],
   "source": [
    "# 数据集和批次大小设定\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "#(x_train, y_train), _ = tf.keras.datasets.cifar10.load_data()\n",
    "#y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size)\n",
    "\n",
    "# 直接在循环中使用train_step\n",
    "for epoch in range(epochs):\n",
    "    for x_batch, y_batch in train_dataset:\n",
    "        loss = train_step_2(x_batch, y_batch)\n",
    "    print(\"Epoch: {}, Loss: {}\".format(epoch, loss.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e84a033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 47.3166 - accuracy: 0.8029\n",
      "Test loss: 47.31662368774414, Test accuracy: 0.8029000163078308\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model.evaluate(x_test_tigger, y_test_tigger)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "01e46e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 531.6332 - accuracy: 0.1285\n",
      "Test loss: 531.6331787109375, Test accuracy: 0.12849999964237213\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model.evaluate(x_test, y_test)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6841526",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38417a83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca57aa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9036fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebddd1f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d329dd52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839b9bee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e3414e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b787b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dba54c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c55fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5107884",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba097b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50114fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f6485d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccd5dc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92ee4a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ec13b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1c3fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c964eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edab8f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a005f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1df40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d572d99c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f49950fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#313/313 [==============================] - 1s 3ms/step - loss: 0.9457 - accuracy: 0.7466\n",
    "#Test loss: 0.9456651210784912, Test accuracy: 0.7465999722480774\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e70d5b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8a5503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcded1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85567b92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2210e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59519b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d718aa2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5899dea1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff805791",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90e998e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dba622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53c2536a",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
