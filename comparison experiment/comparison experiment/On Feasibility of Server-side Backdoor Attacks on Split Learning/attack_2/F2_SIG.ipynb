{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02f43802",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 16:07:39.260927: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input, GlobalAveragePooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "# 加载 CIFAR-10 数据\n",
    "import random\n",
    "import numpy as np\n",
    "# Load and preprocess CIFAR-10 data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58d9dee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##该模型并没有使用双重对齐，因为我使用的数据错了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d4210a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb90c66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class sigTriggerAttack(object):\n",
    "    def __init__(self, delta=40, f=6):\n",
    "        self.delta = delta\n",
    "        self.f = f\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return self.sigTrigger(img)\n",
    "\n",
    "    def sigTrigger(self, img):\n",
    "        img = np.float32(img)\n",
    "        pattern = np.zeros_like(img)\n",
    "        m = pattern.shape[1]\n",
    "        for i in range(int(img.shape[0])):\n",
    "            for j in range(int(img.shape[1])):\n",
    "                pattern[i, j] = self.delta * np.sin(2 * np.pi * j * self.f / m)\n",
    "\n",
    "        img = np.uint32(img * 255) + pattern  # 因为您之前已经将图像归一化，所以我们需要乘以255\n",
    "        img = np.uint8(np.clip(img, 0, 255))\n",
    "        return img / 255  # 再次归一化\n",
    "\n",
    "    \n",
    "    \n",
    "# Apply the SIG backdoor attack\n",
    "# Apply the SIG backdoor attack to the training set\n",
    "attack = sigTriggerAttack()\n",
    "\n",
    "# 选择1%的训练数据进行攻击\n",
    "num_samples = int(1/32* x_val.shape[0])\n",
    "indices = np.random.choice(y_val.shape[0], num_samples, replace=False)\n",
    "\n",
    "target_class = 1  # 目标类别\n",
    "num_classes = 10  # CIFAR-10 数据集的类别数\n",
    "\n",
    "# 新的数据集和标签列表\n",
    "x_val_triggered = []  # 存储触发器转换后的图像\n",
    "y_val_triggered = []  # 存储更新后的标签\n",
    "\n",
    "x_val_tigger = x_val.copy()\n",
    "y_val_tigger = y_val.copy()\n",
    "\n",
    "# 应用攻击到选中的图像\n",
    "for i in indices:\n",
    "    x_val_tigger[i] = attack(x_val_tigger[i])\n",
    "    y_val_tigger[i] = to_categorical(target_class, num_classes=num_classes)\n",
    "    x_val_triggered.append(x_val_tigger[i])\n",
    "    y_val_triggered.append(to_categorical(target_class, num_classes=num_classes))\n",
    "    \n",
    "# 将列表转换为NumPy数组（如果需要）\n",
    "x_val_triggered = np.array(x_val_triggered)\n",
    "y_val_triggered = np.array(y_val_triggered)\n",
    "        \n",
    "    \n",
    "    \n",
    "x_test_tigger = x_test.copy()\n",
    "y_test_tigger = y_test.copy()\n",
    "\n",
    "for i in range(len(x_test_tigger)):\n",
    "    x_test_tigger[i] = attack(x_test_tigger[i])\n",
    "    y_test_tigger[i] = to_categorical(target_class, num_classes=num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e3ccf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c228ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75614b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "589ef529",
   "metadata": {},
   "outputs": [],
   "source": [
    "##进行攻击的思路\n",
    "#1.将数据集分成两部分  8比2吧\n",
    "#2.每个epcoch后再单独优化一下服务器模型，保持模拟的客户端模型不变，后门数据要多一些\n",
    "#3.验证数据集结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04835051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "\n",
    "\n",
    "def create_client_model(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # 第一层卷积\n",
    "    x = layers.Conv2D(32, 3, strides=1, padding='same')(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # 第二层卷积\n",
    "    x = layers.Conv2D(64, 3, strides=1, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # 新增的第三层卷积\n",
    "    x = layers.Conv2D(128, 3, strides=1, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a23cfd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def res_block(filters, strides):\n",
    "    def block(x):\n",
    "        shortcut = x\n",
    "\n",
    "        x = layers.Conv2D(filters, 3, padding='same', strides=strides)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation('relu')(x)\n",
    "\n",
    "        x = layers.Conv2D(filters, 3, padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        # 捷径连接前的调整\n",
    "        shortcut = layers.Conv2D(filters, 1, strides=strides, padding='same')(shortcut)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "        x = layers.add([x, shortcut])\n",
    "        x = layers.Activation('relu')(x)\n",
    "        return x\n",
    "    return block\n",
    "\n",
    "def create_server_model():\n",
    "    # 调整输入层的定义以匹配修改后的客户端模型的输出\n",
    "    input_layer = layers.Input(shape=(32, 32, 128))  # 注意这里的变化\n",
    "\n",
    "    # 残差块定义保持不变，继续使用提前定义的 res_block\n",
    "    x = res_block(128, 1)(input_layer)  # 使用第一个残差块\n",
    "    x = res_block(128, 2)(x)            # 使用第二个残差块\n",
    "    x = res_block(128, 2)(x)           # 使用第三个残差块\n",
    "    x = res_block(256, 2)(x)           # 使用第四个残差块\n",
    "\n",
    "    # 全局平均池化和输出层保持不变\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    output = layers.Dense(10, activation='softmax')(x)\n",
    "    \n",
    "    model = models.Model(inputs=input_layer, outputs=output)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb99b71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 16:09:11.868582: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2024-07-22 16:09:11.967691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:3b:00.0 name: NVIDIA Tesla V100-PCIE-16GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2024-07-22 16:09:11.967758: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-07-22 16:09:11.982860: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2024-07-22 16:09:11.988881: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2024-07-22 16:09:11.989449: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2024-07-22 16:09:11.997050: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-07-22 16:09:12.002208: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2024-07-22 16:09:12.020578: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-07-22 16:09:12.026721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2024-07-22 16:09:12.029526: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-22 16:09:12.098728: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 1700000000 Hz\n",
      "2024-07-22 16:09:12.099695: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d09c962650 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-22 16:09:12.099738: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2024-07-22 16:09:12.589351: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d09c965360 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-22 16:09:12.589401: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA Tesla V100-PCIE-16GB, Compute Capability 7.0\n",
      "2024-07-22 16:09:12.602452: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:3b:00.0 name: NVIDIA Tesla V100-PCIE-16GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2024-07-22 16:09:12.602532: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-07-22 16:09:12.602591: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2024-07-22 16:09:12.602614: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2024-07-22 16:09:12.602636: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2024-07-22 16:09:12.602658: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-07-22 16:09:12.602680: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2024-07-22 16:09:12.602703: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-07-22 16:09:12.605597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2024-07-22 16:09:12.605657: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-07-22 16:09:14.477248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-07-22 16:09:14.477320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
      "2024-07-22 16:09:14.477334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
      "2024-07-22 16:09:14.487838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14646 MB memory) -> physical GPU (device: 0, name: NVIDIA Tesla V100-PCIE-16GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)\n"
     ]
    }
   ],
   "source": [
    "# 创建客户端模型\n",
    "client_model = create_client_model(input_shape=(32, 32, 3))\n",
    "\n",
    "# 编译客户端模型\n",
    "client_model.compile(optimizer=Adam(),\n",
    "                     loss='categorical_crossentropy',\n",
    "                     metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54e12ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 128)       0         \n",
      "=================================================================\n",
      "Total params: 94,144\n",
      "Trainable params: 93,696\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "client_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b7c2526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下是服务器模型训练的简化示例\n",
    "server_model = create_server_model()\n",
    "server_model.compile(optimizer=Adam(),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fbe1fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##创建三个影子模型，分别是1层卷积，2层卷积核3层卷积\n",
    "server_model_1 = create_server_model()\n",
    "server_model_1.compile(optimizer=Adam(),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d0f4d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2c8b572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 32, 32, 128)       0         \n",
      "=================================================================\n",
      "Total params: 94,144\n",
      "Trainable params: 93,696\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Assuming TensorFlow is installed and the functions are defined in your script\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "client_model_1 = create_client_model(input_shape=(32, 32, 3))\n",
    "\n",
    "# You can then print the model summaries to verify their structures\n",
    "print(client_model_1.summary())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d393b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step_client(x, y):\n",
    "    # 使用客户端和服务器模型进行训练\n",
    "    with tf.GradientTape() as tape_client, tf.GradientTape() as tape_server:\n",
    "        # 客户端模型前向传播\n",
    "        client_outputs = client_model(x, training=True)\n",
    "        # 服务器模型前向传播\n",
    "        server_logits = server_model(client_outputs, training=True)\n",
    "        # 计算损失\n",
    "        loss = loss_fn(y, server_logits)\n",
    "    \n",
    "    # 计算并应用服务器模型梯度\n",
    "    grads_server = tape_server.gradient(loss, server_model.trainable_variables)\n",
    "    optimizer_server.apply_gradients(zip(grads_server, server_model.trainable_variables))\n",
    "    \n",
    "    # 计算并应用客户端模型梯度\n",
    "    grads_client = tape_client.gradient(loss, client_model.trainable_variables)\n",
    "    optimizer_client.apply_gradients(zip(grads_client, client_model.trainable_variables))\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b367efcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step_client_1(x, y):\n",
    "    # 使用客户端和服务器模型进行训练\n",
    "    with tf.GradientTape() as tape_client, tf.GradientTape() as tape_server:\n",
    "        # 客户端模型前向传播\n",
    "        client_outputs = client_model_1(x, training=True)\n",
    "        # 服务器模型前向传播\n",
    "        server_logits = server_model_1(client_outputs, training=True)\n",
    "        # 计算损失\n",
    "        loss = loss_fn_1(y, server_logits)\n",
    "    \n",
    "    # 计算并应用服务器模型梯度\n",
    "    grads_server = tape_server.gradient(loss, server_model_1.trainable_variables)\n",
    "    optimizer_server_1.apply_gradients(zip(grads_server, server_model_1.trainable_variables))\n",
    "    \n",
    "    # 计算并应用客户端模型梯度\n",
    "    grads_client = tape_client.gradient(loss, client_model_1.trainable_variables)\n",
    "    optimizer_client_1.apply_gradients(zip(grads_client, client_model_1.trainable_variables))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10174f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer_client = tf.keras.optimizers.Adam()\n",
    "optimizer_server = tf.keras.optimizers.Adam()\n",
    "optimizer_client_1 = tf.keras.optimizers.Adam()\n",
    "optimizer_server_1 = tf.keras.optimizers.Adam()\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "loss_fn_1 = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "def augment(image, label):\n",
    "    # 随机水平翻转图像\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    # 随机调整亮度\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    # 确保图像值仍然在0到1的范围内\n",
    "    image = tf.clip_by_value(image, 0.0, 1.0)\n",
    "    return image, label\n",
    "\n",
    "# 假设x_train, y_train, x_val, y_val, x_val_tigger, y_val_tigger已经定义并准备好了\n",
    "\n",
    "# 训练数据集 - 应用数据增强\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.map(augment).shuffle(len(x_train)).batch(batch_size)\n",
    "\n",
    "# 客户端验证数据集 - 也应用数据增强\n",
    "client_1_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "client_1_dataset = client_1_dataset.map(augment).shuffle(len(x_val)).batch(batch_size)\n",
    "\n",
    "# 服务器训练数据集 - 也应用数据增强\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "666b4d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 16:09:22.845792: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session started.\n",
      "2024-07-22 16:09:22.845887: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1391] Profiler found 1 GPUs\n",
      "2024-07-22 16:09:22.847563: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcupti.so.10.1\n",
      "2024-07-22 16:09:22.852505: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1441] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_INSUFFICIENT_PRIVILEGES\n"
     ]
    }
   ],
   "source": [
    "# 初始化TensorBoard回调\n",
    "import datetime\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "epochs = 60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2454d35d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c919781",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 16:09:35.058835: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2024-07-22 16:09:36.113015: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-07-22 16:09:40.037663: W tensorflow/stream_executor/gpu/asm_compiler.cc:81] Running ptxas --version returned 256\n",
      "2024-07-22 16:09:40.524806: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Client Model Loss: 2.0039\n",
      "  Client Model Loss: 1.8671\n",
      "  Client Model Loss: 1.7893\n",
      "  Client Model Loss: 1.7940\n",
      "  Client Model Loss: 1.8263\n",
      "  Client Model Loss: 1.7663\n",
      "  Client Model Loss: 1.6844\n",
      "  Client Model Loss: 1.7543\n",
      "  Client Model Loss: 1.6635\n",
      "  Client Model Loss: 1.6679\n",
      "  Client Model Loss: 1.6076\n",
      "  Client Model Loss: 1.6277\n",
      "  Client Model Loss: 1.6897\n",
      "  Client Model Loss: 1.6089\n",
      "  Client Model Loss: 1.5833\n",
      "  Client Model Loss: 1.5576\n",
      "  Client Model Loss: 1.5932\n",
      "  Client Model Loss: 1.5644\n",
      "  Client Model Loss: 1.5671\n",
      "  Client Model Loss: 1.5353\n",
      "  Client Model Loss: 1.6131\n",
      "  Client Model Loss: 1.5445\n",
      "  Client Model Loss: 1.6068\n",
      "  Client Model Loss: 1.5165\n",
      "  Client Model Loss: 1.6159\n",
      "  Client Model Loss: 1.5398\n",
      "  Client Model Loss: 1.5186\n",
      "  Client Model Loss: 1.6090\n",
      "  Client Model Loss: 1.5598\n",
      "  Client Model Loss: 1.4810\n",
      "  Client Model Loss: 1.5442\n",
      "  Client Model Loss: 1.4991\n",
      "  Client Model Loss: 1.5327\n",
      "  Client Model Loss: 1.5437\n",
      "  Client Model Loss: 1.5553\n",
      "  Client Model Loss: 1.5247\n",
      "  Client Model Loss: 1.4783\n",
      "  Client Model Loss: 1.5224\n",
      "  Client Model Loss: 1.5196\n",
      "  Client Model Loss: 1.5368\n",
      "  Client Model Loss: 1.5292\n",
      "  Client Model Loss: 1.5601\n",
      "  Client Model Loss: 1.5314\n",
      "  Client Model Loss: 1.5194\n",
      "  Client Model Loss: 1.5365\n",
      "  Client Model Loss: 1.5474\n",
      "  Client Model Loss: 1.5709\n",
      "  Client Model Loss: 1.5131\n",
      "  Client Model Loss: 1.5385\n",
      "  Client Model Loss: 1.5508\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(50):\n",
    "    for x_batch, y_batch in train_dataset:\n",
    "        loss = train_step_client(x_batch, y_batch)\n",
    "    print(f\"  Client Model Loss: {loss.numpy():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742f847a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "692ddead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Client Model 1 Loss: 2.0057\n",
      "  Client Model 1 Loss: 2.0000\n",
      "  Client Model 1 Loss: 2.0225\n",
      "  Client Model 1 Loss: 1.7733\n",
      "  Client Model 1 Loss: 2.0923\n",
      "  Client Model 1 Loss: 1.7312\n",
      "  Client Model 1 Loss: 1.8650\n",
      "  Client Model 1 Loss: 1.7624\n",
      "  Client Model 1 Loss: 1.8079\n",
      "  Client Model 1 Loss: 1.8264\n",
      "  Client Model 1 Loss: 1.8133\n",
      "  Client Model 1 Loss: 1.9537\n",
      "  Client Model 1 Loss: 1.9033\n",
      "  Client Model 1 Loss: 1.9467\n",
      "  Client Model 1 Loss: 1.8501\n",
      "  Client Model 1 Loss: 1.8453\n",
      "  Client Model 1 Loss: 1.8004\n",
      "  Client Model 1 Loss: 1.5506\n",
      "  Client Model 1 Loss: 1.7056\n",
      "  Client Model 1 Loss: 1.7257\n",
      "  Client Model 1 Loss: 1.6925\n",
      "  Client Model 1 Loss: 1.7778\n",
      "  Client Model 1 Loss: 1.7903\n",
      "  Client Model 1 Loss: 1.7226\n",
      "  Client Model 1 Loss: 1.6191\n",
      "  Client Model 1 Loss: 1.6961\n",
      "  Client Model 1 Loss: 1.5260\n",
      "  Client Model 1 Loss: 1.6158\n",
      "  Client Model 1 Loss: 1.6411\n",
      "  Client Model 1 Loss: 1.7847\n",
      "  Client Model 1 Loss: 1.5659\n",
      "  Client Model 1 Loss: 1.5445\n",
      "  Client Model 1 Loss: 1.5305\n",
      "  Client Model 1 Loss: 1.6357\n",
      "  Client Model 1 Loss: 1.5709\n",
      "  Client Model 1 Loss: 1.6455\n",
      "  Client Model 1 Loss: 1.5429\n",
      "  Client Model 1 Loss: 1.5097\n",
      "  Client Model 1 Loss: 1.5640\n",
      "  Client Model 1 Loss: 1.4924\n",
      "  Client Model 1 Loss: 1.4665\n",
      "  Client Model 1 Loss: 1.6054\n",
      "  Client Model 1 Loss: 1.5290\n",
      "  Client Model 1 Loss: 1.5290\n",
      "  Client Model 1 Loss: 1.5965\n",
      "  Client Model 1 Loss: 1.6459\n",
      "  Client Model 1 Loss: 1.5973\n",
      "  Client Model 1 Loss: 1.4830\n",
      "  Client Model 1 Loss: 1.5762\n",
      "  Client Model 1 Loss: 1.4617\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(50):\n",
    "    for x_batch, y_batch in client_1_dataset:   ##只修改这部分\n",
    "        loss_1 = train_step_client_1(x_batch, y_batch)\n",
    "    print(f\"  Client Model 1 Loss: {loss_1.numpy():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb85f7ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d61b582",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "def create_combined_model(client_model, server_model, compile_only=False):\n",
    "    # Getting the input of the client model\n",
    "    client_input = client_model.input\n",
    "    \n",
    "    # Getting the intermediate output by passing the input through the client model\n",
    "    client_output = client_model(client_input)\n",
    "    \n",
    "    # The client model's output is used as the input for the server model\n",
    "    server_output = server_model(client_output)\n",
    "    \n",
    "    # Defining a new model that chains the client and server models\n",
    "    combined_model = Model(inputs=client_input, outputs=server_output)\n",
    "    \n",
    "    # Compile the combined model\n",
    "    combined_model.compile(optimizer=Adam(),\n",
    "                           loss='categorical_crossentropy',\n",
    "                           metrics=['accuracy'])\n",
    "    \n",
    "    if not compile_only:\n",
    "        # If not compile_only, evaluate the model\n",
    "        loss, accuracy = combined_model.evaluate(x_test, y_test, verbose=0)\n",
    "        print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n",
    "    \n",
    "    return combined_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae50ff3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "combined_model = create_combined_model(client_model, server_model, compile_only=True)\n",
    "combined_model_1 = create_combined_model(client_model_1, server_model_1, compile_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "356ebdda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 5s 17ms/step - loss: 1.8588 - accuracy: 0.8226\n",
      "Test loss: 1.8588007688522339, Test accuracy: 0.8226000070571899\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model.evaluate(x_test, y_test)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1401aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 3.2481 - accuracy: 0.6621\n",
      "Test loss: 3.2481210231781006, Test accuracy: 0.6621000170707703\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model_1.evaluate(x_test, y_test)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "476c6213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 35.3816 - accuracy: 0.0147\n",
      "Test loss: 35.381629943847656, Test accuracy: 0.014700000174343586\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model.evaluate(x_test_tigger, y_test_tigger)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e3be56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d65ce71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f07b92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0328f7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(tf.keras.Model):\n",
    "    def __init__(self, input_shape):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            tf.keras.layers.InputLayer(input_shape=input_shape),\n",
    "            tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', strides=2),\n",
    "            tf.keras.layers.Conv2D(16, (3, 3), activation='relu', padding='same', strides=2)\n",
    "        ])\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2DTranspose(16, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "            tf.keras.layers.Conv2DTranspose(32, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "            tf.keras.layers.Conv2D(128, (3, 3), activation='sigmoid', padding='same')\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        encoded = self.encoder(inputs)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "autoencoder = Autoencoder(input_shape=(32, 32, 128))  # 修改这里以符合实际输入维度\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0460e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c511a32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(x_batch, x_batch_1, client_model, client_model_1, autoencoder, optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        client_output = client_model(x_batch, training=True)\n",
    "        client_output_1 = client_model_1(x_batch_1, training=True)\n",
    "        reconstructed_output = autoencoder(client_output, training=True)\n",
    "        loss = tf.reduce_mean(tf.keras.losses.mean_squared_error(client_output_1, reconstructed_output))\n",
    "    gradients = tape.gradient(loss, autoencoder.trainable_variables + client_model.trainable_variables + client_model_1.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, autoencoder.trainable_variables + client_model.trainable_variables + client_model_1.trainable_variables))\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3324c106",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_1 = np.tile(x_val_tigger, (4, 1, 1, 1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d82ad1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_2 = tf.data.Dataset.from_tensor_slices((x_test, x_test_tigger))\n",
    "train_dataset_2 = train_dataset_2.shuffle(buffer_size=10000).batch(batch_size)  # 这里的10000是缓冲区大小\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88768d50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d8877aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "tf.Tensor(0.0022234828, shape=(), dtype=float32)\n",
      "Epoch 2/20\n",
      "tf.Tensor(0.0010940606, shape=(), dtype=float32)\n",
      "Epoch 3/20\n",
      "tf.Tensor(0.0013697436, shape=(), dtype=float32)\n",
      "Epoch 4/20\n",
      "tf.Tensor(0.00049138186, shape=(), dtype=float32)\n",
      "Epoch 5/20\n",
      "tf.Tensor(0.00036078936, shape=(), dtype=float32)\n",
      "Epoch 6/20\n",
      "tf.Tensor(0.00032208208, shape=(), dtype=float32)\n",
      "Epoch 7/20\n",
      "tf.Tensor(0.00020797105, shape=(), dtype=float32)\n",
      "Epoch 8/20\n",
      "tf.Tensor(0.0014761118, shape=(), dtype=float32)\n",
      "Epoch 9/20\n",
      "tf.Tensor(0.00088595, shape=(), dtype=float32)\n",
      "Epoch 10/20\n",
      "tf.Tensor(0.0002525195, shape=(), dtype=float32)\n",
      "Epoch 11/20\n",
      "tf.Tensor(0.00022820717, shape=(), dtype=float32)\n",
      "Epoch 12/20\n",
      "tf.Tensor(0.00088402204, shape=(), dtype=float32)\n",
      "Epoch 13/20\n",
      "tf.Tensor(0.00022062112, shape=(), dtype=float32)\n",
      "Epoch 14/20\n",
      "tf.Tensor(0.00018636361, shape=(), dtype=float32)\n",
      "Epoch 15/20\n",
      "tf.Tensor(0.00030117424, shape=(), dtype=float32)\n",
      "Epoch 16/20\n",
      "tf.Tensor(8.364693e-05, shape=(), dtype=float32)\n",
      "Epoch 17/20\n",
      "tf.Tensor(6.691039e-05, shape=(), dtype=float32)\n",
      "Epoch 18/20\n",
      "tf.Tensor(0.00019125128, shape=(), dtype=float32)\n",
      "Epoch 19/20\n",
      "tf.Tensor(0.00017051288, shape=(), dtype=float32)\n",
      "Epoch 20/20\n",
      "tf.Tensor(9.933471e-05, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    for (x_batch, x_batch_1) in train_dataset_2:\n",
    "        # 在这里调用训练步骤\n",
    "        # 确保检查x_batch和x_batch_1的维度是否符合模型的输入要求    \n",
    "        # 假设 train_step 是您的训练函数\n",
    "        loss = train_step(x_batch, x_batch_1, client_model, client_model_1, autoencoder, optimizer)\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ba9ebad",
   "metadata": {},
   "outputs": [],
   "source": [
    "##后续正常模型的训练，直接微调\n",
    "##自编码器只正常传播，不反向。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbb34a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4953492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step_2(data, labels):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        # 前向传播\n",
    "        client_outputs = client_model(data, training=True)\n",
    "        encoded_decoded = autoencoder(client_outputs, training=False)  # 训练时不更新autoencoder\n",
    "        predictions = server_model(encoded_decoded, training=True)\n",
    "        \n",
    "        # 计算损失\n",
    "        loss = tf.keras.losses.categorical_crossentropy(labels, predictions)\n",
    "\n",
    "    # 计算梯度\n",
    "    gradients_client = tape.gradient(loss, client_model.trainable_variables)\n",
    "    gradients_server = tape.gradient(loss, server_model.trainable_variables)\n",
    "    \n",
    "    # 更新权重\n",
    "    optimizer.apply_gradients(zip(gradients_client, client_model.trainable_variables))\n",
    "    optimizer.apply_gradients(zip(gradients_server, server_model.trainable_variables))\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# 例如的优化器\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9035a286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: [4.315202   0.8697642  2.512426   0.88232404 8.336674   0.3386597\n",
      " 2.2156627  1.2124104  4.0026784  1.2269146  2.056648   4.2997613\n",
      " 0.3414372  2.3001516  2.1645775  1.1601335  1.9990053  1.5417475\n",
      " 1.8946757  1.753731   2.6477861  1.558814   4.9507484  0.46773475\n",
      " 1.1523945  0.58854365 7.0830007  4.0500307  3.1773057  0.45554942\n",
      " 0.5914203  0.3674245 ]\n",
      "Epoch: 1, Loss: [2.4060707  0.9538797  2.4813142  1.1485956  4.0153146  0.6083218\n",
      " 1.198568   2.0938106  2.557756   0.75932825 1.4817687  3.6660328\n",
      " 0.55693966 1.2070912  1.1909689  0.8477852  1.3892384  1.8805768\n",
      " 1.3879731  2.3299565  2.0131083  0.9278344  2.9840364  0.4279429\n",
      " 1.2802446  0.5108975  4.068235   3.3829784  2.8055387  0.51726305\n",
      " 0.74943745 0.68595666]\n",
      "Epoch: 2, Loss: [1.8650084  1.0241531  2.4319594  1.0484667  2.858787   0.6318902\n",
      " 0.6027827  2.1285548  2.246725   0.60246617 1.3054531  3.9627202\n",
      " 0.44304463 1.0542877  0.83839756 0.7565739  1.4515008  1.973923\n",
      " 1.3271011  2.7232187  1.6781708  0.85851294 1.7906152  0.5633868\n",
      " 1.3567216  0.47213107 3.391006   2.8252854  2.8459864  0.31104788\n",
      " 0.9060584  0.6770479 ]\n",
      "Epoch: 3, Loss: [1.5442209  0.83980924 2.4659743  0.96722066 2.5629501  0.478545\n",
      " 0.42572373 2.0470924  1.9445567  0.42538077 1.187163   4.120317\n",
      " 0.3959983  1.1294019  0.69117683 0.65888107 1.6013856  1.8191264\n",
      " 1.0622369  2.6285152  1.07645    0.94718355 1.0548137  0.67546606\n",
      " 1.4682059  0.4090883  2.961514   2.5092907  2.9113657  0.24748999\n",
      " 1.0390344  0.6382015 ]\n",
      "Epoch: 4, Loss: [1.5366424  0.6326372  2.2833776  0.7358832  2.3891115  0.38362354\n",
      " 0.42371532 2.0258768  1.7643951  0.2851607  0.96957266 4.204548\n",
      " 0.37579575 1.4686764  0.514654   0.6328337  1.5405324  1.7531937\n",
      " 0.92965066 2.6099901  0.72498775 1.0052891  0.7397684  0.7920099\n",
      " 1.5970452  0.3254343  2.6474504  2.1228518  2.7624035  0.24945359\n",
      " 1.0379834  0.6440772 ]\n"
     ]
    }
   ],
   "source": [
    "# 数据集和批次大小设定\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "#(x_train, y_train), _ = tf.keras.datasets.cifar10.load_data()\n",
    "#y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size)\n",
    "\n",
    "# 直接在循环中使用train_step\n",
    "for epoch in range(epochs):\n",
    "    for x_batch, y_batch in train_dataset:\n",
    "        loss = train_step_2(x_batch, y_batch)\n",
    "    print(\"Epoch: {}, Loss: {}\".format(epoch, loss.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0136ea97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 20.8177 - accuracy: 0.5631\n",
      "Test loss: 20.817655563354492, Test accuracy: 0.5630999803543091\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model.evaluate(x_test_tigger, y_test_tigger)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "825ba0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 379.3007 - accuracy: 0.1112\n",
      "Test loss: 379.3006896972656, Test accuracy: 0.1111999973654747\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model.evaluate(x_test, y_test)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9af046b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1eb639b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4494f3aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e666cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9c629a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bc2d4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760da89e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ee753b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5510e6d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e19f6f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18ce98a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e006b52c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b40870",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1f4e5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59902c96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d70e2f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7795e8b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df44e4ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b870de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1996264c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bd4c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ad4fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f69399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42103c39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16166627",
   "metadata": {},
   "outputs": [],
   "source": [
    "#313/313 [==============================] - 1s 3ms/step - loss: 0.9457 - accuracy: 0.7466\n",
    "#Test loss: 0.9456651210784912, Test accuracy: 0.7465999722480774\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5779f424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b3488b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4599d336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f9b916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea5c058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924e0078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7f7939",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cdd3dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0677e902",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b004cea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620a52fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf6a0497",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
