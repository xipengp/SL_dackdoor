{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c60afba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 21:11:48.820123: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input, GlobalAveragePooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '3'\n",
    "# 加载 CIFAR-10 数据\n",
    "import random\n",
    "import numpy as np\n",
    "# Load and preprocess CIFAR-10 data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41d482cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##该模型并没有使用双重对齐，因为我使用的数据错了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84173dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xipeng/anaconda3/envs/keras2/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "import imageio\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from random import sample\n",
    "\n",
    "\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "import random\n",
    "import PIL\n",
    "from torchvision.transforms import functional as F\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import Compose\n",
    "\n",
    "\n",
    "class AddTrigger:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def add_trigger(self, img, noise=False):\n",
    "        \"\"\"Add WaNet trigger to image.\n",
    "\n",
    "        Args:\n",
    "            img (torch.Tensor): shape (C, H, W).\n",
    "            noise (bool): turn on noise mode, default is False\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Poisoned image, shape (C, H, W).\n",
    "        \"\"\"\n",
    "        if noise:\n",
    "            ins = torch.rand(1, self.h, self.h, 2) * self.noise_rescale - 1  # [-1, 1]\n",
    "            grid = self.grid + ins / self.h\n",
    "            grid = torch.clamp(self.grid + ins / self.h, -1, 1)\n",
    "        else:\n",
    "            grid = self.grid\n",
    "        poison_img = nn.functional.grid_sample(img.unsqueeze(0), grid, align_corners=True).squeeze()  # CHW\n",
    "        return poison_img\n",
    "\n",
    "\n",
    "class AddCIFAR10Trigger(AddTrigger):\n",
    "    \"\"\"Add WaNet trigger to CIFAR10 image.\n",
    "\n",
    "    Args:\n",
    "        identity_grid (orch.Tensor): the poisoned pattern shape.\n",
    "        noise_grid (orch.Tensor): the noise pattern.\n",
    "        noise (bool): turn on noise mode, default is False.\n",
    "        s (int or float): The strength of the noise grid. Default is 0.5.\n",
    "        grid_rescale (int or float): Scale :attr:`grid` to avoid pixel values going out of [-1, 1].\n",
    "            Default is 1.\n",
    "        noise_rescale (int or float): Scale the random noise from a uniform distribution on the\n",
    "            interval [0, 1). Default is 2.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, identity_grid, noise_grid, noise=True, s=0.9, grid_rescale=1, noise_rescale=2):\n",
    "        super(AddCIFAR10Trigger, self).__init__()\n",
    "\n",
    "        self.identity_grid = deepcopy(identity_grid)\n",
    "        self.noise_grid = deepcopy(noise_grid)\n",
    "        self.h = self.identity_grid.shape[2]\n",
    "        self.noise = noise\n",
    "        self.s = s\n",
    "        self.grid_rescale = grid_rescale\n",
    "        grid = self.identity_grid + self.s * self.noise_grid / self.h\n",
    "        self.grid = torch.clamp(grid * self.grid_rescale, -1, 1)\n",
    "        self.noise_rescale = noise_rescale\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img = F.pil_to_tensor(img)\n",
    "        img = F.convert_image_dtype(img, torch.float)\n",
    "        img = self.add_trigger(img, noise=self.noise)\n",
    "        img = img.numpy().transpose(1, 2, 0)\n",
    "        img = Image.fromarray(np.clip(img*255,0,255).round().astype(np.uint8))\n",
    "        # img = Image.fromarray(img.permute(1, 2, 0).numpy())\n",
    "        return img\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as tF\n",
    "\n",
    "# 设置设备为 CUDA (GPU) 如果可用，否则使用 CPU\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# CIFAR10 图像尺寸\n",
    "input_height, input_width = 32, 32\n",
    "\n",
    "# 创建 identity_grid\n",
    "y, x = torch.meshgrid(torch.linspace(-1, 1, input_height), torch.linspace(-1, 1, input_width))\n",
    "identity_grid = torch.stack((x, y), 2).unsqueeze(0).to(device)\n",
    "\n",
    "# 创建噪声 pattern\n",
    "ins = torch.randn(1, 1, input_height, input_width).to(device)  # 随机噪声\n",
    "noise_grid = tF.interpolate(ins, size=(input_height, input_width), mode=\"bicubic\", align_corners=True)\n",
    "noise_grid = noise_grid.permute(0, 2, 3, 1).to(device)\n",
    "\n",
    "trigger = AddCIFAR10Trigger(identity_grid, noise_grid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "169f22f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 选择1%的训练数据进行攻击\n",
    "num_samples = int(0.05 * x_val.shape[0])\n",
    "indices = np.random.choice(y_val.shape[0], num_samples, replace=False)\n",
    "\n",
    "target_class = 1  # 目标类别\n",
    "num_classes = 10  # CIFAR-10 数据集的类别数\n",
    "\n",
    "y_val_tigger_2 = np.zeros(len(y_val))  # 所有标签初始化为0\n",
    "# 将标签转换为one-hot编码\n",
    "y_val_tigger_2 = to_categorical(y_val_tigger_2, num_classes=2)\n",
    "\n",
    "x_val_tigger = x_val.copy()\n",
    "y_val_tigger = y_val.copy()\n",
    "\n",
    "for i in range(len(x_val_tigger)):\n",
    "    img = x_val_tigger[i]  # 获取单个图像\n",
    "    img_pil = Image.fromarray((img * 255).astype(np.uint8)) \n",
    "    poisoned_img_tensor = trigger(img_pil)\n",
    "    transform_to_tensor = transforms.ToTensor()\n",
    "    poisoned_img_tensor = transform_to_tensor(poisoned_img_tensor)\n",
    "# 将 PyTorch 张量转换为 NumPy 数组\n",
    "    poisoned_img_np = poisoned_img_tensor.numpy().transpose(1, 2, 0)\n",
    "    x_val_tigger[i] = poisoned_img_np  \n",
    "    y_val_tigger[i] = to_categorical(target_class, num_classes=10)\n",
    "    y_val_tigger_2[i] = to_categorical(target_class, num_classes = 2 )   \n",
    "    \n",
    "    \n",
    "x_test_tigger = x_test.copy()\n",
    "y_test_tigger = y_test.copy()\n",
    "\n",
    "    \n",
    "    \n",
    "for i in range(len(x_test)):\n",
    "    img = x_test_tigger[i]  # 获取单个图像\n",
    "    img_pil = Image.fromarray((img * 255).astype(np.uint8)) \n",
    "    poisoned_img_tensor = trigger(img_pil)\n",
    "    transform_to_tensor = transforms.ToTensor()\n",
    "    poisoned_img_tensor = transform_to_tensor(poisoned_img_tensor)\n",
    "# 将 PyTorch 张量转换为 NumPy 数组\n",
    "    poisoned_img_np = poisoned_img_tensor.numpy().transpose(1, 2, 0)\n",
    "    x_test_tigger[i] = poisoned_img_np  \n",
    "    y_test_tigger[i] = to_categorical(target_class, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868cb926",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4afbc06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c832278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac519184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "\n",
    "def create_client_model(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # 第一层卷积\n",
    "    x = layers.Conv2D(32, 3, strides=1, padding='same')(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # 第二层卷积\n",
    "    x = layers.Conv2D(64, 3, strides=1, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # 新增的第三层卷积\n",
    "    x = layers.Conv2D(128, 3, strides=1, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9b113d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def res_block(filters, strides):\n",
    "    def block(x):\n",
    "        shortcut = x\n",
    "\n",
    "        x = layers.Conv2D(filters, 3, padding='same', strides=strides)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation('relu')(x)\n",
    "\n",
    "        x = layers.Conv2D(filters, 3, padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        # 捷径连接前的调整\n",
    "        shortcut = layers.Conv2D(filters, 1, strides=strides, padding='same')(shortcut)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "        x = layers.add([x, shortcut])\n",
    "        x = layers.Activation('relu')(x)\n",
    "        return x\n",
    "    return block\n",
    "\n",
    "def create_server_model():\n",
    "    # 调整输入层的定义以匹配修改后的客户端模型的输出\n",
    "    input_layer = layers.Input(shape=(32, 32, 128))  # 注意这里的变化\n",
    "\n",
    "    # 残差块定义保持不变，继续使用提前定义的 res_block\n",
    "    x = res_block(64, 1)(input_layer)  # 使用第一个残差块\n",
    "    x = res_block(128, 2)(x)            # 使用第二个残差块\n",
    "    x = res_block(128, 2)(x)           # 使用第三个残差块\n",
    "    x = res_block(256, 2)(x)           # 使用第四个残差块\n",
    "\n",
    "    # 全局平均池化和输出层保持不变\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    output = layers.Dense(10, activation='softmax')(x)\n",
    "    \n",
    "    model = models.Model(inputs=input_layer, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "315784e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_aux_model():\n",
    "    # 调整输入层的定义以匹配修改后的客户端模型的输出\n",
    "    input_layer = layers.Input(shape=(32, 32, 128))  # 注意这里的变化\n",
    "\n",
    "    # 第一个卷积层和ReLU激活\n",
    "    x = layers.Conv2D(128, 3, strides=2, padding='same')(input_layer)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # 第二个卷积层和ReLU激活\n",
    "    x = layers.Conv2D(128, 3, strides=2, padding='same')(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # 添加残差块\n",
    "    x = res_block(256, 1)(x)  # 使用第一个残差块\n",
    "    x = res_block(256, 1)(x) # 使用第二个残差块\n",
    "\n",
    "    # 第三个卷积层和ReLU激活\n",
    "    x = layers.Conv2D(256, 3, strides=2, padding='same')(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # 全连接层\n",
    "    x = layers.Flatten()(x)\n",
    "    output = layers.Dense(2, activation='softmax')(x)\n",
    "    \n",
    "    model = models.Model(inputs=input_layer, outputs=output)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "275e51f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 21:13:13.318770: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2024-07-22 21:13:13.482948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:d8:00.0 name: NVIDIA Tesla V100-PCIE-16GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2024-07-22 21:13:13.483025: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-07-22 21:13:13.502187: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2024-07-22 21:13:13.506174: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2024-07-22 21:13:13.522368: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2024-07-22 21:13:13.526569: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-07-22 21:13:13.543888: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2024-07-22 21:13:13.578818: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-07-22 21:13:13.581715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2024-07-22 21:13:13.603062: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-22 21:13:13.659218: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 1700000000 Hz\n",
      "2024-07-22 21:13:13.665113: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55bfbb582510 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-22 21:13:13.665154: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2024-07-22 21:13:14.291740: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55bfbb5eea60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-22 21:13:14.291780: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA Tesla V100-PCIE-16GB, Compute Capability 7.0\n",
      "2024-07-22 21:13:14.293326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:d8:00.0 name: NVIDIA Tesla V100-PCIE-16GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2024-07-22 21:13:14.293373: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-07-22 21:13:14.293422: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2024-07-22 21:13:14.293444: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2024-07-22 21:13:14.293466: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2024-07-22 21:13:14.293487: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-07-22 21:13:14.293508: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2024-07-22 21:13:14.293531: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-07-22 21:13:14.296004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2024-07-22 21:13:14.296055: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-07-22 21:13:17.035713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-07-22 21:13:17.035773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
      "2024-07-22 21:13:17.035787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
      "2024-07-22 21:13:17.048930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12893 MB memory) -> physical GPU (device: 0, name: NVIDIA Tesla V100-PCIE-16GB, pci bus id: 0000:d8:00.0, compute capability: 7.0)\n"
     ]
    }
   ],
   "source": [
    "aux_model = create_aux_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c39f56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_discrim_model():\n",
    "    # 调整输入层的定义以匹配修改后的客户端模型的输出\n",
    "    input_layer = layers.Input(shape=(32, 32, 128))   # 注意这里的变化\n",
    "\n",
    "    # 第一个卷积层和ReLU激活\n",
    "    x = layers.Conv2D(128, 3, strides=2, padding='same')(input_layer)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # 第二个卷积层和ReLU激活\n",
    "    x = layers.Conv2D(128, 3, strides=2, padding='same')(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # 添加三个残差块\n",
    "    x = res_block(256, 1)(x)  # 使用第一个残差块\n",
    "    x = res_block(256, 1)(x)  # 使用第二个残差块\n",
    "    x = res_block(256, 1)(x)  # 使用第三个残差块\n",
    "\n",
    "    # 第三个卷积层和ReLU激活\n",
    "    x = layers.Conv2D(256, 3, strides=2, padding='same')(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # 全连接层，输出单一值\n",
    "    x = layers.Flatten()(x)\n",
    "    output = layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = models.Model(inputs=input_layer, outputs=output)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41af76d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrim_model = create_discrim_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbf547e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 32, 32, 128) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 128)  147584      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 16, 16, 128)  0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 8, 8, 128)    147584      re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 8, 8, 128)    0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 8, 8, 256)    295168      re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 8, 8, 256)    1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 8, 8, 256)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 8, 8, 256)    590080      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 8, 8, 256)    33024       re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 8, 8, 256)    1024        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 8, 8, 256)    1024        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 8, 8, 256)    0           batch_normalization_7[0][0]      \n",
      "                                                                 batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 8, 8, 256)    0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 8, 8, 256)    590080      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 8, 8, 256)    1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 8, 8, 256)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 8, 8, 256)    590080      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 8, 8, 256)    65792       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 8, 8, 256)    1024        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 8, 8, 256)    1024        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 8, 8, 256)    0           batch_normalization_10[0][0]     \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 8, 8, 256)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 8, 8, 256)    590080      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 8, 8, 256)    1024        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 8, 8, 256)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 8, 8, 256)    590080      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 8, 8, 256)    65792       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8, 8, 256)    1024        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 8, 256)    1024        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 8, 8, 256)    0           batch_normalization_13[0][0]     \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 8, 8, 256)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 4, 4, 256)    590080      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 4, 4, 256)    0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 4096)         0           re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            4097        flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,308,737\n",
      "Trainable params: 4,304,129\n",
      "Non-trainable params: 4,608\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discrim_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db651573",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_model = create_server_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e3f8e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建客户端模型\n",
    "client_model = create_client_model(input_shape=(32, 32, 3))\n",
    "\n",
    "# 编译客户端模型\n",
    "client_model.compile(optimizer=Adam(),\n",
    "                     loss='categorical_crossentropy',\n",
    "                     metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48415595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae58403e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d87a529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下是服务器模型训练的简化示例\n",
    "server_model.compile(optimizer=Adam(),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "discrim_model.compile(optimizer=Adam(),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "aux_model.compile(optimizer=Adam(),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fd1fc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##创建三个影子模型，分别是1层卷积，2层卷积核3层卷积\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de2fe1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_client_model_1(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    # 确保输出为128个通道\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(input_layer)\n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n",
    "def create_client_model_2(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(input_layer)\n",
    "    # 第二层输出调整为128个通道\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n",
    "def create_client_model_3(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(input_layer)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same')(x)  # 移除这里的激活函数\n",
    "    x = layers.Activation('relu')(x)  # 显式添加ReLU激活层\n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n",
    "\n",
    "def create_client_model_4(input_shape):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(input_layer)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    # 第四层输出调整为128个通道\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
    "    model = models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a21e02f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming TensorFlow is installed and the functions are defined in your script\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "client_model_1 = create_client_model(input_shape=(32, 32, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc16f227",
   "metadata": {},
   "outputs": [],
   "source": [
    "###数据集\n",
    "###对于影子数据集，需要5000个，并且中毒率为百分之10.需要修改标签，\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e466dc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b93d0dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "\n",
    "# 获取client_model的输出，作为其他两个模型的输入\n",
    "feature_output = client_model_1.output\n",
    "\n",
    "# 用client_model的输出作为输入创建两个任务的模型\n",
    "server_output = server_model(feature_output)\n",
    "aux_output = aux_model(feature_output)\n",
    "\n",
    "combined_model = models.Model(inputs=client_model_1.input, outputs=[aux_output, server_output])\n",
    "combined_model.compile(optimizer='adam',\n",
    "                       loss={'aux_output': 'binary_crossentropy', \n",
    "                             'server_output': 'categorical_crossentropy'},\n",
    "                       loss_weights={'aux_output': 0.5, \n",
    "                                     'server_output': 0.5},\n",
    "                       metrics=['accuracy'])\n",
    "combined_model.compile(optimizer='adam',\n",
    "                       loss=['binary_crossentropy', 'categorical_crossentropy'],\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8a0962e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 21:13:40.727610: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2024-07-22 21:13:42.522721: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-07-22 21:13:49.637667: W tensorflow/stream_executor/gpu/asm_compiler.cc:81] Running ptxas --version returned 256\n",
      "2024-07-22 21:13:50.406577: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1406/1406 [==============================] - 399s 284ms/step - loss: 0.0031 - functional_1_loss: 3.0713e-04 - functional_5_loss: 0.0028 - functional_1_accuracy: 0.9999 - functional_5_accuracy: 0.9995\n",
      "Epoch 2/50\n",
      "1406/1406 [==============================] - 39s 28ms/step - loss: 1.2651e-05 - functional_1_loss: 0.0000e+00 - functional_5_loss: 1.2651e-05 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "1406/1406 [==============================] - 38s 27ms/step - loss: 4.4643e-06 - functional_1_loss: 0.0000e+00 - functional_5_loss: 4.4643e-06 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "1406/1406 [==============================] - 39s 28ms/step - loss: 1.9564e-06 - functional_1_loss: 0.0000e+00 - functional_5_loss: 1.9564e-06 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "1406/1406 [==============================] - 39s 27ms/step - loss: 9.3653e-07 - functional_1_loss: 0.0000e+00 - functional_5_loss: 9.3653e-07 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "1406/1406 [==============================] - 40s 29ms/step - loss: 4.5339e-07 - functional_1_loss: 0.0000e+00 - functional_5_loss: 4.5339e-07 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "1406/1406 [==============================] - 39s 28ms/step - loss: 1.8788e-07 - functional_1_loss: 0.0000e+00 - functional_5_loss: 1.8788e-07 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "1406/1406 [==============================] - 40s 29ms/step - loss: 6.5653e-09 - functional_1_loss: 0.0000e+00 - functional_5_loss: 6.5653e-09 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "1406/1406 [==============================] - 40s 28ms/step - loss: 1.5974e-10 - functional_1_loss: 0.0000e+00 - functional_5_loss: 1.5974e-10 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "1406/1406 [==============================] - 39s 28ms/step - loss: 0.0000e+00 - functional_1_loss: 0.0000e+00 - functional_5_loss: 0.0000e+00 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "1406/1406 [==============================] - 40s 29ms/step - loss: 0.0000e+00 - functional_1_loss: 0.0000e+00 - functional_5_loss: 0.0000e+00 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "1406/1406 [==============================] - 39s 28ms/step - loss: 0.0000e+00 - functional_1_loss: 0.0000e+00 - functional_5_loss: 0.0000e+00 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "1406/1406 [==============================] - 37s 26ms/step - loss: 0.0000e+00 - functional_1_loss: 0.0000e+00 - functional_5_loss: 0.0000e+00 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "1406/1406 [==============================] - 37s 26ms/step - loss: 0.0000e+00 - functional_1_loss: 0.0000e+00 - functional_5_loss: 0.0000e+00 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "1406/1406 [==============================] - 37s 26ms/step - loss: 0.0000e+00 - functional_1_loss: 0.0000e+00 - functional_5_loss: 0.0000e+00 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "1406/1406 [==============================] - 38s 27ms/step - loss: 0.0000e+00 - functional_1_loss: 0.0000e+00 - functional_5_loss: 0.0000e+00 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "1406/1406 [==============================] - 36s 26ms/step - loss: 0.0000e+00 - functional_1_loss: 0.0000e+00 - functional_5_loss: 0.0000e+00 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "1406/1406 [==============================] - 35s 25ms/step - loss: 0.0000e+00 - functional_1_loss: 0.0000e+00 - functional_5_loss: 0.0000e+00 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "1406/1406 [==============================] - 37s 26ms/step - loss: 0.0000e+00 - functional_1_loss: 0.0000e+00 - functional_5_loss: 0.0000e+00 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "1406/1406 [==============================] - 37s 26ms/step - loss: 0.0000e+00 - functional_1_loss: 0.0000e+00 - functional_5_loss: 0.0000e+00 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "1406/1406 [==============================] - 36s 25ms/step - loss: 0.0000e+00 - functional_1_loss: 0.0000e+00 - functional_5_loss: 0.0000e+00 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "1406/1406 [==============================] - 37s 27ms/step - loss: 0.0000e+00 - functional_1_loss: 0.0000e+00 - functional_5_loss: 0.0000e+00 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "1406/1406 [==============================] - 38s 27ms/step - loss: 0.0000e+00 - functional_1_loss: 0.0000e+00 - functional_5_loss: 0.0000e+00 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "1406/1406 [==============================] - 37s 27ms/step - loss: 0.0000e+00 - functional_1_loss: 0.0000e+00 - functional_5_loss: 0.0000e+00 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "1406/1406 [==============================] - 38s 27ms/step - loss: 0.0000e+00 - functional_1_loss: 0.0000e+00 - functional_5_loss: 0.0000e+00 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "1406/1406 [==============================] - 40s 28ms/step - loss: 0.0000e+00 - functional_1_loss: 0.0000e+00 - functional_5_loss: 0.0000e+00 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "1406/1406 [==============================] - 39s 28ms/step - loss: 0.0000e+00 - functional_1_loss: 0.0000e+00 - functional_5_loss: 0.0000e+00 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "1406/1406 [==============================] - 41s 29ms/step - loss: 0.0000e+00 - functional_1_loss: 0.0000e+00 - functional_5_loss: 0.0000e+00 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "1406/1406 [==============================] - 39s 27ms/step - loss: 0.0000e+00 - functional_1_loss: 0.0000e+00 - functional_5_loss: 0.0000e+00 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "1406/1406 [==============================] - 40s 28ms/step - loss: 0.0000e+00 - functional_1_loss: 0.0000e+00 - functional_5_loss: 0.0000e+00 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "1406/1406 [==============================] - 38s 27ms/step - loss: 0.0000e+00 - functional_1_loss: 0.0000e+00 - functional_5_loss: 0.0000e+00 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "1406/1406 [==============================] - 39s 28ms/step - loss: 0.0000e+00 - functional_1_loss: 0.0000e+00 - functional_5_loss: 0.0000e+00 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "1406/1406 [==============================] - 37s 27ms/step - loss: 0.0000e+00 - functional_1_loss: 0.0000e+00 - functional_5_loss: 0.0000e+00 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "1406/1406 [==============================] - 39s 28ms/step - loss: 0.0000e+00 - functional_1_loss: 0.0000e+00 - functional_5_loss: 0.0000e+00 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "1406/1406 [==============================] - 40s 28ms/step - loss: 0.0000e+00 - functional_1_loss: 0.0000e+00 - functional_5_loss: 0.0000e+00 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "1406/1406 [==============================] - 39s 27ms/step - loss: 0.0000e+00 - functional_1_loss: 0.0000e+00 - functional_5_loss: 0.0000e+00 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "1406/1406 [==============================] - 38s 27ms/step - loss: 0.0000e+00 - functional_1_loss: 0.0000e+00 - functional_5_loss: 0.0000e+00 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "1406/1406 [==============================] - 39s 28ms/step - loss: 0.0000e+00 - functional_1_loss: 0.0000e+00 - functional_5_loss: 0.0000e+00 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "1406/1406 [==============================] - 38s 27ms/step - loss: 0.0000e+00 - functional_1_loss: 0.0000e+00 - functional_5_loss: 0.0000e+00 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "1406/1406 [==============================] - 34s 24ms/step - loss: 0.0000e+00 - functional_1_loss: 0.0000e+00 - functional_5_loss: 0.0000e+00 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "1406/1406 [==============================] - 36s 25ms/step - loss: 0.0000e+00 - functional_1_loss: 0.0000e+00 - functional_5_loss: 0.0000e+00 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "1406/1406 [==============================] - 35s 25ms/step - loss: 0.0000e+00 - functional_1_loss: 0.0000e+00 - functional_5_loss: 0.0000e+00 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "1406/1406 [==============================] - 36s 26ms/step - loss: 0.0000e+00 - functional_1_loss: 0.0000e+00 - functional_5_loss: 0.0000e+00 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "1406/1406 [==============================] - 34s 24ms/step - loss: 0.0000e+00 - functional_1_loss: 0.0000e+00 - functional_5_loss: 0.0000e+00 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "1406/1406 [==============================] - 35s 25ms/step - loss: 0.0000e+00 - functional_1_loss: 0.0000e+00 - functional_5_loss: 0.0000e+00 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "1406/1406 [==============================] - 35s 25ms/step - loss: 0.0000e+00 - functional_1_loss: 0.0000e+00 - functional_5_loss: 0.0000e+00 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "1406/1406 [==============================] - 35s 25ms/step - loss: 0.0000e+00 - functional_1_loss: 0.0000e+00 - functional_5_loss: 0.0000e+00 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "1406/1406 [==============================] - 34s 25ms/step - loss: 0.0000e+00 - functional_1_loss: 0.0000e+00 - functional_5_loss: 0.0000e+00 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "1406/1406 [==============================] - 34s 24ms/step - loss: 0.0000e+00 - functional_1_loss: 0.0000e+00 - functional_5_loss: 0.0000e+00 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "1406/1406 [==============================] - 36s 25ms/step - loss: 0.0000e+00 - functional_1_loss: 0.0000e+00 - functional_5_loss: 0.0000e+00 - functional_1_accuracy: 1.0000 - functional_5_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "def preprocess(image, label1, label2):\n",
    "    # 随机翻转图像\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    # 随机调整亮度\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    # 其他数据增强操作...\n",
    "    return image, (label1, label2)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_val_tigger, y_val_tigger_2, y_val_tigger))\n",
    "train_dataset = train_dataset.map(preprocess)  # 应用数据增强\n",
    "train_dataset = train_dataset.batch(32)        # 批处理大小\n",
    "train_dataset = train_dataset.repeat()         # 重复数据集\n",
    "\n",
    "# 使用数据集训练模型\n",
    "history = combined_model.fit(train_dataset,\n",
    "                             epochs=50,\n",
    "                             steps_per_epoch=len(x_train) // 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5252662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###可以看到训练精度还是蛮高的，但是测试精度不理想。过拟合了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a6a50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791c0c72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad54af10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "182686d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "def create_combined_model(client_model, server_model, compile_only=False):\n",
    "    # Getting the input of the client model\n",
    "    client_input = client_model.input\n",
    "    \n",
    "    # Getting the intermediate output by passing the input through the client model\n",
    "    client_output = client_model(client_input)\n",
    "    \n",
    "    # The client model's output is used as the input for the server model\n",
    "    server_output = server_model(client_output)\n",
    "    \n",
    "    # Defining a new model that chains the client and server models\n",
    "    combined_model = Model(inputs=client_input, outputs=server_output)\n",
    "    \n",
    "    # Compile the combined model\n",
    "    combined_model.compile(optimizer=Adam(),\n",
    "                           loss='categorical_crossentropy',\n",
    "                           metrics=['accuracy'])\n",
    "    \n",
    "    if not compile_only:\n",
    "        # If not compile_only, evaluate the model\n",
    "        loss, accuracy = combined_model.evaluate(x_test, y_test, verbose=0)\n",
    "        print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n",
    "    \n",
    "    return combined_model\n",
    "combined_model_mian = create_combined_model(client_model_1, server_model, compile_only=True)\n",
    "combined_model_aux = create_combined_model(client_model_1, aux_model, compile_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18a82e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model_mian.evaluate(x_val_tigger, y_val_tigger, verbose=1)\n",
    "##数据集太小会导致过拟合，因此 - loss: 1.7600e-07 - accuracy: 1.0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76a43cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model_aux.evaluate(x_val_tigger, y_val_tigger_2, verbose=1)\n",
    "#0.9证明全部归为了1。 数据集不均衡，会导致二分类器没办法使用，这里也是一个bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b80e977a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 114s 365ms/step - loss: 22.8001 - accuracy: 0.1000\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model_mian.evaluate(x_test, y_test, verbose=1)\n",
    "##因为数据集比较小，因此精度会比客户端小很多，正常"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "606242d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model_mian.evaluate(x_test_tigger, y_test_tigger, verbose=1)\n",
    "##后门成功率很高。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3bfdf7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "def train_discriminator(model, real_data, fake_data, optimizer):\n",
    "    \"\"\"\n",
    "    Train the discriminator on one batch of real and fake data using TensorFlow.\n",
    "    \n",
    "    Args:\n",
    "    model (tf.keras.Model): The discriminator model.\n",
    "    real_data (tf.Tensor): Batch of real data.\n",
    "    fake_data (tf.Tensor): Batch of fake data.\n",
    "    optimizer (tf.keras.optimizers.Optimizer): Optimizer for the discriminator.\n",
    "    \n",
    "    Returns:\n",
    "    float: The loss value.\n",
    "    \"\"\"\n",
    "    # 真实数据标签（1）和假数据标签（0）\n",
    "    real_labels = tf.ones((real_data.shape[0], 1))\n",
    "    fake_labels = tf.zeros((fake_data.shape[0], 1))\n",
    "\n",
    "    # 合并真实数据和假数据及其标签\n",
    "    inputs = tf.concat([real_data, fake_data], axis=0)\n",
    "    labels = tf.concat([real_labels, fake_labels], axis=0)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = BinaryCrossentropy(from_logits=False)(labels, predictions)\n",
    "\n",
    "    # 计算梯度并更新模型参数\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    return loss.numpy()  # 返回损失值\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "770f149e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_client_model(client_model, discrim_model, train_batch, optimizer):\n",
    "    \"\"\"\n",
    "    Train the client model so that the discriminator cannot distinguish\n",
    "    between real (val_batch) and fake (generated by client_model).\n",
    "    \n",
    "    Args:\n",
    "    client_model (tf.keras.Model): The client model to be trained.\n",
    "    discrim_model (tf.keras.Model): The discriminator model.\n",
    "    train_batch (tf.Tensor): Batch of real data.\n",
    "    optimizer (tf.keras.optimizers.Optimizer): Optimizer for the client model.\n",
    "    \n",
    "    Returns:\n",
    "    float: The loss value.\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        # 通过 client_model 生成的输出\n",
    "        generated_data = client_model(train_batch, training=True)\n",
    "        \n",
    "        # 通过 discrim_model 计算生成数据的判别值，确保 discrim_model 处于评估模式\n",
    "        fake_outputs = discrim_model(generated_data, training=False)\n",
    "        \n",
    "        # 计算损失，使得 discrim_model 无法区分 generated_data 和真实数据\n",
    "        loss = -tf.reduce_mean(tf.math.log(1 - fake_outputs + 1e-8))  # 1e-8 防止 log(0)\n",
    "    \n",
    "    # 计算 client_model 的梯度并更新\n",
    "    gradients = tape.gradient(loss, client_model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, client_model.trainable_variables))\n",
    "    \n",
    "    return loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12ba82cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb8d0e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(image, label):\n",
    "    # 随机水平翻转图像\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    # 随机调整亮度\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    # 确保图像值仍然在0到1的范围内\n",
    "    image = tf.clip_by_value(image, 0.0, 1.0)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "603d6854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 3.5882439613342285\n",
      "Epoch: 1, Loss: 9.937897682189941\n",
      "Epoch: 2, Loss: -0.0\n",
      "Epoch: 3, Loss: 0.017557883635163307\n",
      "Epoch: 4, Loss: 1.3521133661270142\n",
      "Epoch: 5, Loss: 1.1920931797249068e-07\n",
      "Epoch: 6, Loss: 18.42068099975586\n",
      "Epoch: 7, Loss: -0.0\n",
      "Epoch: 8, Loss: 0.0003939472953788936\n",
      "Epoch: 9, Loss: 8.782441727817059e-05\n",
      "Epoch: 10, Loss: 4.276651452528313e-06\n",
      "Epoch: 11, Loss: 2.831084728240967\n",
      "Epoch: 12, Loss: 0.004774904809892178\n",
      "Epoch: 13, Loss: 2.886889934539795\n",
      "Epoch: 14, Loss: 5.437136650085449\n",
      "Epoch: 15, Loss: 0.0010164225241169333\n",
      "Epoch: 16, Loss: 5.119038105010986\n",
      "Epoch: 17, Loss: 0.19936290383338928\n",
      "Epoch: 18, Loss: 0.007732592523097992\n",
      "Epoch: 19, Loss: 2.299527883529663\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20 # 定义训练的轮数\n",
    "batch_size = 64  # 或者根据你的内存限制调整\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(x_train).batch(64)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(x_val_tigger).batch(32).repeat()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "discrim_model.compile(optimizer=Adam(learning_rate=0.0002, beta_1=0.5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "client_optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\n",
    "\n",
    "combined_dataset = tf.data.Dataset.zip((train_dataset, val_dataset))\n",
    "\n",
    "# 使用 itertools.cycle 让验证数据循环使用\n",
    "#val_loader = cycle(val_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for (train_batch, val_batch) in combined_dataset:\n",
    "        real_data = client_model(train_batch)\n",
    "        fake_data = client_model_1(val_batch)\n",
    "        loss = train_discriminator(discrim_model, real_data, fake_data, optimizer)\n",
    "        loss = train_client_model(client_model, discrim_model, train_batch, client_optimizer)\n",
    "    print(f\"Epoch: {epoch}, Loss: {loss}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1f387d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model_mian_c = create_combined_model(client_model, server_model, compile_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a89f90b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 23.4617 - accuracy: 0.1000\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model_mian_c.evaluate(x_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f041071a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model_mian_c.evaluate(x_test_tigger, y_test_tigger, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b29e1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model_mian_c.evaluate(x_val_tigger, y_val_tigger, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "95771d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 5ms/step - loss: 23.5052 - accuracy: 0.0974\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = combined_model_mian_c.evaluate(x_val, y_val, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691bb7ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5770e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821ccded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c558d9c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf22d01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da19e000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f003d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49910c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8fccd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a175bafb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc335ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b3b286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2827b30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#313/313 [==============================] - 1s 3ms/step - loss: 0.9457 - accuracy: 0.7466\n",
    "#Test loss: 0.9456651210784912, Test accuracy: 0.7465999722480774\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647fe269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcab6815",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec0ba22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d1c861",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37509cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d471386c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19742d84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f36fbc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027a4ace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a792b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2658f35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5deedf7",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
